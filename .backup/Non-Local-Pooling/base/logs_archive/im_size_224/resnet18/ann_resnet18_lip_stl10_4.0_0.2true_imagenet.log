
 Run on time: 2022-06-23 02:13:41.111488

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : RESNET18_LIP
	 im_size              : 224
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0,1
 DataParallel(
  (module): NetworkByName(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): LIP_BASE(
              (logit): Sequential(
                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): LIP_BASE(
              (logit): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): LIP_BASE(
              (logit): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.2567, train_acc: 0.1816 test_loss: 1.9218, test_acc: 0.2639, best: 0.2639, time: 0:01:09
 Epoch: 2, lr: 1.0e-02, train_loss: 1.9950, train_acc: 0.2228 test_loss: 2.2194, test_acc: 0.2715, best: 0.2715, time: 0:00:51
 Epoch: 3, lr: 1.0e-02, train_loss: 1.9034, train_acc: 0.2558 test_loss: 1.7982, test_acc: 0.3227, best: 0.3227, time: 0:00:52
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8438, train_acc: 0.2834 test_loss: 1.8168, test_acc: 0.3322, best: 0.3322, time: 0:00:51
 Epoch: 5, lr: 1.0e-02, train_loss: 1.7925, train_acc: 0.3130 test_loss: 1.8969, test_acc: 0.3441, best: 0.3441, time: 0:00:50
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7181, train_acc: 0.3520 test_loss: 1.9674, test_acc: 0.3830, best: 0.3830, time: 0:00:51
 Epoch: 7, lr: 1.0e-02, train_loss: 1.6662, train_acc: 0.3698 test_loss: 1.8421, test_acc: 0.3726, best: 0.3830, time: 0:00:50
 Epoch: 8, lr: 1.0e-02, train_loss: 1.6280, train_acc: 0.3812 test_loss: 1.6158, test_acc: 0.3945, best: 0.3945, time: 0:00:51
 Epoch: 9, lr: 1.0e-02, train_loss: 1.5666, train_acc: 0.4130 test_loss: 1.6605, test_acc: 0.4017, best: 0.4017, time: 0:00:51
 Epoch: 10, lr: 1.0e-02, train_loss: 1.5184, train_acc: 0.4270 test_loss: 1.4293, test_acc: 0.4785, best: 0.4785, time: 0:00:51
 Epoch: 11, lr: 1.0e-02, train_loss: 1.4966, train_acc: 0.4390 test_loss: 1.6788, test_acc: 0.4266, best: 0.4785, time: 0:00:50
 Epoch: 12, lr: 1.0e-02, train_loss: 1.4671, train_acc: 0.4586 test_loss: 1.4618, test_acc: 0.4490, best: 0.4785, time: 0:00:51
 Epoch: 13, lr: 1.0e-02, train_loss: 1.4363, train_acc: 0.4630 test_loss: 1.4644, test_acc: 0.4743, best: 0.4785, time: 0:00:51
 Epoch: 14, lr: 1.0e-02, train_loss: 1.4138, train_acc: 0.4768 test_loss: 1.3284, test_acc: 0.5215, best: 0.5215, time: 0:00:51
 Epoch: 15, lr: 1.0e-02, train_loss: 1.3722, train_acc: 0.4942 test_loss: 1.3200, test_acc: 0.5314, best: 0.5314, time: 0:00:51
 Epoch: 16, lr: 1.0e-02, train_loss: 1.3611, train_acc: 0.4968 test_loss: 1.2961, test_acc: 0.5316, best: 0.5316, time: 0:00:50
 Epoch: 17, lr: 1.0e-02, train_loss: 1.3197, train_acc: 0.5164 test_loss: 1.3586, test_acc: 0.5324, best: 0.5324, time: 0:00:51
 Epoch: 18, lr: 1.0e-02, train_loss: 1.3054, train_acc: 0.5318 test_loss: 1.3501, test_acc: 0.5154, best: 0.5324, time: 0:00:51
 Epoch: 19, lr: 1.0e-02, train_loss: 1.2716, train_acc: 0.5392 test_loss: 1.4390, test_acc: 0.5182, best: 0.5324, time: 0:00:50
 Epoch: 20, lr: 1.0e-02, train_loss: 1.2618, train_acc: 0.5336 test_loss: 1.2552, test_acc: 0.5565, best: 0.5565, time: 0:00:51
 Epoch: 21, lr: 1.0e-02, train_loss: 1.2300, train_acc: 0.5478 test_loss: 1.2285, test_acc: 0.5674, best: 0.5674, time: 0:00:51
 Epoch: 22, lr: 1.0e-02, train_loss: 1.2168, train_acc: 0.5596 test_loss: 1.2274, test_acc: 0.5736, best: 0.5736, time: 0:00:51
 Epoch: 23, lr: 1.0e-02, train_loss: 1.1710, train_acc: 0.5790 test_loss: 1.2034, test_acc: 0.5829, best: 0.5829, time: 0:00:51
 Epoch: 24, lr: 1.0e-02, train_loss: 1.1643, train_acc: 0.5762 test_loss: 1.3844, test_acc: 0.5252, best: 0.5829, time: 0:00:51
 Epoch: 25, lr: 1.0e-02, train_loss: 1.1440, train_acc: 0.5816 test_loss: 1.2295, test_acc: 0.5806, best: 0.5829, time: 0:00:50
 Epoch: 26, lr: 1.0e-02, train_loss: 1.1182, train_acc: 0.5962 test_loss: 1.0785, test_acc: 0.6328, best: 0.6328, time: 0:00:51
 Epoch: 27, lr: 1.0e-02, train_loss: 1.1021, train_acc: 0.6028 test_loss: 1.2036, test_acc: 0.5909, best: 0.6328, time: 0:00:51
 Epoch: 28, lr: 1.0e-02, train_loss: 1.1094, train_acc: 0.5914 test_loss: 1.2979, test_acc: 0.5853, best: 0.6328, time: 0:00:50
 Epoch: 29, lr: 1.0e-02, train_loss: 1.0705, train_acc: 0.6168 test_loss: 1.1680, test_acc: 0.6071, best: 0.6328, time: 0:00:51
 Epoch: 30, lr: 1.0e-02, train_loss: 1.0770, train_acc: 0.6136 test_loss: 1.1804, test_acc: 0.5883, best: 0.6328, time: 0:00:51
 Epoch: 31, lr: 1.0e-02, train_loss: 1.0471, train_acc: 0.6224 test_loss: 1.3891, test_acc: 0.5971, best: 0.6328, time: 0:00:51
 Epoch: 32, lr: 1.0e-02, train_loss: 1.0273, train_acc: 0.6348 test_loss: 1.0759, test_acc: 0.6360, best: 0.6360, time: 0:00:50
 Epoch: 33, lr: 1.0e-02, train_loss: 0.9907, train_acc: 0.6466 test_loss: 1.2264, test_acc: 0.6074, best: 0.6360, time: 0:00:51
 Epoch: 34, lr: 1.0e-02, train_loss: 0.9970, train_acc: 0.6410 test_loss: 1.1476, test_acc: 0.6269, best: 0.6360, time: 0:00:50
 Epoch: 35, lr: 1.0e-02, train_loss: 0.9584, train_acc: 0.6602 test_loss: 1.1307, test_acc: 0.6579, best: 0.6579, time: 0:00:50
 Epoch: 36, lr: 1.0e-02, train_loss: 0.9735, train_acc: 0.6500 test_loss: 1.0002, test_acc: 0.6611, best: 0.6611, time: 0:00:51
 Epoch: 37, lr: 1.0e-02, train_loss: 0.9319, train_acc: 0.6600 test_loss: 1.4897, test_acc: 0.6218, best: 0.6611, time: 0:00:50
 Epoch: 38, lr: 1.0e-02, train_loss: 0.9257, train_acc: 0.6630 test_loss: 1.6625, test_acc: 0.5874, best: 0.6611, time: 0:00:51
 Epoch: 39, lr: 1.0e-02, train_loss: 0.9106, train_acc: 0.6802 test_loss: 1.2355, test_acc: 0.6620, best: 0.6620, time: 0:00:50
 Epoch: 40, lr: 1.0e-02, train_loss: 0.9394, train_acc: 0.6628 test_loss: 1.2687, test_acc: 0.6242, best: 0.6620, time: 0:00:51
 Epoch: 41, lr: 1.0e-02, train_loss: 0.8917, train_acc: 0.6766 test_loss: 0.9567, test_acc: 0.6724, best: 0.6724, time: 0:00:51
 Epoch: 42, lr: 1.0e-02, train_loss: 0.8473, train_acc: 0.6986 test_loss: 1.1132, test_acc: 0.6633, best: 0.6724, time: 0:00:52
 Epoch: 43, lr: 1.0e-02, train_loss: 0.8836, train_acc: 0.6824 test_loss: 0.9607, test_acc: 0.6816, best: 0.6816, time: 0:00:51
 Epoch: 44, lr: 1.0e-02, train_loss: 0.8344, train_acc: 0.7046 test_loss: 1.0980, test_acc: 0.6684, best: 0.6816, time: 0:00:52
 Epoch: 45, lr: 1.0e-02, train_loss: 0.8188, train_acc: 0.7064 test_loss: 1.0515, test_acc: 0.6967, best: 0.6967, time: 0:00:51
 Epoch: 46, lr: 1.0e-02, train_loss: 0.8134, train_acc: 0.7102 test_loss: 0.9170, test_acc: 0.6905, best: 0.6967, time: 0:00:51
 Epoch: 47, lr: 1.0e-02, train_loss: 0.7951, train_acc: 0.7144 test_loss: 0.8558, test_acc: 0.7185, best: 0.7185, time: 0:00:52
 Epoch: 48, lr: 1.0e-02, train_loss: 0.7753, train_acc: 0.7222 test_loss: 1.0171, test_acc: 0.6700, best: 0.7185, time: 0:00:50
 Epoch: 49, lr: 1.0e-02, train_loss: 0.7676, train_acc: 0.7230 test_loss: 0.8709, test_acc: 0.7021, best: 0.7185, time: 0:00:51
 Epoch: 50, lr: 1.0e-02, train_loss: 0.7587, train_acc: 0.7232 test_loss: 0.9360, test_acc: 0.6903, best: 0.7185, time: 0:00:51
 Epoch: 51, lr: 1.0e-02, train_loss: 0.7607, train_acc: 0.7286 test_loss: 0.9546, test_acc: 0.6811, best: 0.7185, time: 0:00:50
 Epoch: 52, lr: 1.0e-02, train_loss: 0.7479, train_acc: 0.7320 test_loss: 0.9096, test_acc: 0.7013, best: 0.7185, time: 0:00:50
 Epoch: 53, lr: 1.0e-02, train_loss: 0.7092, train_acc: 0.7492 test_loss: 0.9182, test_acc: 0.7199, best: 0.7199, time: 0:00:51
 Epoch: 54, lr: 1.0e-02, train_loss: 0.7301, train_acc: 0.7422 test_loss: 0.9790, test_acc: 0.6927, best: 0.7199, time: 0:00:50
 Epoch: 55, lr: 1.0e-02, train_loss: 0.7248, train_acc: 0.7432 test_loss: 0.8205, test_acc: 0.7362, best: 0.7362, time: 0:00:50
 Epoch: 56, lr: 1.0e-02, train_loss: 0.6928, train_acc: 0.7534 test_loss: 0.9179, test_acc: 0.7202, best: 0.7362, time: 0:00:50
 Epoch: 57, lr: 1.0e-02, train_loss: 0.6755, train_acc: 0.7584 test_loss: 0.8266, test_acc: 0.7229, best: 0.7362, time: 0:00:51
 Epoch: 58, lr: 1.0e-02, train_loss: 0.6715, train_acc: 0.7674 test_loss: 0.9834, test_acc: 0.7320, best: 0.7362, time: 0:00:51
 Epoch: 59, lr: 1.0e-02, train_loss: 0.6674, train_acc: 0.7690 test_loss: 0.8579, test_acc: 0.7319, best: 0.7362, time: 0:00:51
 Epoch: 60, lr: 1.0e-02, train_loss: 0.7030, train_acc: 0.7534 test_loss: 0.8512, test_acc: 0.7329, best: 0.7362, time: 0:00:51
 Epoch: 61, lr: 1.0e-02, train_loss: 0.6887, train_acc: 0.7504 test_loss: 0.8315, test_acc: 0.7415, best: 0.7415, time: 0:00:50
 Epoch: 62, lr: 1.0e-02, train_loss: 0.6502, train_acc: 0.7700 test_loss: 0.7615, test_acc: 0.7450, best: 0.7450, time: 0:00:51
 Epoch: 63, lr: 1.0e-02, train_loss: 0.6666, train_acc: 0.7604 test_loss: 0.7936, test_acc: 0.7552, best: 0.7552, time: 0:00:51
 Epoch: 64, lr: 1.0e-02, train_loss: 0.6215, train_acc: 0.7826 test_loss: 1.0165, test_acc: 0.7301, best: 0.7552, time: 0:00:51
 Epoch: 65, lr: 1.0e-02, train_loss: 0.6126, train_acc: 0.7890 test_loss: 0.9222, test_acc: 0.7418, best: 0.7552, time: 0:00:51
 Epoch: 66, lr: 1.0e-02, train_loss: 0.6198, train_acc: 0.7828 test_loss: 0.9382, test_acc: 0.7462, best: 0.7552, time: 0:00:51
 Epoch: 67, lr: 1.0e-02, train_loss: 0.6098, train_acc: 0.7830 test_loss: 1.2202, test_acc: 0.7358, best: 0.7552, time: 0:00:51
 Epoch: 68, lr: 1.0e-02, train_loss: 0.5959, train_acc: 0.7920 test_loss: 0.8893, test_acc: 0.7252, best: 0.7552, time: 0:00:51
 Epoch: 69, lr: 1.0e-02, train_loss: 0.5779, train_acc: 0.7958 test_loss: 0.7700, test_acc: 0.7552, best: 0.7552, time: 0:00:51
 Epoch: 70, lr: 1.0e-02, train_loss: 0.5590, train_acc: 0.8010 test_loss: 0.8836, test_acc: 0.7388, best: 0.7552, time: 0:00:51
 Epoch: 71, lr: 1.0e-02, train_loss: 0.5547, train_acc: 0.8078 test_loss: 0.9621, test_acc: 0.7341, best: 0.7552, time: 0:00:50
 Epoch: 72, lr: 1.0e-02, train_loss: 0.5459, train_acc: 0.8078 test_loss: 0.9217, test_acc: 0.7494, best: 0.7552, time: 0:00:51
 Epoch: 73, lr: 1.0e-02, train_loss: 0.5377, train_acc: 0.8102 test_loss: 0.8104, test_acc: 0.7499, best: 0.7552, time: 0:00:51
 Epoch: 74, lr: 1.0e-02, train_loss: 0.5454, train_acc: 0.8130 test_loss: 1.0485, test_acc: 0.7476, best: 0.7552, time: 0:00:50
 Epoch: 75, lr: 1.0e-02, train_loss: 0.5273, train_acc: 0.8128 test_loss: 0.8975, test_acc: 0.7475, best: 0.7552, time: 0:00:52
 Epoch: 76, lr: 1.0e-02, train_loss: 0.5312, train_acc: 0.8140 test_loss: 0.7198, test_acc: 0.7706, best: 0.7706, time: 0:00:51
 Epoch: 77, lr: 1.0e-02, train_loss: 0.5138, train_acc: 0.8168 test_loss: 0.7886, test_acc: 0.7644, best: 0.7706, time: 0:00:51
 Epoch: 78, lr: 1.0e-02, train_loss: 0.5210, train_acc: 0.8168 test_loss: 0.9794, test_acc: 0.7475, best: 0.7706, time: 0:00:51
 Epoch: 79, lr: 1.0e-02, train_loss: 0.5081, train_acc: 0.8244 test_loss: 0.9797, test_acc: 0.7528, best: 0.7706, time: 0:00:51
 Epoch: 80, lr: 1.0e-02, train_loss: 0.4870, train_acc: 0.8336 test_loss: 0.7772, test_acc: 0.7764, best: 0.7764, time: 0:00:51
 Epoch: 81, lr: 1.0e-02, train_loss: 0.4659, train_acc: 0.8322 test_loss: 0.8165, test_acc: 0.7806, best: 0.7806, time: 0:00:51
 Epoch: 82, lr: 1.0e-02, train_loss: 0.4726, train_acc: 0.8348 test_loss: 0.8576, test_acc: 0.7505, best: 0.7806, time: 0:00:50
 Epoch: 83, lr: 1.0e-02, train_loss: 0.4881, train_acc: 0.8278 test_loss: 0.8701, test_acc: 0.7446, best: 0.7806, time: 0:00:51
 Epoch: 84, lr: 1.0e-02, train_loss: 0.4745, train_acc: 0.8310 test_loss: 0.8858, test_acc: 0.7648, best: 0.7806, time: 0:00:51
 Epoch: 85, lr: 1.0e-02, train_loss: 0.4569, train_acc: 0.8368 test_loss: 0.9210, test_acc: 0.7778, best: 0.7806, time: 0:00:51
 Epoch: 86, lr: 1.0e-02, train_loss: 0.4646, train_acc: 0.8418 test_loss: 1.6658, test_acc: 0.7139, best: 0.7806, time: 0:00:51
 Epoch: 87, lr: 1.0e-02, train_loss: 0.4452, train_acc: 0.8414 test_loss: 0.9859, test_acc: 0.7398, best: 0.7806, time: 0:00:51
 Epoch: 88, lr: 1.0e-02, train_loss: 0.4481, train_acc: 0.8446 test_loss: 0.9123, test_acc: 0.7600, best: 0.7806, time: 0:00:51
 Epoch: 89, lr: 1.0e-02, train_loss: 0.4378, train_acc: 0.8446 test_loss: 1.6383, test_acc: 0.7312, best: 0.7806, time: 0:00:50
 Epoch: 90, lr: 1.0e-02, train_loss: 0.4464, train_acc: 0.8490 test_loss: 0.7543, test_acc: 0.7771, best: 0.7806, time: 0:00:50
 Epoch: 91, lr: 1.0e-02, train_loss: 0.4189, train_acc: 0.8540 test_loss: 0.8349, test_acc: 0.7665, best: 0.7806, time: 0:00:51
 Epoch: 92, lr: 1.0e-02, train_loss: 0.4310, train_acc: 0.8522 test_loss: 0.8025, test_acc: 0.7781, best: 0.7806, time: 0:00:51
 Epoch: 93, lr: 1.0e-02, train_loss: 0.4123, train_acc: 0.8538 test_loss: 0.9418, test_acc: 0.7528, best: 0.7806, time: 0:00:50
 Epoch: 94, lr: 1.0e-02, train_loss: 0.4010, train_acc: 0.8626 test_loss: 0.9485, test_acc: 0.7468, best: 0.7806, time: 0:00:50
 Epoch: 95, lr: 1.0e-02, train_loss: 0.3928, train_acc: 0.8636 test_loss: 0.9202, test_acc: 0.7659, best: 0.7806, time: 0:00:51
 Epoch: 96, lr: 1.0e-02, train_loss: 0.3855, train_acc: 0.8652 test_loss: 0.6729, test_acc: 0.8075, best: 0.8075, time: 0:00:52
 Epoch: 97, lr: 1.0e-02, train_loss: 0.3982, train_acc: 0.8636 test_loss: 0.7394, test_acc: 0.7909, best: 0.8075, time: 0:00:52
 Epoch: 98, lr: 1.0e-02, train_loss: 0.3989, train_acc: 0.8570 test_loss: 1.0864, test_acc: 0.7284, best: 0.8075, time: 0:00:50
 Epoch: 99, lr: 1.0e-02, train_loss: 0.3893, train_acc: 0.8682 test_loss: 0.8686, test_acc: 0.7808, best: 0.8075, time: 0:00:51
 Epoch: 100, lr: 1.0e-02, train_loss: 0.3881, train_acc: 0.8670 test_loss: 0.8494, test_acc: 0.7691, best: 0.8075, time: 0:00:51
 Epoch: 101, lr: 1.0e-02, train_loss: 0.3854, train_acc: 0.8636 test_loss: 0.8679, test_acc: 0.7581, best: 0.8075, time: 0:00:51
 Epoch: 102, lr: 1.0e-02, train_loss: 0.3838, train_acc: 0.8690 test_loss: 0.8537, test_acc: 0.7700, best: 0.8075, time: 0:00:52
 Epoch: 103, lr: 1.0e-02, train_loss: 0.3775, train_acc: 0.8712 test_loss: 0.8633, test_acc: 0.7751, best: 0.8075, time: 0:00:50
 Epoch: 104, lr: 1.0e-02, train_loss: 0.3783, train_acc: 0.8664 test_loss: 0.7393, test_acc: 0.7975, best: 0.8075, time: 0:00:50
 Epoch: 105, lr: 1.0e-02, train_loss: 0.3813, train_acc: 0.8728 test_loss: 0.8944, test_acc: 0.7652, best: 0.8075, time: 0:00:51
 Epoch: 106, lr: 1.0e-02, train_loss: 0.3653, train_acc: 0.8772 test_loss: 1.0426, test_acc: 0.7750, best: 0.8075, time: 0:00:51
 Epoch: 107, lr: 1.0e-02, train_loss: 0.3447, train_acc: 0.8792 test_loss: 1.0745, test_acc: 0.7479, best: 0.8075, time: 0:00:51
 Epoch: 108, lr: 1.0e-02, train_loss: 0.3546, train_acc: 0.8776 test_loss: 0.9292, test_acc: 0.7636, best: 0.8075, time: 0:00:51
 Epoch: 109, lr: 1.0e-02, train_loss: 0.3610, train_acc: 0.8750 test_loss: 0.8798, test_acc: 0.7734, best: 0.8075, time: 0:00:51
 Epoch: 110, lr: 1.0e-02, train_loss: 0.3611, train_acc: 0.8730 test_loss: 0.8087, test_acc: 0.7875, best: 0.8075, time: 0:00:51
 Epoch: 111, lr: 1.0e-02, train_loss: 0.3495, train_acc: 0.8800 test_loss: 0.9536, test_acc: 0.7648, best: 0.8075, time: 0:00:51
 Epoch: 112, lr: 1.0e-02, train_loss: 0.3322, train_acc: 0.8842 test_loss: 1.0329, test_acc: 0.7712, best: 0.8075, time: 0:00:51
 Epoch: 113, lr: 1.0e-02, train_loss: 0.3395, train_acc: 0.8826 test_loss: 0.9533, test_acc: 0.7616, best: 0.8075, time: 0:00:50
 Epoch: 114, lr: 1.0e-02, train_loss: 0.3232, train_acc: 0.8884 test_loss: 0.8893, test_acc: 0.7843, best: 0.8075, time: 0:00:51
 Epoch: 115, lr: 1.0e-02, train_loss: 0.3103, train_acc: 0.8940 test_loss: 0.7227, test_acc: 0.8027, best: 0.8075, time: 0:00:50
 Epoch: 116, lr: 1.0e-02, train_loss: 0.3199, train_acc: 0.8912 test_loss: 1.1369, test_acc: 0.7630, best: 0.8075, time: 0:00:51
 Epoch: 117, lr: 1.0e-02, train_loss: 0.3297, train_acc: 0.8836 test_loss: 0.9366, test_acc: 0.7646, best: 0.8075, time: 0:00:51
 Epoch: 118, lr: 1.0e-02, train_loss: 0.3433, train_acc: 0.8854 test_loss: 0.8828, test_acc: 0.7879, best: 0.8075, time: 0:00:51
 Epoch: 119, lr: 1.0e-02, train_loss: 0.3276, train_acc: 0.8872 test_loss: 1.5877, test_acc: 0.7458, best: 0.8075, time: 0:00:50
 Epoch: 120, lr: 1.0e-02, train_loss: 0.3072, train_acc: 0.8976 test_loss: 1.0169, test_acc: 0.7784, best: 0.8075, time: 0:00:51
 Epoch: 121, lr: 1.0e-02, train_loss: 0.3157, train_acc: 0.8902 test_loss: 1.6027, test_acc: 0.7316, best: 0.8075, time: 0:00:51
 Epoch: 122, lr: 1.0e-02, train_loss: 0.3180, train_acc: 0.8924 test_loss: 1.3519, test_acc: 0.7609, best: 0.8075, time: 0:00:50
 Epoch: 123, lr: 1.0e-02, train_loss: 0.2995, train_acc: 0.8946 test_loss: 1.0182, test_acc: 0.7829, best: 0.8075, time: 0:00:50
 Epoch: 124, lr: 1.0e-02, train_loss: 0.2948, train_acc: 0.9006 test_loss: 0.9387, test_acc: 0.7884, best: 0.8075, time: 0:00:50
 Epoch: 125, lr: 1.0e-02, train_loss: 0.3066, train_acc: 0.8938 test_loss: 0.9369, test_acc: 0.7907, best: 0.8075, time: 0:00:51
 Epoch: 126, lr: 1.0e-02, train_loss: 0.3007, train_acc: 0.8978 test_loss: 0.9913, test_acc: 0.7821, best: 0.8075, time: 0:00:51
 Epoch: 127, lr: 1.0e-02, train_loss: 0.2877, train_acc: 0.9086 test_loss: 0.7497, test_acc: 0.8016, best: 0.8075, time: 0:00:51
 Epoch: 128, lr: 1.0e-02, train_loss: 0.3061, train_acc: 0.8954 test_loss: 0.8038, test_acc: 0.8003, best: 0.8075, time: 0:00:51
 Epoch: 129, lr: 1.0e-02, train_loss: 0.3045, train_acc: 0.8958 test_loss: 0.9299, test_acc: 0.7903, best: 0.8075, time: 0:00:51
 Epoch: 130, lr: 1.0e-02, train_loss: 0.2997, train_acc: 0.8982 test_loss: 0.9572, test_acc: 0.7796, best: 0.8075, time: 0:00:51
 Epoch: 131, lr: 1.0e-02, train_loss: 0.2831, train_acc: 0.9024 test_loss: 0.7956, test_acc: 0.8045, best: 0.8075, time: 0:00:50
 Epoch: 132, lr: 1.0e-02, train_loss: 0.2878, train_acc: 0.8984 test_loss: 0.9160, test_acc: 0.7790, best: 0.8075, time: 0:00:51
 Epoch: 133, lr: 1.0e-02, train_loss: 0.3034, train_acc: 0.8974 test_loss: 1.0441, test_acc: 0.7847, best: 0.8075, time: 0:00:52
 Epoch: 134, lr: 1.0e-02, train_loss: 0.2750, train_acc: 0.9038 test_loss: 0.9624, test_acc: 0.7885, best: 0.8075, time: 0:00:51
 Epoch: 135, lr: 1.0e-02, train_loss: 0.2672, train_acc: 0.9090 test_loss: 1.0327, test_acc: 0.7739, best: 0.8075, time: 0:00:51
 Epoch: 136, lr: 1.0e-02, train_loss: 0.2756, train_acc: 0.9058 test_loss: 0.7971, test_acc: 0.8035, best: 0.8075, time: 0:00:50
 Epoch: 137, lr: 1.0e-02, train_loss: 0.2758, train_acc: 0.9068 test_loss: 0.6959, test_acc: 0.8057, best: 0.8075, time: 0:00:52
 Epoch: 138, lr: 1.0e-02, train_loss: 0.2798, train_acc: 0.9004 test_loss: 0.9792, test_acc: 0.7730, best: 0.8075, time: 0:00:50
 Epoch: 139, lr: 1.0e-02, train_loss: 0.2637, train_acc: 0.9074 test_loss: 1.3610, test_acc: 0.7476, best: 0.8075, time: 0:00:51
 Epoch: 140, lr: 1.0e-02, train_loss: 0.2770, train_acc: 0.9028 test_loss: 1.0131, test_acc: 0.7701, best: 0.8075, time: 0:00:51
 Epoch: 141, lr: 1.0e-02, train_loss: 0.2595, train_acc: 0.9154 test_loss: 1.0278, test_acc: 0.7769, best: 0.8075, time: 0:00:51
 Epoch: 142, lr: 1.0e-02, train_loss: 0.2638, train_acc: 0.9108 test_loss: 0.9711, test_acc: 0.7850, best: 0.8075, time: 0:00:50
 Epoch: 143, lr: 1.0e-02, train_loss: 0.2640, train_acc: 0.9090 test_loss: 0.7565, test_acc: 0.8079, best: 0.8079, time: 0:00:50
 Epoch: 144, lr: 1.0e-02, train_loss: 0.2594, train_acc: 0.9106 test_loss: 0.8360, test_acc: 0.8013, best: 0.8079, time: 0:00:50
 Epoch: 145, lr: 1.0e-02, train_loss: 0.2548, train_acc: 0.9136 test_loss: 0.9836, test_acc: 0.7817, best: 0.8079, time: 0:00:51
 Epoch: 146, lr: 1.0e-02, train_loss: 0.2512, train_acc: 0.9160 test_loss: 0.8124, test_acc: 0.7965, best: 0.8079, time: 0:00:50
 Epoch: 147, lr: 1.0e-02, train_loss: 0.2510, train_acc: 0.9176 test_loss: 0.7071, test_acc: 0.8113, best: 0.8113, time: 0:00:51
 Epoch: 148, lr: 1.0e-02, train_loss: 0.2502, train_acc: 0.9116 test_loss: 1.2841, test_acc: 0.7572, best: 0.8113, time: 0:00:50
 Epoch: 149, lr: 1.0e-02, train_loss: 0.2532, train_acc: 0.9130 test_loss: 0.8459, test_acc: 0.7926, best: 0.8113, time: 0:00:50
 Epoch: 150, lr: 1.0e-02, train_loss: 0.2553, train_acc: 0.9124 test_loss: 0.7980, test_acc: 0.8027, best: 0.8113, time: 0:00:51
 Epoch: 151, lr: 1.0e-02, train_loss: 0.2438, train_acc: 0.9170 test_loss: 0.9988, test_acc: 0.7764, best: 0.8113, time: 0:00:51
 Epoch: 152, lr: 1.0e-02, train_loss: 0.2451, train_acc: 0.9172 test_loss: 0.9629, test_acc: 0.7830, best: 0.8113, time: 0:00:51
 Epoch: 153, lr: 1.0e-02, train_loss: 0.2434, train_acc: 0.9128 test_loss: 0.9953, test_acc: 0.7835, best: 0.8113, time: 0:00:51
 Epoch: 154, lr: 1.0e-02, train_loss: 0.2620, train_acc: 0.9070 test_loss: 1.1351, test_acc: 0.7879, best: 0.8113, time: 0:00:50
 Epoch: 155, lr: 1.0e-02, train_loss: 0.2458, train_acc: 0.9168 test_loss: 0.7860, test_acc: 0.8100, best: 0.8113, time: 0:00:50
 Epoch: 156, lr: 1.0e-02, train_loss: 0.2275, train_acc: 0.9214 test_loss: 0.7020, test_acc: 0.8237, best: 0.8237, time: 0:00:50
 Epoch: 157, lr: 1.0e-02, train_loss: 0.2338, train_acc: 0.9240 test_loss: 0.9107, test_acc: 0.7990, best: 0.8237, time: 0:00:51
 Epoch: 158, lr: 1.0e-02, train_loss: 0.2341, train_acc: 0.9194 test_loss: 0.8384, test_acc: 0.8080, best: 0.8237, time: 0:00:50
 Epoch: 159, lr: 1.0e-02, train_loss: 0.2560, train_acc: 0.9070 test_loss: 1.7853, test_acc: 0.7604, best: 0.8237, time: 0:00:51
 Epoch: 160, lr: 1.0e-02, train_loss: 0.2195, train_acc: 0.9260 test_loss: 1.8477, test_acc: 0.7690, best: 0.8237, time: 0:00:51
 Epoch: 161, lr: 1.0e-02, train_loss: 0.2510, train_acc: 0.9158 test_loss: 1.0212, test_acc: 0.7986, best: 0.8237, time: 0:00:52
 Epoch: 162, lr: 1.0e-02, train_loss: 0.2264, train_acc: 0.9242 test_loss: 1.4162, test_acc: 0.7712, best: 0.8237, time: 0:00:50
 Epoch: 163, lr: 1.0e-02, train_loss: 0.2327, train_acc: 0.9212 test_loss: 0.8793, test_acc: 0.8005, best: 0.8237, time: 0:00:51
 Epoch: 164, lr: 1.0e-02, train_loss: 0.2379, train_acc: 0.9196 test_loss: 0.9985, test_acc: 0.7779, best: 0.8237, time: 0:00:51
 Epoch: 165, lr: 1.0e-02, train_loss: 0.2197, train_acc: 0.9208 test_loss: 0.7991, test_acc: 0.8030, best: 0.8237, time: 0:00:51
 Epoch: 166, lr: 1.0e-02, train_loss: 0.2249, train_acc: 0.9222 test_loss: 0.8834, test_acc: 0.7957, best: 0.8237, time: 0:00:51
 Epoch: 167, lr: 1.0e-02, train_loss: 0.2230, train_acc: 0.9228 test_loss: 0.7666, test_acc: 0.8139, best: 0.8237, time: 0:00:51
 Epoch: 168, lr: 1.0e-02, train_loss: 0.2355, train_acc: 0.9234 test_loss: 0.7329, test_acc: 0.8134, best: 0.8237, time: 0:00:51
 Epoch: 169, lr: 1.0e-02, train_loss: 0.2277, train_acc: 0.9246 test_loss: 0.9122, test_acc: 0.8046, best: 0.8237, time: 0:00:51
 Epoch: 170, lr: 1.0e-02, train_loss: 0.2283, train_acc: 0.9224 test_loss: 0.8063, test_acc: 0.8066, best: 0.8237, time: 0:00:51
 Epoch: 171, lr: 1.0e-02, train_loss: 0.2218, train_acc: 0.9270 test_loss: 1.5327, test_acc: 0.7974, best: 0.8237, time: 0:00:51
 Epoch: 172, lr: 1.0e-02, train_loss: 0.2060, train_acc: 0.9302 test_loss: 0.8220, test_acc: 0.8173, best: 0.8237, time: 0:00:50
 Epoch: 173, lr: 1.0e-02, train_loss: 0.2253, train_acc: 0.9258 test_loss: 3.6665, test_acc: 0.7585, best: 0.8237, time: 0:00:50
 Epoch: 174, lr: 1.0e-02, train_loss: 0.2353, train_acc: 0.9202 test_loss: 1.6154, test_acc: 0.7564, best: 0.8237, time: 0:00:50
 Epoch: 175, lr: 1.0e-02, train_loss: 0.2187, train_acc: 0.9264 test_loss: 0.9096, test_acc: 0.8059, best: 0.8237, time: 0:00:51
 Epoch: 176, lr: 1.0e-02, train_loss: 0.2047, train_acc: 0.9318 test_loss: 1.3320, test_acc: 0.7830, best: 0.8237, time: 0:00:51
 Epoch: 177, lr: 1.0e-02, train_loss: 0.2183, train_acc: 0.9240 test_loss: 0.8820, test_acc: 0.7969, best: 0.8237, time: 0:00:50
 Epoch: 178, lr: 1.0e-02, train_loss: 0.2117, train_acc: 0.9278 test_loss: 1.1050, test_acc: 0.7951, best: 0.8237, time: 0:00:50
 Epoch: 179, lr: 1.0e-02, train_loss: 0.2272, train_acc: 0.9196 test_loss: 0.9868, test_acc: 0.7971, best: 0.8237, time: 0:00:51
 Epoch: 180, lr: 2.0e-03, train_loss: 0.1761, train_acc: 0.9388 test_loss: 1.1088, test_acc: 0.8045, best: 0.8237, time: 0:00:51
 Epoch: 181, lr: 2.0e-03, train_loss: 0.1706, train_acc: 0.9418 test_loss: 0.8126, test_acc: 0.8176, best: 0.8237, time: 0:00:51
 Epoch: 182, lr: 2.0e-03, train_loss: 0.1711, train_acc: 0.9432 test_loss: 1.2543, test_acc: 0.7947, best: 0.8237, time: 0:00:51
 Epoch: 183, lr: 2.0e-03, train_loss: 0.1466, train_acc: 0.9530 test_loss: 0.9544, test_acc: 0.8139, best: 0.8237, time: 0:00:52
 Epoch: 184, lr: 2.0e-03, train_loss: 0.1578, train_acc: 0.9472 test_loss: 1.3916, test_acc: 0.7861, best: 0.8237, time: 0:00:50
 Epoch: 185, lr: 2.0e-03, train_loss: 0.1595, train_acc: 0.9476 test_loss: 1.1777, test_acc: 0.7967, best: 0.8237, time: 0:00:50
 Epoch: 186, lr: 2.0e-03, train_loss: 0.1366, train_acc: 0.9520 test_loss: 0.9560, test_acc: 0.8111, best: 0.8237, time: 0:00:51
 Epoch: 187, lr: 2.0e-03, train_loss: 0.1588, train_acc: 0.9494 test_loss: 1.0750, test_acc: 0.8075, best: 0.8237, time: 0:00:50
 Epoch: 188, lr: 2.0e-03, train_loss: 0.1519, train_acc: 0.9482 test_loss: 0.9132, test_acc: 0.8149, best: 0.8237, time: 0:00:51
 Epoch: 189, lr: 2.0e-03, train_loss: 0.1542, train_acc: 0.9454 test_loss: 0.9557, test_acc: 0.8153, best: 0.8237, time: 0:00:50
 Epoch: 190, lr: 2.0e-03, train_loss: 0.1466, train_acc: 0.9518 test_loss: 0.8451, test_acc: 0.8196, best: 0.8237, time: 0:00:50
 Epoch: 191, lr: 2.0e-03, train_loss: 0.1559, train_acc: 0.9494 test_loss: 0.9128, test_acc: 0.8147, best: 0.8237, time: 0:00:50
 Epoch: 192, lr: 2.0e-03, train_loss: 0.1485, train_acc: 0.9514 test_loss: 1.0905, test_acc: 0.8046, best: 0.8237, time: 0:00:50
 Epoch: 193, lr: 2.0e-03, train_loss: 0.1443, train_acc: 0.9528 test_loss: 1.2198, test_acc: 0.8015, best: 0.8237, time: 0:00:51
 Epoch: 194, lr: 2.0e-03, train_loss: 0.1314, train_acc: 0.9576 test_loss: 0.8763, test_acc: 0.8203, best: 0.8237, time: 0:00:50
 Epoch: 195, lr: 2.0e-03, train_loss: 0.1461, train_acc: 0.9500 test_loss: 0.9039, test_acc: 0.8193, best: 0.8237, time: 0:00:51
 Epoch: 196, lr: 2.0e-03, train_loss: 0.1374, train_acc: 0.9542 test_loss: 0.9701, test_acc: 0.8134, best: 0.8237, time: 0:00:51
 Epoch: 197, lr: 2.0e-03, train_loss: 0.1443, train_acc: 0.9528 test_loss: 1.0597, test_acc: 0.8135, best: 0.8237, time: 0:00:50
 Epoch: 198, lr: 2.0e-03, train_loss: 0.1321, train_acc: 0.9554 test_loss: 0.9306, test_acc: 0.8153, best: 0.8237, time: 0:00:50
 Epoch: 199, lr: 2.0e-03, train_loss: 0.1394, train_acc: 0.9532 test_loss: 0.9795, test_acc: 0.8110, best: 0.8237, time: 0:00:51
 Epoch: 200, lr: 2.0e-03, train_loss: 0.1258, train_acc: 0.9578 test_loss: 0.8011, test_acc: 0.8240, best: 0.8240, time: 0:00:51
 Epoch: 201, lr: 2.0e-03, train_loss: 0.1301, train_acc: 0.9552 test_loss: 1.0145, test_acc: 0.8093, best: 0.8240, time: 0:00:51
 Epoch: 202, lr: 2.0e-03, train_loss: 0.1285, train_acc: 0.9560 test_loss: 1.2217, test_acc: 0.8059, best: 0.8240, time: 0:00:51
 Epoch: 203, lr: 2.0e-03, train_loss: 0.1244, train_acc: 0.9574 test_loss: 1.1993, test_acc: 0.8025, best: 0.8240, time: 0:00:50
 Epoch: 204, lr: 2.0e-03, train_loss: 0.1424, train_acc: 0.9518 test_loss: 1.0704, test_acc: 0.8077, best: 0.8240, time: 0:00:51
 Epoch: 205, lr: 2.0e-03, train_loss: 0.1406, train_acc: 0.9530 test_loss: 1.3208, test_acc: 0.7951, best: 0.8240, time: 0:00:51
 Epoch: 206, lr: 2.0e-03, train_loss: 0.1331, train_acc: 0.9568 test_loss: 0.8806, test_acc: 0.8173, best: 0.8240, time: 0:00:51
 Epoch: 207, lr: 2.0e-03, train_loss: 0.1250, train_acc: 0.9546 test_loss: 0.8920, test_acc: 0.8163, best: 0.8240, time: 0:00:50
 Epoch: 208, lr: 2.0e-03, train_loss: 0.1391, train_acc: 0.9508 test_loss: 0.9334, test_acc: 0.8115, best: 0.8240, time: 0:00:51
 Epoch: 209, lr: 2.0e-03, train_loss: 0.1269, train_acc: 0.9566 test_loss: 1.2825, test_acc: 0.7981, best: 0.8240, time: 0:00:51
 Epoch: 210, lr: 2.0e-03, train_loss: 0.1289, train_acc: 0.9580 test_loss: 0.8380, test_acc: 0.8177, best: 0.8240, time: 0:00:51
 Epoch: 211, lr: 2.0e-03, train_loss: 0.1277, train_acc: 0.9560 test_loss: 0.9001, test_acc: 0.8175, best: 0.8240, time: 0:00:51
 Epoch: 212, lr: 2.0e-03, train_loss: 0.1367, train_acc: 0.9568 test_loss: 0.9839, test_acc: 0.8129, best: 0.8240, time: 0:00:51
 Epoch: 213, lr: 2.0e-03, train_loss: 0.1309, train_acc: 0.9562 test_loss: 0.9364, test_acc: 0.8179, best: 0.8240, time: 0:00:50
 Epoch: 214, lr: 2.0e-03, train_loss: 0.1300, train_acc: 0.9576 test_loss: 1.3096, test_acc: 0.7911, best: 0.8240, time: 0:00:51
 Epoch: 215, lr: 2.0e-03, train_loss: 0.1307, train_acc: 0.9552 test_loss: 0.8597, test_acc: 0.8267, best: 0.8267, time: 0:00:51
 Epoch: 216, lr: 2.0e-03, train_loss: 0.1261, train_acc: 0.9590 test_loss: 0.9067, test_acc: 0.8199, best: 0.8267, time: 0:00:51
 Epoch: 217, lr: 2.0e-03, train_loss: 0.1223, train_acc: 0.9548 test_loss: 0.8843, test_acc: 0.8179, best: 0.8267, time: 0:00:51
 Epoch: 218, lr: 2.0e-03, train_loss: 0.1362, train_acc: 0.9554 test_loss: 1.1760, test_acc: 0.8047, best: 0.8267, time: 0:00:51
 Epoch: 219, lr: 2.0e-03, train_loss: 0.1312, train_acc: 0.9538 test_loss: 1.1746, test_acc: 0.8044, best: 0.8267, time: 0:00:51
 Epoch: 220, lr: 2.0e-03, train_loss: 0.1281, train_acc: 0.9580 test_loss: 0.8416, test_acc: 0.8227, best: 0.8267, time: 0:00:50
 Epoch: 221, lr: 2.0e-03, train_loss: 0.1276, train_acc: 0.9558 test_loss: 1.0337, test_acc: 0.8105, best: 0.8267, time: 0:00:51
 Epoch: 222, lr: 2.0e-03, train_loss: 0.1252, train_acc: 0.9602 test_loss: 1.1084, test_acc: 0.8096, best: 0.8267, time: 0:00:50
 Epoch: 223, lr: 2.0e-03, train_loss: 0.1297, train_acc: 0.9568 test_loss: 0.9570, test_acc: 0.8173, best: 0.8267, time: 0:00:50
 Epoch: 224, lr: 2.0e-03, train_loss: 0.1248, train_acc: 0.9606 test_loss: 0.9306, test_acc: 0.8190, best: 0.8267, time: 0:00:52
 Epoch: 225, lr: 2.0e-03, train_loss: 0.1315, train_acc: 0.9568 test_loss: 0.7964, test_acc: 0.8276, best: 0.8276, time: 0:00:51
 Epoch: 226, lr: 2.0e-03, train_loss: 0.1163, train_acc: 0.9610 test_loss: 0.9123, test_acc: 0.8225, best: 0.8276, time: 0:00:51
 Epoch: 227, lr: 2.0e-03, train_loss: 0.1165, train_acc: 0.9618 test_loss: 0.7441, test_acc: 0.8283, best: 0.8283, time: 0:00:51
 Epoch: 228, lr: 2.0e-03, train_loss: 0.1323, train_acc: 0.9544 test_loss: 0.8307, test_acc: 0.8200, best: 0.8283, time: 0:00:50
 Epoch: 229, lr: 2.0e-03, train_loss: 0.1163, train_acc: 0.9636 test_loss: 0.9436, test_acc: 0.8181, best: 0.8283, time: 0:00:50
 Epoch: 230, lr: 2.0e-03, train_loss: 0.1211, train_acc: 0.9592 test_loss: 0.9540, test_acc: 0.8161, best: 0.8283, time: 0:00:51
 Epoch: 231, lr: 2.0e-03, train_loss: 0.1331, train_acc: 0.9524 test_loss: 1.3020, test_acc: 0.7964, best: 0.8283, time: 0:00:51
 Epoch: 232, lr: 2.0e-03, train_loss: 0.1359, train_acc: 0.9554 test_loss: 0.8120, test_acc: 0.8244, best: 0.8283, time: 0:00:51
 Epoch: 233, lr: 2.0e-03, train_loss: 0.1224, train_acc: 0.9604 test_loss: 0.8022, test_acc: 0.8217, best: 0.8283, time: 0:00:50
 Epoch: 234, lr: 2.0e-03, train_loss: 0.1210, train_acc: 0.9594 test_loss: 0.7495, test_acc: 0.8203, best: 0.8283, time: 0:00:50
 Epoch: 235, lr: 2.0e-03, train_loss: 0.1187, train_acc: 0.9566 test_loss: 0.7485, test_acc: 0.8256, best: 0.8283, time: 0:00:51
 Epoch: 236, lr: 2.0e-03, train_loss: 0.1246, train_acc: 0.9572 test_loss: 1.3903, test_acc: 0.7939, best: 0.8283, time: 0:00:51
 Epoch: 237, lr: 2.0e-03, train_loss: 0.1198, train_acc: 0.9610 test_loss: 0.8610, test_acc: 0.8215, best: 0.8283, time: 0:00:50
 Epoch: 238, lr: 2.0e-03, train_loss: 0.1251, train_acc: 0.9576 test_loss: 0.8285, test_acc: 0.8223, best: 0.8283, time: 0:00:50
 Epoch: 239, lr: 2.0e-03, train_loss: 0.1162, train_acc: 0.9606 test_loss: 1.1680, test_acc: 0.8016, best: 0.8283, time: 0:00:50
 Epoch: 240, lr: 4.0e-04, train_loss: 0.1230, train_acc: 0.9576 test_loss: 0.7687, test_acc: 0.8277, best: 0.8283, time: 0:00:50
 Epoch: 241, lr: 4.0e-04, train_loss: 0.1210, train_acc: 0.9594 test_loss: 0.8600, test_acc: 0.8229, best: 0.8283, time: 0:00:51
 Epoch: 242, lr: 4.0e-04, train_loss: 0.1039, train_acc: 0.9664 test_loss: 0.7462, test_acc: 0.8267, best: 0.8283, time: 0:00:51
 Epoch: 243, lr: 4.0e-04, train_loss: 0.1182, train_acc: 0.9614 test_loss: 1.0507, test_acc: 0.8074, best: 0.8283, time: 0:00:50
 Epoch: 244, lr: 4.0e-04, train_loss: 0.0957, train_acc: 0.9660 test_loss: 1.2162, test_acc: 0.8051, best: 0.8283, time: 0:00:51
 Epoch: 245, lr: 4.0e-04, train_loss: 0.1177, train_acc: 0.9604 test_loss: 0.7558, test_acc: 0.8309, best: 0.8309, time: 0:00:51
 Epoch: 246, lr: 4.0e-04, train_loss: 0.1139, train_acc: 0.9650 test_loss: 1.2047, test_acc: 0.8037, best: 0.8309, time: 0:00:51
 Epoch: 247, lr: 4.0e-04, train_loss: 0.1085, train_acc: 0.9650 test_loss: 0.8354, test_acc: 0.8224, best: 0.8309, time: 0:00:51
 Epoch: 248, lr: 4.0e-04, train_loss: 0.1109, train_acc: 0.9640 test_loss: 0.8724, test_acc: 0.8200, best: 0.8309, time: 0:00:51
 Epoch: 249, lr: 4.0e-04, train_loss: 0.1134, train_acc: 0.9632 test_loss: 0.8973, test_acc: 0.8161, best: 0.8309, time: 0:00:51
 Epoch: 250, lr: 4.0e-04, train_loss: 0.1146, train_acc: 0.9626 test_loss: 1.1978, test_acc: 0.8019, best: 0.8309, time: 0:00:50
 Epoch: 251, lr: 4.0e-04, train_loss: 0.1221, train_acc: 0.9584 test_loss: 0.7861, test_acc: 0.8261, best: 0.8309, time: 0:00:51
 Epoch: 252, lr: 4.0e-04, train_loss: 0.1158, train_acc: 0.9616 test_loss: 0.7447, test_acc: 0.8296, best: 0.8309, time: 0:00:51
 Epoch: 253, lr: 4.0e-04, train_loss: 0.1240, train_acc: 0.9604 test_loss: 1.0200, test_acc: 0.8130, best: 0.8309, time: 0:00:50
 Epoch: 254, lr: 4.0e-04, train_loss: 0.1084, train_acc: 0.9632 test_loss: 0.7705, test_acc: 0.8275, best: 0.8309, time: 0:00:51
 Epoch: 255, lr: 4.0e-04, train_loss: 0.1104, train_acc: 0.9634 test_loss: 1.2445, test_acc: 0.8019, best: 0.8309, time: 0:00:51
 Epoch: 256, lr: 4.0e-04, train_loss: 0.1118, train_acc: 0.9628 test_loss: 1.1503, test_acc: 0.8039, best: 0.8309, time: 0:00:51
 Epoch: 257, lr: 4.0e-04, train_loss: 0.1106, train_acc: 0.9638 test_loss: 0.9848, test_acc: 0.8134, best: 0.8309, time: 0:00:51
 Epoch: 258, lr: 4.0e-04, train_loss: 0.1071, train_acc: 0.9646 test_loss: 0.9544, test_acc: 0.8134, best: 0.8309, time: 0:00:51
 Epoch: 259, lr: 4.0e-04, train_loss: 0.1097, train_acc: 0.9644 test_loss: 1.2037, test_acc: 0.8064, best: 0.8309, time: 0:00:50
 Epoch: 260, lr: 4.0e-04, train_loss: 0.1028, train_acc: 0.9654 test_loss: 0.8093, test_acc: 0.8285, best: 0.8309, time: 0:00:50
 Epoch: 261, lr: 4.0e-04, train_loss: 0.1295, train_acc: 0.9576 test_loss: 1.0299, test_acc: 0.8089, best: 0.8309, time: 0:00:51
 Epoch: 262, lr: 4.0e-04, train_loss: 0.1050, train_acc: 0.9648 test_loss: 1.0076, test_acc: 0.8115, best: 0.8309, time: 0:00:50
 Epoch: 263, lr: 4.0e-04, train_loss: 0.1072, train_acc: 0.9628 test_loss: 0.9792, test_acc: 0.8094, best: 0.8309, time: 0:00:52
 Epoch: 264, lr: 4.0e-04, train_loss: 0.1140, train_acc: 0.9622 test_loss: 0.9761, test_acc: 0.8134, best: 0.8309, time: 0:00:51
 Epoch: 265, lr: 4.0e-04, train_loss: 0.1110, train_acc: 0.9614 test_loss: 0.9555, test_acc: 0.8169, best: 0.8309, time: 0:00:51
 Epoch: 266, lr: 4.0e-04, train_loss: 0.1048, train_acc: 0.9638 test_loss: 0.7905, test_acc: 0.8236, best: 0.8309, time: 0:00:51
 Epoch: 267, lr: 4.0e-04, train_loss: 0.1089, train_acc: 0.9622 test_loss: 0.7628, test_acc: 0.8289, best: 0.8309, time: 0:00:51
 Epoch: 268, lr: 4.0e-04, train_loss: 0.1042, train_acc: 0.9656 test_loss: 1.1368, test_acc: 0.8014, best: 0.8309, time: 0:00:51
 Epoch: 269, lr: 4.0e-04, train_loss: 0.1098, train_acc: 0.9650 test_loss: 1.0754, test_acc: 0.8146, best: 0.8309, time: 0:00:50
 Epoch: 270, lr: 8.0e-05, train_loss: 0.1195, train_acc: 0.9618 test_loss: 0.8898, test_acc: 0.8196, best: 0.8309, time: 0:00:50
 Epoch: 271, lr: 8.0e-05, train_loss: 0.1132, train_acc: 0.9634 test_loss: 1.0909, test_acc: 0.8093, best: 0.8309, time: 0:00:51
 Epoch: 272, lr: 8.0e-05, train_loss: 0.1123, train_acc: 0.9646 test_loss: 0.8085, test_acc: 0.8217, best: 0.8309, time: 0:00:50
 Epoch: 273, lr: 8.0e-05, train_loss: 0.1138, train_acc: 0.9632 test_loss: 0.8007, test_acc: 0.8246, best: 0.8309, time: 0:00:50
 Epoch: 274, lr: 8.0e-05, train_loss: 0.1207, train_acc: 0.9594 test_loss: 0.9660, test_acc: 0.8136, best: 0.8309, time: 0:00:51
 Epoch: 275, lr: 8.0e-05, train_loss: 0.1057, train_acc: 0.9644 test_loss: 0.6836, test_acc: 0.8340, best: 0.8340, time: 0:00:50
 Epoch: 276, lr: 8.0e-05, train_loss: 0.1067, train_acc: 0.9642 test_loss: 0.9441, test_acc: 0.8149, best: 0.8340, time: 0:00:50
 Epoch: 277, lr: 8.0e-05, train_loss: 0.1126, train_acc: 0.9642 test_loss: 0.8124, test_acc: 0.8241, best: 0.8340, time: 0:00:50
 Epoch: 278, lr: 8.0e-05, train_loss: 0.1051, train_acc: 0.9684 test_loss: 0.7671, test_acc: 0.8270, best: 0.8340, time: 0:00:51
 Epoch: 279, lr: 8.0e-05, train_loss: 0.1033, train_acc: 0.9658 test_loss: 1.1386, test_acc: 0.8075, best: 0.8340, time: 0:00:50
 Epoch: 280, lr: 8.0e-05, train_loss: 0.1177, train_acc: 0.9612 test_loss: 0.7313, test_acc: 0.8295, best: 0.8340, time: 0:00:51
 Epoch: 281, lr: 8.0e-05, train_loss: 0.1104, train_acc: 0.9640 test_loss: 1.1396, test_acc: 0.8060, best: 0.8340, time: 0:00:50
 Epoch: 282, lr: 8.0e-05, train_loss: 0.0996, train_acc: 0.9666 test_loss: 0.7422, test_acc: 0.8279, best: 0.8340, time: 0:00:51
 Epoch: 283, lr: 8.0e-05, train_loss: 0.1146, train_acc: 0.9614 test_loss: 0.7697, test_acc: 0.8250, best: 0.8340, time: 0:00:52
 Epoch: 284, lr: 8.0e-05, train_loss: 0.1038, train_acc: 0.9654 test_loss: 0.9123, test_acc: 0.8186, best: 0.8340, time: 0:00:51
 Epoch: 285, lr: 8.0e-05, train_loss: 0.1142, train_acc: 0.9612 test_loss: 0.9081, test_acc: 0.8180, best: 0.8340, time: 0:00:50
 Epoch: 286, lr: 8.0e-05, train_loss: 0.1012, train_acc: 0.9682 test_loss: 0.7122, test_acc: 0.8304, best: 0.8340, time: 0:00:51
 Epoch: 287, lr: 8.0e-05, train_loss: 0.1100, train_acc: 0.9630 test_loss: 1.4506, test_acc: 0.7896, best: 0.8340, time: 0:00:51
 Epoch: 288, lr: 8.0e-05, train_loss: 0.1117, train_acc: 0.9630 test_loss: 1.1621, test_acc: 0.8036, best: 0.8340, time: 0:00:51
 Epoch: 289, lr: 8.0e-05, train_loss: 0.1151, train_acc: 0.9620 test_loss: 0.9064, test_acc: 0.8186, best: 0.8340, time: 0:00:51
 Epoch: 290, lr: 8.0e-05, train_loss: 0.1159, train_acc: 0.9600 test_loss: 0.7467, test_acc: 0.8304, best: 0.8340, time: 0:00:51
 Epoch: 291, lr: 8.0e-05, train_loss: 0.1151, train_acc: 0.9624 test_loss: 0.8778, test_acc: 0.8209, best: 0.8340, time: 0:00:50
 Epoch: 292, lr: 8.0e-05, train_loss: 0.1185, train_acc: 0.9618 test_loss: 0.7082, test_acc: 0.8330, best: 0.8340, time: 0:00:50
 Epoch: 293, lr: 8.0e-05, train_loss: 0.1176, train_acc: 0.9588 test_loss: 0.8934, test_acc: 0.8180, best: 0.8340, time: 0:00:51
 Epoch: 294, lr: 8.0e-05, train_loss: 0.1146, train_acc: 0.9600 test_loss: 0.7424, test_acc: 0.8295, best: 0.8340, time: 0:00:51
 Epoch: 295, lr: 8.0e-05, train_loss: 0.1126, train_acc: 0.9610 test_loss: 0.7965, test_acc: 0.8241, best: 0.8340, time: 0:00:51
 Epoch: 296, lr: 8.0e-05, train_loss: 0.1013, train_acc: 0.9676 test_loss: 0.7412, test_acc: 0.8266, best: 0.8340, time: 0:00:51
 Epoch: 297, lr: 8.0e-05, train_loss: 0.1098, train_acc: 0.9648 test_loss: 0.7398, test_acc: 0.8274, best: 0.8340, time: 0:00:51
 Epoch: 298, lr: 8.0e-05, train_loss: 0.1009, train_acc: 0.9668 test_loss: 0.7119, test_acc: 0.8327, best: 0.8340, time: 0:00:51
 Epoch: 299, lr: 8.0e-05, train_loss: 0.1083, train_acc: 0.9650 test_loss: 1.2285, test_acc: 0.8020, best: 0.8340, time: 0:00:50
 Highest accuracy: 0.8340