
 Run on time: 2022-07-13 00:04:23.006930

 Architecture: mobilenet_v2-nlpnoexp_headfix2_nowin-2222121

 Pool Config: {
    "arch": "mobilenet_v2",
    "conv1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer2": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer3": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer4": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer5": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": 2,
            "_conv2d": null,
            "_win_norm": false
        }
    },
    "layer6": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer7": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": 2,
            "_conv2d": null,
            "_win_norm": false
        }
    },
    "conv2": {
        "_conv2d": "norm",
        "pool_cfg": {}
    }
}

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : mobilenet_v2-nlpnoexp_headfix2_nowin-2222121
	 im_size              : 128
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): Network(
    (net): MobileNetV2(
      (conv1): Sequential(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (features): Sequential(
        (0): Sequential(
          (0): InvertedResidual(
            (pooling): Pool2d(
              (logit): Sequential(
                (pool_weight): NLP_BASE(
                  (downsample): Sequential(
                    (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): ReLU(inplace=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)
                  )
                  (restore): Sequential(
                    (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): Sigmoid()
                  )
                  (pos_embed): PositionEmbeddingLearned(
                    (row_embed): Embedding(256, 8)
                    (col_embed): Embedding(256, 8)
                  )
                )
              )
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            )
            (conv): Sequential(
              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): Sequential(
          (0): InvertedResidual(
            (pooling): Pool2d(
              (logit): Sequential(
                (pool_weight): NLP_BASE(
                  (downsample): Sequential(
                    (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): ReLU(inplace=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=24, out_features=24, bias=True)
                  )
                  (restore): Sequential(
                    (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): Sigmoid()
                  )
                  (pos_embed): PositionEmbeddingLearned(
                    (row_embed): Embedding(256, 12)
                    (col_embed): Embedding(256, 12)
                  )
                )
              )
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            )
            (conv): Sequential(
              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
              (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
              (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): Sequential(
          (0): InvertedResidual(
            (pooling): Pool2d(
              (logit): Sequential(
                (pool_weight): NLP_BASE(
                  (downsample): Sequential(
                    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): ReLU(inplace=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)
                  )
                  (restore): Sequential(
                    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): Sigmoid()
                  )
                  (pos_embed): PositionEmbeddingLearned(
                    (row_embed): Embedding(256, 16)
                    (col_embed): Embedding(256, 16)
                  )
                )
              )
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            )
            (conv): Sequential(
              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
              (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): Sequential(
          (0): InvertedResidual(
            (pooling): Pool2d(
              (logit): Sequential(
                (pool_weight): NLP_BASE(
                  (downsample): Sequential(
                    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): ReLU(inplace=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
                  )
                  (restore): Sequential(
                    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): Sigmoid()
                  )
                  (pos_embed): PositionEmbeddingLearned(
                    (row_embed): Embedding(256, 32)
                    (col_embed): Embedding(256, 32)
                  )
                )
              )
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            )
            (conv): Sequential(
              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (4): Sequential(
          (0): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (5): Sequential(
          (0): InvertedResidual(
            (pooling): Pool2d(
              (logit): Sequential(
                (pool_weight): NLP_BASE(
                  (downsample): Sequential(
                    (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): ReLU(inplace=True)
                  )
                  (multihead_attn): MultiheadAttention(
                    (out_proj): NonDynamicallyQuantizableLinear(in_features=160, out_features=160, bias=True)
                  )
                  (restore): Sequential(
                    (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))
                    (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                    (2): Sigmoid()
                  )
                  (pos_embed): PositionEmbeddingLearned(
                    (row_embed): Embedding(256, 80)
                    (col_embed): Embedding(256, 80)
                  )
                )
              )
              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
            )
            (conv): Sequential(
              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
              (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
              (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
              (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (6): Sequential(
          (0): InvertedResidual(
            (conv): Sequential(
              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU6(inplace=True)
              (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
              (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU6(inplace=True)
              (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
      )
      (conv2): Sequential(
        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (classifier): Linear(in_features=1280, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.6315, train_acc: 0.1578 test_loss: 2.0597, test_acc: 0.2396, best: 0.2396, time: 0:02:01
 Epoch: 2, lr: 1.0e-02, train_loss: 2.1689, train_acc: 0.1864 test_loss: 2.0572, test_acc: 0.2101, best: 0.2396, time: 0:02:01
 Epoch: 3, lr: 1.0e-02, train_loss: 2.1571, train_acc: 0.1750 test_loss: 1.9618, test_acc: 0.2555, best: 0.2555, time: 0:02:02
 Epoch: 4, lr: 1.0e-02, train_loss: 2.0937, train_acc: 0.2058 test_loss: 1.9332, test_acc: 0.2462, best: 0.2555, time: 0:02:02
 Epoch: 5, lr: 1.0e-02, train_loss: 2.0804, train_acc: 0.2170 test_loss: 1.9384, test_acc: 0.2729, best: 0.2729, time: 0:02:02
 Epoch: 6, lr: 1.0e-02, train_loss: 2.0740, train_acc: 0.2058 test_loss: 1.9396, test_acc: 0.2741, best: 0.2741, time: 0:02:02
 Epoch: 7, lr: 1.0e-02, train_loss: 2.0472, train_acc: 0.2300 test_loss: 1.8759, test_acc: 0.2884, best: 0.2884, time: 0:02:02
 Epoch: 8, lr: 1.0e-02, train_loss: 2.0262, train_acc: 0.2372 test_loss: 1.9105, test_acc: 0.2547, best: 0.2884, time: 0:02:02
 Epoch: 9, lr: 1.0e-02, train_loss: 2.0346, train_acc: 0.2324 test_loss: 1.8827, test_acc: 0.2772, best: 0.2884, time: 0:02:02
 Epoch: 10, lr: 1.0e-02, train_loss: 2.0049, train_acc: 0.2402 test_loss: 1.9114, test_acc: 0.2834, best: 0.2884, time: 0:02:02
 Epoch: 11, lr: 1.0e-02, train_loss: 2.0308, train_acc: 0.2362 test_loss: 1.8397, test_acc: 0.3120, best: 0.3120, time: 0:02:02
 Epoch: 12, lr: 1.0e-02, train_loss: 1.9645, train_acc: 0.2492 test_loss: 1.7893, test_acc: 0.2988, best: 0.3120, time: 0:02:02
 Epoch: 13, lr: 1.0e-02, train_loss: 2.0382, train_acc: 0.2330 test_loss: 1.8894, test_acc: 0.3121, best: 0.3121, time: 0:02:02
 Epoch: 14, lr: 1.0e-02, train_loss: 1.9912, train_acc: 0.2482 test_loss: 1.9245, test_acc: 0.2601, best: 0.3121, time: 0:02:02
 Epoch: 15, lr: 1.0e-02, train_loss: 1.9638, train_acc: 0.2528 test_loss: 1.7770, test_acc: 0.2978, best: 0.3121, time: 0:02:02
 Epoch: 16, lr: 1.0e-02, train_loss: 1.9229, train_acc: 0.2658 test_loss: 1.7323, test_acc: 0.3474, best: 0.3474, time: 0:02:02
 Epoch: 17, lr: 1.0e-02, train_loss: 1.9071, train_acc: 0.2742 test_loss: 1.7151, test_acc: 0.3371, best: 0.3474, time: 0:02:02
 Epoch: 18, lr: 1.0e-02, train_loss: 1.8804, train_acc: 0.2792