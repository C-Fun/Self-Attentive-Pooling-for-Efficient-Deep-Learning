
 Run on time: 2022-07-01 13:54:00.856406

 Architecture: prepool-gaussian_pool-4-resnet18-skip-1222

 Pool Config: {
    "arch": "resnet18",
    "conv1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "pool": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "gaussian_pool",
            "_stride": 4,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer2": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer3": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer4": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    }
}

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : PREPOOL-GAUSSIAN_POOL-4-RESNET18-SKIP-1222
	 im_size              : None
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): Network(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): GaussianPooling2d(
        kernel_size=4, stride=4, padding=0
        (ToHidden): Sequential(
          (0): AdaptiveAvgPool2d(output_size=(1, 1))
          (1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU()
        )
        (ToMean): Sequential(
          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (ToSigma): Sequential(
          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Sigmoid()
        )
        (activation): Softplus(beta=1, threshold=20)
      )
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3885, train_acc: 0.1860 test_loss: 1.8359, test_acc: 0.2700, best: 0.2700, time: 0:00:41
 Epoch: 2, lr: 1.0e-02, train_loss: 1.9756, train_acc: 0.2430 test_loss: 1.7598, test_acc: 0.3013, best: 0.3013, time: 0:00:42
 Epoch: 3, lr: 1.0e-02, train_loss: 1.8998, train_acc: 0.2712 test_loss: 1.7175, test_acc: 0.3239, best: 0.3239, time: 0:00:42
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8247, train_acc: 0.3066 test_loss: 1.6841, test_acc: 0.3535, best: 0.3535, time: 0:00:42
 Epoch: 5, lr: 1.0e-02, train_loss: 1.7932, train_acc: 0.3232 test_loss: 1.6052, test_acc: 0.3680, best: 0.3680, time: 0:00:42
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7448, train_acc: 0.3438 test_loss: 1.5627, test_acc: 0.3997, best: 0.3997, time: 0:00:42
 Epoch: 7, lr: 1.0e-02, train_loss: 1.7034, train_acc: 0.3640 test_loss: 1.6171, test_acc: 0.4148, best: 0.4148, time: 0:00:42
 Epoch: 8, lr: 1.0e-02, train_loss: 1.6638, train_acc: 0.3846 test_loss: 1.5149, test_acc: 0.4244, best: 0.4244, time: 0:00:42
 Epoch: 9, lr: 1.0e-02, train_loss: 1.6123, train_acc: 0.3980 test_loss: 1.4800, test_acc: 0.4387, best: 0.4387, time: 0:00:42
 Epoch: 10, lr: 1.0e-02, train_loss: 1.5742, train_acc: 0.4182 test_loss: 1.3886, test_acc: 0.4843, best: 0.4843, time: 0:00:42
 Epoch: 11, lr: 1.0e-02, train_loss: 1.5344, train_acc: 0.4362 test_loss: 1.4439, test_acc: 0.4659, best: 0.4843, time: 0:00:41
 Epoch: 12, lr: 1.0e-02, train_loss: 1.5131, train_acc: 0.4350 test_loss: 1.4928, test_acc: 0.4536, best: 0.4843, time: 0:00:41
 Epoch: 13, lr: 1.0e-02, train_loss: 1.4779, train_acc: 0.4490 test_loss: 1.3369, test_acc: 0.5031, best: 0.5031, time: 0:00:42
 Epoch: 14, lr: 1.0e-02, train_loss: 1.4334, train_acc: 0.4782 test_loss: 1.3074, test_acc: 0.5234, best: 0.5234, time: 0:00:42
 Epoch: 15, lr: 1.0e-02, train_loss: 1.4339, train_acc: 0.4818 test_loss: 1.2624, test_acc: 0.5376, best: 0.5376, time: 0:00:42
 Epoch: 16, lr: 1.0e-02, train_loss: 1.3876, train_acc: 0.4942 test_loss: 1.3930, test_acc: 0.5159, best: 0.5376, time: 0:00:41
 Epoch: 17, lr: 1.0e-02, train_loss: 1.3753, train_acc: 0.4926 test_loss: 1.2731, test_acc: 0.5250, best: 0.5376, time: 0:00:41
 Epoch: 18, lr: 1.0e-02, train_loss: 1.3568, train_acc: 0.5022 test_loss: 1.2564, test_acc: 0.5454, best: 0.5454, time: 0:00:42
 Epoch: 19, lr: 1.0e-02, train_loss: 1.3446, train_acc: 0.5106 test_loss: 1.1673, test_acc: 0.5710, best: 0.5710, time: 0:00:42
 Epoch: 20, lr: 1.0e-02, train_loss: 1.3072, train_acc: 0.5174 test_loss: 1.1816, test_acc: 0.5744, best: 0.5744, time: 0:00:42
 Epoch: 21, lr: 1.0e-02, train_loss: 1.2842, train_acc: 0.5226 test_loss: 1.1460, test_acc: 0.5821, best: 0.5821, time: 0:00:42
 Epoch: 22, lr: 1.0e-02, train_loss: 1.2788, train_acc: 0.5342 test_loss: 1.1013, test_acc: 0.6004, best: 0.6004, time: 0:00:42
 Epoch: 23, lr: 1.0e-02, train_loss: 1.2462, train_acc: 0.5526 test_loss: 1.1210, test_acc: 0.6012, best: 0.6012, time: 0:00:42
 Epoch: 24, lr: 1.0e-02, train_loss: 1.2372, train_acc: 0.5582 test_loss: 1.0867, test_acc: 0.6096, best: 0.6096, time: 0:00:42
 Epoch: 25, lr: 1.0e-02, train_loss: 1.2118, train_acc: 0.5600 test_loss: 1.1091, test_acc: 0.6028, best: 0.6096, time: 0:00:41
 Epoch: 26, lr: 1.0e-02, train_loss: 1.1807, train_acc: 0.5752 test_loss: 1.0361, test_acc: 0.6256, best: 0.6256, time: 0:00:42
 Epoch: 27, lr: 1.0e-02, train_loss: 1.1743, train_acc: 0.5734 test_loss: 1.0334, test_acc: 0.6178, best: 0.6256, time: 0:00:41
 Epoch: 28, lr: 1.0e-02, train_loss: 1.1526, train_acc: 0.5834 test_loss: 1.0743, test_acc: 0.6195, best: 0.6256, time: 0:00:41
 Epoch: 29, lr: 1.0e-02, train_loss: 1.1481, train_acc: 0.5768 test_loss: 1.0821, test_acc: 0.6146, best: 0.6256, time: 0:00:41
 Epoch: 30, lr: 1.0e-02, train_loss: 1.1277, train_acc: 0.5910 test_loss: 1.0405, test_acc: 0.6315, best: 0.6315, time: 0:00:42
 Epoch: 31, lr: 1.0e-02, train_loss: 1.1129, train_acc: 0.5956 test_loss: 1.0440, test_acc: 0.6275, best: 0.6315, time: 0:00:42
 Epoch: 32, lr: 1.0e-02, train_loss: 1.0978, train_acc: 0.6002 test_loss: 1.0688, test_acc: 0.6286, best: 0.6315, time: 0:00:41
 Epoch: 33, lr: 1.0e-02, train_loss: 1.0938, train_acc: 0.6026 test_loss: 1.0403, test_acc: 0.6334, best: 0.6334, time: 0:00:42
 Epoch: 34, lr: 1.0e-02, train_loss: 1.0628, train_acc: 0.6126 test_loss: 1.0054, test_acc: 0.6332, best: 0.6334, time: 0:00:41
 Epoch: 35, lr: 1.0e-02, train_loss: 1.0806, train_acc: 0.6122 test_loss: 0.9779, test_acc: 0.6519, best: 0.6519, time: 0:00:42
 Epoch: 36, lr: 1.0e-02, train_loss: 1.0636, train_acc: 0.6180 test_loss: 1.0690, test_acc: 0.6336, best: 0.6519, time: 0:00:41
 Epoch: 37, lr: 1.0e-02, train_loss: 1.0568, train_acc: 0.6148 test_loss: 0.9851, test_acc: 0.6522, best: 0.6522, time: 0:00:42
 Epoch: 38, lr: 1.0e-02, train_loss: 1.0223, train_acc: 0.6396 test_loss: 1.0656, test_acc: 0.6419, best: 0.6522, time: 0:00:41
 Epoch: 39, lr: 1.0e-02, train_loss: 1.0236, train_acc: 0.6320 test_loss: 1.0390, test_acc: 0.6428, best: 0.6522, time: 0:00:41
 Epoch: 40, lr: 1.0e-02, train_loss: 1.0126, train_acc: 0.6344 test_loss: 0.9556, test_acc: 0.6655, best: 0.6655, time: 0:00:42
 Epoch: 41, lr: 1.0e-02, train_loss: 0.9985, train_acc: 0.6428 test_loss: 0.9599, test_acc: 0.6736, best: 0.6736, time: 0:00:42
 Epoch: 42, lr: 1.0e-02, train_loss: 0.9834, train_acc: 0.6450 test_loss: 0.9808, test_acc: 0.6554, best: 0.6736, time: 0:00:41
 Epoch: 43, lr: 1.0e-02, train_loss: 0.9779, train_acc: 0.6438 test_loss: 0.9930, test_acc: 0.6491, best: 0.6736, time: 0:00:41
 Epoch: 44, lr: 1.0e-02, train_loss: 0.9592, train_acc: 0.6512 test_loss: 0.9363, test_acc: 0.6710, best: 0.6736, time: 0:00:41
 Epoch: 45, lr: 1.0e-02, train_loss: 0.9567, train_acc: 0.6516 test_loss: 1.0386, test_acc: 0.6359, best: 0.6736, time: 0:00:41
 Epoch: 46, lr: 1.0e-02, train_loss: 0.9463, train_acc: 0.6628 test_loss: 0.9818, test_acc: 0.6641, best: 0.6736, time: 0:00:41
 Epoch: 47, lr: 1.0e-02, train_loss: 0.9382, train_acc: 0.6648 test_loss: 1.0409, test_acc: 0.6472, best: 0.6736, time: 0:00:41
 Epoch: 48, lr: 1.0e-02, train_loss: 0.9050, train_acc: 0.6764 test_loss: 0.9804, test_acc: 0.6580, best: 0.6736, time: 0:00:41
 Epoch: 49, lr: 1.0e-02, train_loss: 0.9120, train_acc: 0.6734 test_loss: 0.9262, test_acc: 0.6804, best: 0.6804, time: 0:00:42
 Epoch: 50, lr: 1.0e-02, train_loss: 0.9204, train_acc: 0.6690 test_loss: 0.9680, test_acc: 0.6706, best: 0.6804, time: 0:00:41
 Epoch: 51, lr: 1.0e-02, train_loss: 0.8923, train_acc: 0.6738 test_loss: 0.9513, test_acc: 0.6751, best: 0.6804, time: 0:00:41
 Epoch: 52, lr: 1.0e-02, train_loss: 0.8863, train_acc: 0.6814 test_loss: 0.9110, test_acc: 0.6883, best: 0.6883, time: 0:00:42
 Epoch: 53, lr: 1.0e-02, train_loss: 0.8738, train_acc: 0.6870 test_loss: 0.9499, test_acc: 0.6791, best: 0.6883, time: 0:00:41
 Epoch: 54, lr: 1.0e-02, train_loss: 0.8564, train_acc: 0.6948 test_loss: 0.9321, test_acc: 0.6805, best: 0.6883, time: 0:00:41
 Epoch: 55, lr: 1.0e-02, train_loss: 0.8724, train_acc: 0.6804 test_loss: 0.9345, test_acc: 0.6936, best: 0.6936, time: 0:00:42
 Epoch: 56, lr: 1.0e-02, train_loss: 0.8665, train_acc: 0.6832 test_loss: 0.9613, test_acc: 0.6767, best: 0.6936, time: 0:00:41
 Epoch: 57, lr: 1.0e-02, train_loss: 0.8411, train_acc: 0.7034 test_loss: 1.0171, test_acc: 0.6606, best: 0.6936, time: 0:00:41
 Epoch: 58, lr: 1.0e-02, train_loss: 0.8391, train_acc: 0.6998 test_loss: 1.0234, test_acc: 0.6634, best: 0.6936, time: 0:00:41
 Epoch: 59, lr: 1.0e-02, train_loss: 0.8399, train_acc: 0.7026 test_loss: 0.9393, test_acc: 0.6843, best: 0.6936, time: 0:00:41
 Epoch: 60, lr: 1.0e-02, train_loss: 0.7895, train_acc: 0.7172 test_loss: 0.8577, test_acc: 0.7119, best: 0.7119, time: 0:00:42
 Epoch: 61, lr: 1.0e-02, train_loss: 0.8104, train_acc: 0.7120 test_loss: 0.9250, test_acc: 0.6797, best: 0.7119, time: 0:00:41
 Epoch: 62, lr: 1.0e-02, train_loss: 0.7985, train_acc: 0.7150 test_loss: 0.9687, test_acc: 0.6880, best: 0.7119, time: 0:00:41
 Epoch: 63, lr: 1.0e-02, train_loss: 0.7785, train_acc: 0.7142 test_loss: 0.9501, test_acc: 0.6937, best: 0.7119, time: 0:00:41
 Epoch: 64, lr: 1.0e-02, train_loss: 0.8046, train_acc: 0.7108 test_loss: 0.9043, test_acc: 0.6946, best: 0.7119, time: 0:00:41
 Epoch: 65, lr: 1.0e-02, train_loss: 0.7668, train_acc: 0.7250 test_loss: 0.8335, test_acc: 0.7097, best: 0.7119, time: 0:00:41
 Epoch: 66, lr: 1.0e-02, train_loss: 0.7695, train_acc: 0.7186 test_loss: 0.9154, test_acc: 0.6961, best: 0.7119, time: 0:00:41
 Epoch: 67, lr: 1.0e-02, train_loss: 0.7769, train_acc: 0.7204 test_loss: 0.8836, test_acc: 0.7103, best: 0.7119, time: 0:00:41
 Epoch: 68, lr: 1.0e-02, train_loss: 0.7388, train_acc: 0.7340 test_loss: 0.8695, test_acc: 0.7104, best: 0.7119, time: 0:00:41
 Epoch: 69, lr: 1.0e-02, train_loss: 0.7533, train_acc: 0.7340 test_loss: 0.8602, test_acc: 0.7055, best: 0.7119, time: 0:00:41
 Epoch: 70, lr: 1.0e-02, train_loss: 0.7331, train_acc: 0.7432 test_loss: 0.9406, test_acc: 0.6944, best: 0.7119, time: 0:00:41
 Epoch: 71, lr: 1.0e-02, train_loss: 0.7332, train_acc: 0.7458 test_loss: 0.8746, test_acc: 0.7087, best: 0.7119, time: 0:00:41
 Epoch: 72, lr: 1.0e-02, train_loss: 0.7170, train_acc: 0.7448 test_loss: 0.9395, test_acc: 0.6914, best: 0.7119, time: 0:00:41
 Epoch: 73, lr: 1.0e-02, train_loss: 0.7248, train_acc: 0.7474 test_loss: 0.8371, test_acc: 0.7189, best: 0.7189, time: 0:00:42
 Epoch: 74, lr: 1.0e-02, train_loss: 0.7278, train_acc: 0.7446 test_loss: 0.9527, test_acc: 0.6959, best: 0.7189, time: 0:00:41
 Epoch: 75, lr: 1.0e-02, train_loss: 0.7071, train_acc: 0.7462 test_loss: 0.8414, test_acc: 0.7224, best: 0.7224, time: 0:00:42
 Epoch: 76, lr: 1.0e-02, train_loss: 0.7201, train_acc: 0.7422 test_loss: 0.9413, test_acc: 0.6969, best: 0.7224, time: 0:00:41
 Epoch: 77, lr: 1.0e-02, train_loss: 0.7092, train_acc: 0.7468 test_loss: 0.8703, test_acc: 0.7134, best: 0.7224, time: 0:00:41
 Epoch: 78, lr: 1.0e-02, train_loss: 0.7021, train_acc: 0.7454 test_loss: 0.8350, test_acc: 0.7183, best: 0.7224, time: 0:00:41
 Epoch: 79, lr: 1.0e-02, train_loss: 0.6822, train_acc: 0.7498 test_loss: 0.8282, test_acc: 0.7225, best: 0.7225, time: 0:00:42
 Epoch: 80, lr: 1.0e-02, train_loss: 0.6739, train_acc: 0.7622 test_loss: 0.9940, test_acc: 0.6924, best: 0.7225, time: 0:00:41
 Epoch: 81, lr: 1.0e-02, train_loss: 0.6930, train_acc: 0.7526 test_loss: 1.0138, test_acc: 0.6933, best: 0.7225, time: 0:00:41
 Epoch: 82, lr: 1.0e-02, train_loss: 0.6713, train_acc: 0.7626 test_loss: 0.8684, test_acc: 0.7191, best: 0.7225, time: 0:00:41
 Epoch: 83, lr: 1.0e-02, train_loss: 0.6844, train_acc: 0.7586 test_loss: 0.8545, test_acc: 0.7171, best: 0.7225, time: 0:00:41
 Epoch: 84, lr: 1.0e-02, train_loss: 0.6651, train_acc: 0.7646 test_loss: 0.8684, test_acc: 0.7165, best: 0.7225, time: 0:00:41
 Epoch: 85, lr: 1.0e-02, train_loss: 0.6531, train_acc: 0.7676 test_loss: 0.9895, test_acc: 0.7070, best: 0.7225, time: 0:00:41
 Epoch: 86, lr: 1.0e-02, train_loss: 0.6648, train_acc: 0.7602 test_loss: 0.8240, test_acc: 0.7345, best: 0.7345, time: 0:00:42
 Epoch: 87, lr: 1.0e-02, train_loss: 0.6297, train_acc: 0.7774 test_loss: 0.9435, test_acc: 0.7196, best: 0.7345, time: 0:00:41
 Epoch: 88, lr: 1.0e-02, train_loss: 0.6556, train_acc: 0.7726 test_loss: 0.8602, test_acc: 0.7244, best: 0.7345, time: 0:00:41
 Epoch: 89, lr: 1.0e-02, train_loss: 0.6185, train_acc: 0.7744 test_loss: 0.8844, test_acc: 0.7176, best: 0.7345, time: 0:00:41
 Epoch: 90, lr: 1.0e-02, train_loss: 0.6274, train_acc: 0.7840 test_loss: 0.8355, test_acc: 0.7328, best: 0.7345, time: 0:00:41
 Epoch: 91, lr: 1.0e-02, train_loss: 0.6299, train_acc: 0.7784 test_loss: 0.8478, test_acc: 0.7290, best: 0.7345, time: 0:00:41
 Epoch: 92, lr: 1.0e-02, train_loss: 0.6408, train_acc: 0.7678 test_loss: 0.9076, test_acc: 0.7188, best: 0.7345, time: 0:00:41
 Epoch: 93, lr: 1.0e-02, train_loss: 0.6155, train_acc: 0.7782 test_loss: 0.9449, test_acc: 0.7097, best: 0.7345, time: 0:00:41
 Epoch: 94, lr: 1.0e-02, train_loss: 0.6229, train_acc: 0.7838 test_loss: 0.9338, test_acc: 0.7125, best: 0.7345, time: 0:00:41
 Epoch: 95, lr: 1.0e-02, train_loss: 0.6129, train_acc: 0.7840 test_loss: 0.9646, test_acc: 0.7274, best: 0.7345, time: 0:00:41
 Epoch: 96, lr: 1.0e-02, train_loss: 0.5844, train_acc: 0.7974 test_loss: 0.9072, test_acc: 0.7218, best: 0.7345, time: 0:00:41
 Epoch: 97, lr: 1.0e-02, train_loss: 0.5831, train_acc: 0.7978 test_loss: 0.8788, test_acc: 0.7225, best: 0.7345, time: 0:00:41
 Epoch: 98, lr: 1.0e-02, train_loss: 0.5879, train_acc: 0.7890 test_loss: 0.9407, test_acc: 0.7232, best: 0.7345, time: 0:00:41
 Epoch: 99, lr: 1.0e-02, train_loss: 0.5957, train_acc: 0.7854 test_loss: 0.9687, test_acc: 0.7124, best: 0.7345, time: 0:00:41
 Epoch: 100, lr: 1.0e-02, train_loss: 0.6017, train_acc: 0.7900 test_loss: 0.9199, test_acc: 0.7306, best: 0.7345, time: 0:00:41
 Epoch: 101, lr: 1.0e-02, train_loss: 0.5748, train_acc: 0.7978 test_loss: 0.8902, test_acc: 0.7322, best: 0.7345, time: 0:00:41
 Epoch: 102, lr: 1.0e-02, train_loss: 0.5504, train_acc: 0.8062 test_loss: 0.9699, test_acc: 0.7238, best: 0.7345, time: 0:00:41
 Epoch: 103, lr: 1.0e-02, train_loss: 0.5716, train_acc: 0.8010 test_loss: 0.8573, test_acc: 0.7381, best: 0.7381, time: 0:00:42
 Epoch: 104, lr: 1.0e-02, train_loss: 0.5870, train_acc: 0.7954 test_loss: 0.9203, test_acc: 0.7271, best: 0.7381, time: 0:00:41
 Epoch: 105, lr: 1.0e-02, train_loss: 0.5651, train_acc: 0.7944 test_loss: 0.9083, test_acc: 0.7349, best: 0.7381, time: 0:00:41
 Epoch: 106, lr: 1.0e-02, train_loss: 0.5565, train_acc: 0.8008 test_loss: 0.9377, test_acc: 0.7305, best: 0.7381, time: 0:00:41
 Epoch: 107, lr: 1.0e-02, train_loss: 0.5308, train_acc: 0.8098 test_loss: 0.9389, test_acc: 0.7245, best: 0.7381, time: 0:00:41
 Epoch: 108, lr: 1.0e-02, train_loss: 0.5598, train_acc: 0.8058 test_loss: 0.9020, test_acc: 0.7389, best: 0.7389, time: 0:00:42
 Epoch: 109, lr: 1.0e-02, train_loss: 0.5440, train_acc: 0.8176 test_loss: 0.9122, test_acc: 0.7264, best: 0.7389, time: 0:00:41
 Epoch: 110, lr: 1.0e-02, train_loss: 0.5375, train_acc: 0.8082 test_loss: 0.9600, test_acc: 0.7224, best: 0.7389, time: 0:00:41
 Epoch: 111, lr: 1.0e-02, train_loss: 0.5542, train_acc: 0.7994 test_loss: 0.8893, test_acc: 0.7362, best: 0.7389, time: 0:00:41
 Epoch: 112, lr: 1.0e-02, train_loss: 0.5419, train_acc: 0.8130 test_loss: 0.9776, test_acc: 0.7266, best: 0.7389, time: 0:00:41
 Epoch: 113, lr: 1.0e-02, train_loss: 0.5172, train_acc: 0.8194 test_loss: 0.9173, test_acc: 0.7346, best: 0.7389, time: 0:00:41
 Epoch: 114, lr: 1.0e-02, train_loss: 0.5294, train_acc: 0.8168 test_loss: 0.9444, test_acc: 0.7351, best: 0.7389, time: 0:00:41
 Epoch: 115, lr: 1.0e-02, train_loss: 0.5391, train_acc: 0.8084 test_loss: 0.9272, test_acc: 0.7326, best: 0.7389, time: 0:00:42
 Epoch: 116, lr: 1.0e-02, train_loss: 0.5403, train_acc: 0.8132 test_loss: 0.9498, test_acc: 0.7268, best: 0.7389, time: 0:00:41
 Epoch: 117, lr: 1.0e-02, train_loss: 0.5207, train_acc: 0.8198 test_loss: 0.9418, test_acc: 0.7268, best: 0.7389, time: 0:00:41
 Epoch: 118, lr: 1.0e-02, train_loss: 0.5233, train_acc: 0.8184 test_loss: 1.0865, test_acc: 0.7110, best: 0.7389, time: 0:00:41
 Epoch: 119, lr: 1.0e-02, train_loss: 0.5252, train_acc: 0.8134 test_loss: 0.9462, test_acc: 0.7310, best: 0.7389, time: 0:00:41
 Epoch: 120, lr: 1.0e-02, train_loss: 0.5002, train_acc: 0.8226 test_loss: 0.8986, test_acc: 0.7368, best: 0.7389, time: 0:00:41
 Epoch: 121, lr: 1.0e-02, train_loss: 0.5004, train_acc: 0.8316 test_loss: 0.9129, test_acc: 0.7414, best: 0.7414, time: 0:00:41
 Epoch: 122, lr: 1.0e-02, train_loss: 0.4791, train_acc: 0.8340 test_loss: 0.9718, test_acc: 0.7295, best: 0.7414, time: 0:00:41
 Epoch: 123, lr: 1.0e-02, train_loss: 0.5082, train_acc: 0.8228 test_loss: 0.9573, test_acc: 0.7410, best: 0.7414, time: 0:00:41
 Epoch: 124, lr: 1.0e-02, train_loss: 0.5089, train_acc: 0.8244 test_loss: 0.9251, test_acc: 0.7388, best: 0.7414, time: 0:00:41
 Epoch: 125, lr: 1.0e-02, train_loss: 0.4826, train_acc: 0.8248 test_loss: 1.0136, test_acc: 0.7242, best: 0.7414, time: 0:00:41
 Epoch: 126, lr: 1.0e-02, train_loss: 0.4896, train_acc: 0.8272 test_loss: 0.9331, test_acc: 0.7461, best: 0.7461, time: 0:00:41
 Epoch: 127, lr: 1.0e-02, train_loss: 0.4765, train_acc: 0.8300 test_loss: 0.9585, test_acc: 0.7396, best: 0.7461, time: 0:00:41
 Epoch: 128, lr: 1.0e-02, train_loss: 0.4741, train_acc: 0.8332 test_loss: 0.9229, test_acc: 0.7468, best: 0.7468, time: 0:00:41
 Epoch: 129, lr: 1.0e-02, train_loss: 0.5067, train_acc: 0.8224 test_loss: 0.8992, test_acc: 0.7548, best: 0.7548, time: 0:00:41
 Epoch: 130, lr: 1.0e-02, train_loss: 0.4966, train_acc: 0.8272 test_loss: 0.8763, test_acc: 0.7486, best: 0.7548, time: 0:00:41
 Epoch: 131, lr: 1.0e-02, train_loss: 0.4879, train_acc: 0.8306 test_loss: 0.9488, test_acc: 0.7415, best: 0.7548, time: 0:00:41
 Epoch: 132, lr: 1.0e-02, train_loss: 0.4646, train_acc: 0.8396 test_loss: 0.9853, test_acc: 0.7190, best: 0.7548, time: 0:00:41
 Epoch: 133, lr: 1.0e-02, train_loss: 0.4494, train_acc: 0.8380 test_loss: 0.9682, test_acc: 0.7380, best: 0.7548, time: 0:00:41
 Epoch: 134, lr: 1.0e-02, train_loss: 0.4771, train_acc: 0.8338 test_loss: 0.9719, test_acc: 0.7421, best: 0.7548, time: 0:00:41
 Epoch: 135, lr: 1.0e-02, train_loss: 0.4835, train_acc: 0.8376 test_loss: 0.9551, test_acc: 0.7398, best: 0.7548, time: 0:00:41
 Epoch: 136, lr: 1.0e-02, train_loss: 0.4746, train_acc: 0.8354 test_loss: 0.8926, test_acc: 0.7529, best: 0.7548, time: 0:00:41
 Epoch: 137, lr: 1.0e-02, train_loss: 0.4646, train_acc: 0.8458 test_loss: 0.9230, test_acc: 0.7471, best: 0.7548, time: 0:00:41
 Epoch: 138, lr: 1.0e-02, train_loss: 0.4651, train_acc: 0.8342 test_loss: 0.9378, test_acc: 0.7279, best: 0.7548, time: 0:00:41
 Epoch: 139, lr: 1.0e-02, train_loss: 0.4537, train_acc: 0.8480 test_loss: 0.9845, test_acc: 0.7436, best: 0.7548, time: 0:00:41
 Epoch: 140, lr: 1.0e-02, train_loss: 0.4619, train_acc: 0.8400 test_loss: 1.0207, test_acc: 0.7331, best: 0.7548, time: 0:00:41
 Epoch: 141, lr: 1.0e-02, train_loss: 0.4529, train_acc: 0.8466 test_loss: 0.9947, test_acc: 0.7348, best: 0.7548, time: 0:00:41
 Epoch: 142, lr: 1.0e-02, train_loss: 0.4647, train_acc: 0.8404 test_loss: 0.9645, test_acc: 0.7356, best: 0.7548, time: 0:00:41
 Epoch: 143, lr: 1.0e-02, train_loss: 0.4515, train_acc: 0.8406 test_loss: 0.9306, test_acc: 0.7535, best: 0.7548, time: 0:00:41
 Epoch: 144, lr: 1.0e-02, train_loss: 0.4543, train_acc: 0.8416 test_loss: 0.9114, test_acc: 0.7534, best: 0.7548, time: 0:00:41
 Epoch: 145, lr: 1.0e-02, train_loss: 0.4575, train_acc: 0.8410 test_loss: 0.9444, test_acc: 0.7446, best: 0.7548, time: 0:00:41
 Epoch: 146, lr: 1.0e-02, train_loss: 0.4558, train_acc: 0.8446 test_loss: 0.9300, test_acc: 0.7510, best: 0.7548, time: 0:00:41
 Epoch: 147, lr: 1.0e-02, train_loss: 0.4269, train_acc: 0.8502 test_loss: 0.9848, test_acc: 0.7429, best: 0.7548, time: 0:00:41
 Epoch: 148, lr: 1.0e-02, train_loss: 0.4212, train_acc: 0.8518 test_loss: 0.9940, test_acc: 0.7504, best: 0.7548, time: 0:00:41
 Epoch: 149, lr: 1.0e-02, train_loss: 0.4608, train_acc: 0.8462 test_loss: 0.8706, test_acc: 0.7591, best: 0.7591, time: 0:00:41
 Epoch: 150, lr: 1.0e-02, train_loss: 0.4150, train_acc: 0.8558 test_loss: 1.1404, test_acc: 0.7212, best: 0.7591, time: 0:00:41
 Epoch: 151, lr: 1.0e-02, train_loss: 0.4230, train_acc: 0.8528 test_loss: 1.1084, test_acc: 0.7351, best: 0.7591, time: 0:00:41
 Epoch: 152, lr: 1.0e-02, train_loss: 0.4447, train_acc: 0.8474 test_loss: 1.0158, test_acc: 0.7290, best: 0.7591, time: 0:00:41
 Epoch: 153, lr: 1.0e-02, train_loss: 0.4348, train_acc: 0.8472 test_loss: 1.0410, test_acc: 0.7341, best: 0.7591, time: 0:00:41
 Epoch: 154, lr: 1.0e-02, train_loss: 0.4185, train_acc: 0.8554 test_loss: 0.9673, test_acc: 0.7476, best: 0.7591, time: 0:00:41
 Epoch: 155, lr: 1.0e-02, train_loss: 0.4380, train_acc: 0.8528 test_loss: 0.9382, test_acc: 0.7510, best: 0.7591, time: 0:00:41
 Epoch: 156, lr: 1.0e-02, train_loss: 0.4344, train_acc: 0.8496 test_loss: 0.9291, test_acc: 0.7452, best: 0.7591, time: 0:00:41
 Epoch: 157, lr: 1.0e-02, train_loss: 0.4037, train_acc: 0.8592 test_loss: 0.9665, test_acc: 0.7481, best: 0.7591, time: 0:00:41
 Epoch: 158, lr: 1.0e-02, train_loss: 0.4183, train_acc: 0.8548 test_loss: 1.0601, test_acc: 0.7351, best: 0.7591, time: 0:00:41
 Epoch: 159, lr: 1.0e-02, train_loss: 0.4079, train_acc: 0.8618 test_loss: 1.0068, test_acc: 0.7415, best: 0.7591, time: 0:00:41
 Epoch: 160, lr: 1.0e-02, train_loss: 0.4146, train_acc: 0.8556 test_loss: 0.9669, test_acc: 0.7501, best: 0.7591, time: 0:00:41
 Epoch: 161, lr: 1.0e-02, train_loss: 0.4173, train_acc: 0.8598 test_loss: 0.9314, test_acc: 0.7490, best: 0.7591, time: 0:00:41
 Epoch: 162, lr: 1.0e-02, train_loss: 0.4136, train_acc: 0.8572 test_loss: 0.9070, test_acc: 0.7548, best: 0.7591, time: 0:00:41
 Epoch: 163, lr: 1.0e-02, train_loss: 0.4151, train_acc: 0.8544 test_loss: 0.9604, test_acc: 0.7514, best: 0.7591, time: 0:00:41
 Epoch: 164, lr: 1.0e-02, train_loss: 0.3974, train_acc: 0.8628 test_loss: 0.9786, test_acc: 0.7550, best: 0.7591, time: 0:00:41
 Epoch: 165, lr: 1.0e-02, train_loss: 0.3934, train_acc: 0.8610 test_loss: 1.0180, test_acc: 0.7455, best: 0.7591, time: 0:00:41
 Epoch: 166, lr: 1.0e-02, train_loss: 0.3757, train_acc: 0.8734 test_loss: 1.0772, test_acc: 0.7338, best: 0.7591, time: 0:00:41
 Epoch: 167, lr: 1.0e-02, train_loss: 0.3898, train_acc: 0.8690 test_loss: 1.0362, test_acc: 0.7361, best: 0.7591, time: 0:00:41
 Epoch: 168, lr: 1.0e-02, train_loss: 0.3917, train_acc: 0.8670 test_loss: 1.0010, test_acc: 0.7470, best: 0.7591, time: 0:00:41
 Epoch: 169, lr: 1.0e-02, train_loss: 0.3799, train_acc: 0.8678 test_loss: 1.1033, test_acc: 0.7441, best: 0.7591, time: 0:00:41
 Epoch: 170, lr: 1.0e-02, train_loss: 0.4028, train_acc: 0.8610 test_loss: 1.0405, test_acc: 0.7358, best: 0.7591, time: 0:00:41
 Epoch: 171, lr: 1.0e-02, train_loss: 0.3875, train_acc: 0.8662 test_loss: 0.9801, test_acc: 0.7474, best: 0.7591, time: 0:00:41
 Epoch: 172, lr: 1.0e-02, train_loss: 0.3883, train_acc: 0.8664 test_loss: 0.9933, test_acc: 0.7478, best: 0.7591, time: 0:00:41
 Epoch: 173, lr: 1.0e-02, train_loss: 0.3837, train_acc: 0.8622 test_loss: 0.9249, test_acc: 0.7512, best: 0.7591, time: 0:00:41
 Epoch: 174, lr: 1.0e-02, train_loss: 0.3877, train_acc: 0.8648 test_loss: 1.0303, test_acc: 0.7389, best: 0.7591, time: 0:00:41
 Epoch: 175, lr: 1.0e-02, train_loss: 0.3948, train_acc: 0.8602 test_loss: 0.8992, test_acc: 0.7645, best: 0.7645, time: 0:00:41
 Epoch: 176, lr: 1.0e-02, train_loss: 0.3816, train_acc: 0.8714 test_loss: 0.9502, test_acc: 0.7570, best: 0.7645, time: 0:00:41
 Epoch: 177, lr: 1.0e-02, train_loss: 0.3847, train_acc: 0.8682 test_loss: 0.9729, test_acc: 0.7602, best: 0.7645, time: 0:00:41
 Epoch: 178, lr: 1.0e-02, train_loss: 0.3897, train_acc: 0.8674 test_loss: 0.9184, test_acc: 0.7614, best: 0.7645, time: 0:00:41
 Epoch: 179, lr: 1.0e-02, train_loss: 0.3639, train_acc: 0.8754 test_loss: 1.0526, test_acc: 0.7438, best: 0.7645, time: 0:00:41
 Epoch: 180, lr: 2.0e-03, train_loss: 0.3256, train_acc: 0.8886 test_loss: 0.8979, test_acc: 0.7710, best: 0.7710, time: 0:00:41
 Epoch: 181, lr: 2.0e-03, train_loss: 0.3036, train_acc: 0.8930 test_loss: 0.8920, test_acc: 0.7728, best: 0.7728, time: 0:00:41
 Epoch: 182, lr: 2.0e-03, train_loss: 0.3117, train_acc: 0.8954 test_loss: 0.8936, test_acc: 0.7775, best: 0.7775, time: 0:00:41
 Epoch: 183, lr: 2.0e-03, train_loss: 0.3008, train_acc: 0.8948 test_loss: 0.8789, test_acc: 0.7782, best: 0.7782, time: 0:00:41
 Epoch: 184, lr: 2.0e-03, train_loss: 0.3042, train_acc: 0.8990 test_loss: 0.8817, test_acc: 0.7712, best: 0.7782, time: 0:00:41
 Epoch: 185, lr: 2.0e-03, train_loss: 0.2858, train_acc: 0.9024 test_loss: 0.8845, test_acc: 0.7749, best: 0.7782, time: 0:00:41
 Epoch: 186, lr: 2.0e-03, train_loss: 0.2888, train_acc: 0.8998 test_loss: 0.8932, test_acc: 0.7755, best: 0.7782, time: 0:00:41
 Epoch: 187, lr: 2.0e-03, train_loss: 0.2990, train_acc: 0.8982 test_loss: 0.9030, test_acc: 0.7708, best: 0.7782, time: 0:00:41
 Epoch: 188, lr: 2.0e-03, train_loss: 0.2827, train_acc: 0.9054 test_loss: 0.8914, test_acc: 0.7779, best: 0.7782, time: 0:00:41
 Epoch: 189, lr: 2.0e-03, train_loss: 0.2748, train_acc: 0.9042 test_loss: 0.8972, test_acc: 0.7774, best: 0.7782, time: 0:00:41
 Epoch: 190, lr: 2.0e-03, train_loss: 0.2778, train_acc: 0.9044 test_loss: 0.8976, test_acc: 0.7740, best: 0.7782, time: 0:00:41
 Epoch: 191, lr: 2.0e-03, train_loss: 0.2785, train_acc: 0.9044 test_loss: 0.8747, test_acc: 0.7792, best: 0.7792, time: 0:00:41
 Epoch: 192, lr: 2.0e-03, train_loss: 0.2791, train_acc: 0.9040 test_loss: 0.9232, test_acc: 0.7688, best: 0.7792, time: 0:00:41
 Epoch: 193, lr: 2.0e-03, train_loss: 0.2714, train_acc: 0.9056 test_loss: 0.9051, test_acc: 0.7708, best: 0.7792, time: 0:00:41
 Epoch: 194, lr: 2.0e-03, train_loss: 0.2690, train_acc: 0.9102 test_loss: 0.8962, test_acc: 0.7748, best: 0.7792, time: 0:00:41
 Epoch: 195, lr: 2.0e-03, train_loss: 0.2627, train_acc: 0.9074 test_loss: 0.8768, test_acc: 0.7780, best: 0.7792, time: 0:00:41
 Epoch: 196, lr: 2.0e-03, train_loss: 0.2694, train_acc: 0.9060 test_loss: 0.9094, test_acc: 0.7794, best: 0.7794, time: 0:00:41
 Epoch: 197, lr: 2.0e-03, train_loss: 0.2562, train_acc: 0.9116 test_loss: 0.8842, test_acc: 0.7779, best: 0.7794, time: 0:00:41
 Epoch: 198, lr: 2.0e-03, train_loss: 0.2685, train_acc: 0.9066 test_loss: 0.8766, test_acc: 0.7775, best: 0.7794, time: 0:00:41
 Epoch: 199, lr: 2.0e-03, train_loss: 0.2625, train_acc: 0.9066 test_loss: 0.8989, test_acc: 0.7762, best: 0.7794, time: 0:00:41
 Epoch: 200, lr: 2.0e-03, train_loss: 0.2667, train_acc: 0.9086 test_loss: 0.9103, test_acc: 0.7754, best: 0.7794, time: 0:00:41
 Epoch: 201, lr: 2.0e-03, train_loss: 0.2541, train_acc: 0.9126 test_loss: 0.8857, test_acc: 0.7782, best: 0.7794, time: 0:00:41
 Epoch: 202, lr: 2.0e-03, train_loss: 0.2591, train_acc: 0.9130 test_loss: 0.9210, test_acc: 0.7745, best: 0.7794, time: 0:00:41
 Epoch: 203, lr: 2.0e-03, train_loss: 0.2603, train_acc: 0.9092 test_loss: 0.9165, test_acc: 0.7776, best: 0.7794, time: 0:00:41
 Epoch: 204, lr: 2.0e-03, train_loss: 0.2580, train_acc: 0.9088 test_loss: 0.9455, test_acc: 0.7771, best: 0.7794, time: 0:00:41
 Epoch: 205, lr: 2.0e-03, train_loss: 0.2602, train_acc: 0.9144 test_loss: 0.8972, test_acc: 0.7831, best: 0.7831, time: 0:00:41
 Epoch: 206, lr: 2.0e-03, train_loss: 0.2633, train_acc: 0.9106 test_loss: 0.9126, test_acc: 0.7745, best: 0.7831, time: 0:00:41
 Epoch: 207, lr: 2.0e-03, train_loss: 0.2581, train_acc: 0.9158 test_loss: 0.9090, test_acc: 0.7760, best: 0.7831, time: 0:00:41
 Epoch: 208, lr: 2.0e-03, train_loss: 0.2611, train_acc: 0.9094 test_loss: 0.9176, test_acc: 0.7769, best: 0.7831, time: 0:00:41
 Epoch: 209, lr: 2.0e-03, train_loss: 0.2599, train_acc: 0.9118 test_loss: 0.9207, test_acc: 0.7730, best: 0.7831, time: 0:00:41
 Epoch: 210, lr: 2.0e-03, train_loss: 0.2602, train_acc: 0.9138 test_loss: 0.9071, test_acc: 0.7784, best: 0.7831, time: 0:00:41
 Epoch: 211, lr: 2.0e-03, train_loss: 0.2578, train_acc: 0.9086 test_loss: 0.9153, test_acc: 0.7749, best: 0.7831, time: 0:00:41
 Epoch: 212, lr: 2.0e-03, train_loss: 0.2519, train_acc: 0.9168 test_loss: 0.9157, test_acc: 0.7759, best: 0.7831, time: 0:00:41
 Epoch: 213, lr: 2.0e-03, train_loss: 0.2586, train_acc: 0.9100 test_loss: 0.9392, test_acc: 0.7740, best: 0.7831, time: 0:00:41
 Epoch: 214, lr: 2.0e-03, train_loss: 0.2566, train_acc: 0.9130 test_loss: 0.9422, test_acc: 0.7688, best: 0.7831, time: 0:00:41
 Epoch: 215, lr: 2.0e-03, train_loss: 0.2603, train_acc: 0.9112 test_loss: 0.9635, test_acc: 0.7702, best: 0.7831, time: 0:00:41
 Epoch: 216, lr: 2.0e-03, train_loss: 0.2630, train_acc: 0.9092 test_loss: 0.9148, test_acc: 0.7750, best: 0.7831, time: 0:00:41
 Epoch: 217, lr: 2.0e-03, train_loss: 0.2319, train_acc: 0.9202 test_loss: 0.9288, test_acc: 0.7775, best: 0.7831, time: 0:00:41
 Epoch: 218, lr: 2.0e-03, train_loss: 0.2552, train_acc: 0.9148 test_loss: 0.9562, test_acc: 0.7734, best: 0.7831, time: 0:00:41
 Epoch: 219, lr: 2.0e-03, train_loss: 0.2486, train_acc: 0.9148 test_loss: 0.9577, test_acc: 0.7722, best: 0.7831, time: 0:00:41
 Epoch: 220, lr: 2.0e-03, train_loss: 0.2478, train_acc: 0.9178 test_loss: 0.8983, test_acc: 0.7804, best: 0.7831, time: 0:00:41
 Epoch: 221, lr: 2.0e-03, train_loss: 0.2481, train_acc: 0.9150 test_loss: 0.9181, test_acc: 0.7814, best: 0.7831, time: 0:00:41
 Epoch: 222, lr: 2.0e-03, train_loss: 0.2398, train_acc: 0.9176 test_loss: 0.9727, test_acc: 0.7740, best: 0.7831, time: 0:00:41
 Epoch: 223, lr: 2.0e-03, train_loss: 0.2655, train_acc: 0.9084 test_loss: 0.9169, test_acc: 0.7778, best: 0.7831, time: 0:00:41
 Epoch: 224, lr: 2.0e-03, train_loss: 0.2405, train_acc: 0.9158 test_loss: 0.9527, test_acc: 0.7778, best: 0.7831, time: 0:00:41
 Epoch: 225, lr: 2.0e-03, train_loss: 0.2466, train_acc: 0.9160 test_loss: 0.9302, test_acc: 0.7781, best: 0.7831, time: 0:00:41
 Epoch: 226, lr: 2.0e-03, train_loss: 0.2417, train_acc: 0.9194 test_loss: 0.9240, test_acc: 0.7779, best: 0.7831, time: 0:00:41
 Epoch: 227, lr: 2.0e-03, train_loss: 0.2349, train_acc: 0.9196 test_loss: 0.9322, test_acc: 0.7782, best: 0.7831, time: 0:00:41
 Epoch: 228, lr: 2.0e-03, train_loss: 0.2280, train_acc: 0.9222 test_loss: 0.9763, test_acc: 0.7735, best: 0.7831, time: 0:00:41
 Epoch: 229, lr: 2.0e-03, train_loss: 0.2318, train_acc: 0.9200 test_loss: 0.9580, test_acc: 0.7739, best: 0.7831, time: 0:00:41
 Epoch: 230, lr: 2.0e-03, train_loss: 0.2523, train_acc: 0.9140 test_loss: 0.9357, test_acc: 0.7785, best: 0.7831, time: 0:00:41
 Epoch: 231, lr: 2.0e-03, train_loss: 0.2377, train_acc: 0.9224 test_loss: 0.9542, test_acc: 0.7726, best: 0.7831, time: 0:00:41
 Epoch: 232, lr: 2.0e-03, train_loss: 0.2415, train_acc: 0.9146 test_loss: 0.9686, test_acc: 0.7702, best: 0.7831, time: 0:00:41
 Epoch: 233, lr: 2.0e-03, train_loss: 0.2524, train_acc: 0.9162 test_loss: 0.9973, test_acc: 0.7714, best: 0.7831, time: 0:00:41
 Epoch: 234, lr: 2.0e-03, train_loss: 0.2374, train_acc: 0.9208 test_loss: 0.9781, test_acc: 0.7700, best: 0.7831, time: 0:00:41
 Epoch: 235, lr: 2.0e-03, train_loss: 0.2397, train_acc: 0.9200 test_loss: 1.0089, test_acc: 0.7682, best: 0.7831, time: 0:00:41
 Epoch: 236, lr: 2.0e-03, train_loss: 0.2463, train_acc: 0.9182 test_loss: 0.9701, test_acc: 0.7684, best: 0.7831, time: 0:00:41
 Epoch: 237, lr: 2.0e-03, train_loss: 0.2406, train_acc: 0.9172 test_loss: 0.9832, test_acc: 0.7664, best: 0.7831, time: 0:00:41
 Epoch: 238, lr: 2.0e-03, train_loss: 0.2460, train_acc: 0.9146 test_loss: 0.9563, test_acc: 0.7748, best: 0.7831, time: 0:00:41
 Epoch: 239, lr: 2.0e-03, train_loss: 0.2480, train_acc: 0.9148 test_loss: 0.9417, test_acc: 0.7726, best: 0.7831, time: 0:00:41
 Epoch: 240, lr: 4.0e-04, train_loss: 0.2175, train_acc: 0.9288 test_loss: 0.9610, test_acc: 0.7695, best: 0.7831, time: 0:00:41
 Epoch: 241, lr: 4.0e-04, train_loss: 0.2291, train_acc: 0.9236 test_loss: 0.9873, test_acc: 0.7692, best: 0.7831, time: 0:00:41
 Epoch: 242, lr: 4.0e-04, train_loss: 0.2260, train_acc: 0.9192 test_loss: 0.9586, test_acc: 0.7739, best: 0.7831, time: 0:00:41
 Epoch: 243, lr: 4.0e-04, train_loss: 0.2466, train_acc: 0.9178 test_loss: 0.9452, test_acc: 0.7751, best: 0.7831, time: 0:00:41
 Epoch: 244, lr: 4.0e-04, train_loss: 0.2261, train_acc: 0.9250 test_loss: 0.9525, test_acc: 0.7728, best: 0.7831, time: 0:00:41
 Epoch: 245, lr: 4.0e-04, train_loss: 0.2368, train_acc: 0.9172 test_loss: 0.9550, test_acc: 0.7701, best: 0.7831, time: 0:00:41
 Epoch: 246, lr: 4.0e-04, train_loss: 0.2275, train_acc: 0.9226 test_loss: 0.9367, test_acc: 0.7724, best: 0.7831, time: 0:00:41
 Epoch: 247, lr: 4.0e-04, train_loss: 0.2198, train_acc: 0.9218 test_loss: 0.9296, test_acc: 0.7762, best: 0.7831, time: 0:00:41
 Epoch: 248, lr: 4.0e-04, train_loss: 0.2262, train_acc: 0.9248 test_loss: 0.9637, test_acc: 0.7734, best: 0.7831, time: 0:00:41
 Epoch: 249, lr: 4.0e-04, train_loss: 0.2064, train_acc: 0.9306 test_loss: 0.9718, test_acc: 0.7758, best: 0.7831, time: 0:00:41
 Epoch: 250, lr: 4.0e-04, train_loss: 0.2301, train_acc: 0.9240 test_loss: 0.9389, test_acc: 0.7718, best: 0.7831, time: 0:00:41
 Epoch: 251, lr: 4.0e-04, train_loss: 0.2226, train_acc: 0.9248 test_loss: 0.9276, test_acc: 0.7759, best: 0.7831, time: 0:00:41
 Epoch: 252, lr: 4.0e-04, train_loss: 0.2283, train_acc: 0.9198 test_loss: 0.9327, test_acc: 0.7779, best: 0.7831, time: 0:00:41
 Epoch: 253, lr: 4.0e-04, train_loss: 0.2227, train_acc: 0.9200 test_loss: 0.9437, test_acc: 0.7736, best: 0.7831, time: 0:00:41
 Epoch: 254, lr: 4.0e-04, train_loss: 0.2236, train_acc: 0.9238 test_loss: 0.9333, test_acc: 0.7746, best: 0.7831, time: 0:00:41
 Epoch: 255, lr: 4.0e-04, train_loss: 0.2278, train_acc: 0.9214 test_loss: 0.9462, test_acc: 0.7742, best: 0.7831, time: 0:00:41
 Epoch: 256, lr: 4.0e-04, train_loss: 0.2293, train_acc: 0.9220 test_loss: 0.9216, test_acc: 0.7776, best: 0.7831, time: 0:00:41
 Epoch: 257, lr: 4.0e-04, train_loss: 0.2373, train_acc: 0.9244 test_loss: 0.9226, test_acc: 0.7758, best: 0.7831, time: 0:00:41
 Epoch: 258, lr: 4.0e-04, train_loss: 0.2255, train_acc: 0.9220 test_loss: 0.9557, test_acc: 0.7762, best: 0.7831, time: 0:00:41
 Epoch: 259, lr: 4.0e-04, train_loss: 0.2158, train_acc: 0.9240 test_loss: 0.9569, test_acc: 0.7748, best: 0.7831, time: 0:00:41
 Epoch: 260, lr: 4.0e-04, train_loss: 0.2087, train_acc: 0.9286 test_loss: 0.9394, test_acc: 0.7752, best: 0.7831, time: 0:00:41
 Epoch: 261, lr: 4.0e-04, train_loss: 0.2184, train_acc: 0.9272 test_loss: 0.9376, test_acc: 0.7752, best: 0.7831, time: 0:00:41
 Epoch: 262, lr: 4.0e-04, train_loss: 0.2234, train_acc: 0.9228 test_loss: 0.9406, test_acc: 0.7764, best: 0.7831, time: 0:00:41
 Epoch: 263, lr: 4.0e-04, train_loss: 0.2219, train_acc: 0.9260 test_loss: 0.9524, test_acc: 0.7769, best: 0.7831, time: 0:00:41
 Epoch: 264, lr: 4.0e-04, train_loss: 0.2307, train_acc: 0.9182 test_loss: 0.9556, test_acc: 0.7726, best: 0.7831, time: 0:00:41
 Epoch: 265, lr: 4.0e-04, train_loss: 0.2166, train_acc: 0.9260 test_loss: 0.9285, test_acc: 0.7780, best: 0.7831, time: 0:00:41
 Epoch: 266, lr: 4.0e-04, train_loss: 0.2181, train_acc: 0.9266 test_loss: 0.9637, test_acc: 0.7725, best: 0.7831, time: 0:00:41
 Epoch: 267, lr: 4.0e-04, train_loss: 0.2308, train_acc: 0.9222 test_loss: 0.9608, test_acc: 0.7741, best: 0.7831, time: 0:00:41
 Epoch: 268, lr: 4.0e-04, train_loss: 0.2102, train_acc: 0.9242 test_loss: 0.9427, test_acc: 0.7706, best: 0.7831, time: 0:00:41
 Epoch: 269, lr: 4.0e-04, train_loss: 0.2195, train_acc: 0.9226 test_loss: 0.9538, test_acc: 0.7742, best: 0.7831, time: 0:00:41
 Epoch: 270, lr: 8.0e-05, train_loss: 0.2262, train_acc: 0.9218 test_loss: 0.9789, test_acc: 0.7752, best: 0.7831, time: 0:00:41
 Epoch: 271, lr: 8.0e-05, train_loss: 0.2081, train_acc: 0.9318 test_loss: 0.9481, test_acc: 0.7741, best: 0.7831, time: 0:00:41
 Epoch: 272, lr: 8.0e-05, train_loss: 0.2040, train_acc: 0.9300 test_loss: 0.9513, test_acc: 0.7746, best: 0.7831, time: 0:00:41
 Epoch: 273, lr: 8.0e-05, train_loss: 0.2137, train_acc: 0.9254 test_loss: 0.9764, test_acc: 0.7718, best: 0.7831, time: 0:00:41
 Epoch: 274, lr: 8.0e-05, train_loss: 0.2219, train_acc: 0.9244 test_loss: 0.9228, test_acc: 0.7800, best: 0.7831, time: 0:00:41
 Epoch: 275, lr: 8.0e-05, train_loss: 0.2180, train_acc: 0.9258 test_loss: 0.9475, test_acc: 0.7775, best: 0.7831, time: 0:00:41
 Epoch: 276, lr: 8.0e-05, train_loss: 0.2248, train_acc: 0.9260 test_loss: 0.9559, test_acc: 0.7768, best: 0.7831, time: 0:00:41
 Epoch: 277, lr: 8.0e-05, train_loss: 0.2129, train_acc: 0.9304 test_loss: 0.9430, test_acc: 0.7722, best: 0.7831, time: 0:00:41
 Epoch: 278, lr: 8.0e-05, train_loss: 0.2234, train_acc: 0.9248 test_loss: 0.9770, test_acc: 0.7676, best: 0.7831, time: 0:00:41
 Epoch: 279, lr: 8.0e-05, train_loss: 0.1998, train_acc: 0.9336 test_loss: 0.9486, test_acc: 0.7728, best: 0.7831, time: 0:00:41
 Epoch: 280, lr: 8.0e-05, train_loss: 0.2344, train_acc: 0.9224 test_loss: 0.9384, test_acc: 0.7721, best: 0.7831, time: 0:00:41
 Epoch: 281, lr: 8.0e-05, train_loss: 0.2156, train_acc: 0.9246 test_loss: 0.9476, test_acc: 0.7748, best: 0.7831, time: 0:00:41
 Epoch: 282, lr: 8.0e-05, train_loss: 0.2234, train_acc: 0.9262 test_loss: 0.9470, test_acc: 0.7766, best: 0.7831, time: 0:00:41
 Epoch: 283, lr: 8.0e-05, train_loss: 0.2271, train_acc: 0.9200 test_loss: 0.9486, test_acc: 0.7740, best: 0.7831, time: 0:00:41
 Epoch: 284, lr: 8.0e-05, train_loss: 0.2148, train_acc: 0.9294 test_loss: 0.9546, test_acc: 0.7762, best: 0.7831, time: 0:00:41
 Epoch: 285, lr: 8.0e-05, train_loss: 0.2149, train_acc: 0.9286 test_loss: 0.9556, test_acc: 0.7762, best: 0.7831, time: 0:00:41
 Epoch: 286, lr: 8.0e-05, train_loss: 0.2368, train_acc: 0.9198 test_loss: 0.9697, test_acc: 0.7744, best: 0.7831, time: 0:00:41
 Epoch: 287, lr: 8.0e-05, train_loss: 0.2208, train_acc: 0.9242 test_loss: 0.9707, test_acc: 0.7760, best: 0.7831, time: 0:00:41
 Epoch: 288, lr: 8.0e-05, train_loss: 0.2196, train_acc: 0.9248 test_loss: 0.9660, test_acc: 0.7706, best: 0.7831, time: 0:00:41
 Epoch: 289, lr: 8.0e-05, train_loss: 0.2084, train_acc: 0.9280 test_loss: 0.9896, test_acc: 0.7744, best: 0.7831, time: 0:00:41
 Epoch: 290, lr: 8.0e-05, train_loss: 0.2212, train_acc: 0.9228 test_loss: 0.9289, test_acc: 0.7758, best: 0.7831, time: 0:00:41
 Epoch: 291, lr: 8.0e-05, train_loss: 0.2183, train_acc: 0.9264 test_loss: 0.9480, test_acc: 0.7735, best: 0.7831, time: 0:00:41
 Epoch: 292, lr: 8.0e-05, train_loss: 0.2183, train_acc: 0.9236 test_loss: 0.9297, test_acc: 0.7772, best: 0.7831, time: 0:00:41
 Epoch: 293, lr: 8.0e-05, train_loss: 0.2034, train_acc: 0.9350 test_loss: 0.9498, test_acc: 0.7728, best: 0.7831, time: 0:00:41
 Epoch: 294, lr: 8.0e-05, train_loss: 0.2185, train_acc: 0.9218 test_loss: 0.9352, test_acc: 0.7759, best: 0.7831, time: 0:00:41
 Epoch: 295, lr: 8.0e-05, train_loss: 0.2194, train_acc: 0.9248 test_loss: 0.9281, test_acc: 0.7821, best: 0.7831, time: 0:00:41
 Epoch: 296, lr: 8.0e-05, train_loss: 0.2288, train_acc: 0.9208 test_loss: 0.9363, test_acc: 0.7774, best: 0.7831, time: 0:00:41
 Epoch: 297, lr: 8.0e-05, train_loss: 0.2168, train_acc: 0.9242 test_loss: 0.9607, test_acc: 0.7730, best: 0.7831, time: 0:00:41
 Epoch: 298, lr: 8.0e-05, train_loss: 0.2167, train_acc: 0.9274 test_loss: 0.9417, test_acc: 0.7754, best: 0.7831, time: 0:00:41
 Epoch: 299, lr: 8.0e-05, train_loss: 0.2185, train_acc: 0.9270 test_loss: 0.9530, test_acc: 0.7742, best: 0.7831, time: 0:00:41
 Highest accuracy: 0.7831