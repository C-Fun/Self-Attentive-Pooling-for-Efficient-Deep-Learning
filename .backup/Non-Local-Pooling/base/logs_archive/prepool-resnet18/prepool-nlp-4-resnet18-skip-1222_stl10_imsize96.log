
 Run on time: 2022-06-30 11:19:38.851206

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : PREPOOL_RESNET18_NLP_4
	 im_size              : None
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): NetworkByName(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): Pool2d(
        (logit): Sequential(
          (pool_weight): NLP_BASE(
            (downsample): Sequential(
              (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (restore): Sequential(
              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Sigmoid()
            )
            (pos_embed): PositionEmbeddingLearned(
              (row_embed): Embedding(256, 32)
              (col_embed): Embedding(256, 32)
            )
          )
        )
        (pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
      )
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.4083, train_acc: 0.1866 test_loss: 1.9192, test_acc: 0.2544, best: 0.2544, time: 0:01:33
 Epoch: 2, lr: 1.0e-02, train_loss: 1.9844, train_acc: 0.2520 test_loss: 1.8703, test_acc: 0.2562, best: 0.2562, time: 0:01:33
 Epoch: 3, lr: 1.0e-02, train_loss: 1.8895, train_acc: 0.2776 test_loss: 1.6661, test_acc: 0.3453, best: 0.3453, time: 0:01:36
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8399, train_acc: 0.3020 test_loss: 1.6772, test_acc: 0.3559, best: 0.3559, time: 0:01:35
 Epoch: 5, lr: 1.0e-02, train_loss: 1.8143, train_acc: 0.3140 test_loss: 1.5919, test_acc: 0.3990, best: 0.3990, time: 0:01:36
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7505, train_acc: 0.3428 test_loss: 1.5556, test_acc: 0.4088, best: 0.4088, time: 0:01:36
 Epoch: 7, lr: 1.0e-02, train_loss: 1.7098, train_acc: 0.3580 test_loss: 1.5520, test_acc: 0.4154, best: 0.4154, time: 0:01:36
 Epoch: 8, lr: 1.0e-02, train_loss: 1.6929, train_acc: 0.3624 test_loss: 1.6591, test_acc: 0.4205, best: 0.4205, time: 0:01:34
 Epoch: 9, lr: 1.0e-02, train_loss: 1.6589, train_acc: 0.3878 test_loss: 1.4606, test_acc: 0.4743, best: 0.4743, time: 0:01:34
 Epoch: 10, lr: 1.0e-02, train_loss: 1.6011, train_acc: 0.4032 test_loss: 1.4638, test_acc: 0.4482, best: 0.4743, time: 0:01:33
 Epoch: 11, lr: 1.0e-02, train_loss: 1.5679, train_acc: 0.4146 test_loss: 1.4040, test_acc: 0.4959, best: 0.4959, time: 0:01:34
 Epoch: 12, lr: 1.0e-02, train_loss: 1.5509, train_acc: 0.4234 test_loss: 1.4206, test_acc: 0.4820, best: 0.4959, time: 0:01:32
 Epoch: 13, lr: 1.0e-02, train_loss: 1.5119, train_acc: 0.4392 test_loss: 1.3443, test_acc: 0.5049, best: 0.5049, time: 0:01:35
 Epoch: 14, lr: 1.0e-02, train_loss: 1.4762, train_acc: 0.4492 test_loss: 1.4946, test_acc: 0.4770, best: 0.5049, time: 0:01:36
 Epoch: 15, lr: 1.0e-02, train_loss: 1.4645, train_acc: 0.4514 test_loss: 1.3025, test_acc: 0.5222, best: 0.5222, time: 0:01:35
 Epoch: 16, lr: 1.0e-02, train_loss: 1.4386, train_acc: 0.4658 test_loss: 1.4018, test_acc: 0.4946, best: 0.5222, time: 0:01:36
 Epoch: 17, lr: 1.0e-02, train_loss: 1.4116, train_acc: 0.4938 test_loss: 1.3371, test_acc: 0.5040, best: 0.5222, time: 0:01:35
 Epoch: 18, lr: 1.0e-02, train_loss: 1.3897, train_acc: 0.4840 test_loss: 1.2661, test_acc: 0.5361, best: 0.5361, time: 0:01:34
 Epoch: 19, lr: 1.0e-02, train_loss: 1.3706, train_acc: 0.5030 test_loss: 1.4308, test_acc: 0.5052, best: 0.5361, time: 0:01:32
 Epoch: 20, lr: 1.0e-02, train_loss: 1.3324, train_acc: 0.5088 test_loss: 1.1891, test_acc: 0.5614, best: 0.5614, time: 0:01:31
 Epoch: 21, lr: 1.0e-02, train_loss: 1.3214, train_acc: 0.5216 test_loss: 1.1909, test_acc: 0.5577, best: 0.5614, time: 0:01:32
 Epoch: 22, lr: 1.0e-02, train_loss: 1.2949, train_acc: 0.5314 test_loss: 1.1564, test_acc: 0.5803, best: 0.5803, time: 0:01:31
 Epoch: 23, lr: 1.0e-02, train_loss: 1.2754, train_acc: 0.5304 test_loss: 1.1709, test_acc: 0.5689, best: 0.5803, time: 0:01:35
 Epoch: 24, lr: 1.0e-02, train_loss: 1.2833, train_acc: 0.5260 test_loss: 1.1106, test_acc: 0.5925, best: 0.5925, time: 0:01:31
 Epoch: 25, lr: 1.0e-02, train_loss: 1.2609, train_acc: 0.5476 test_loss: 1.1386, test_acc: 0.5913, best: 0.5925, time: 0:01:31
 Epoch: 26, lr: 1.0e-02, train_loss: 1.2337, train_acc: 0.5532 test_loss: 1.1594, test_acc: 0.5696, best: 0.5925, time: 0:01:31
 Epoch: 27, lr: 1.0e-02, train_loss: 1.2236, train_acc: 0.5526 test_loss: 1.1237, test_acc: 0.5835, best: 0.5925, time: 0:01:30
 Epoch: 28, lr: 1.0e-02, train_loss: 1.2060, train_acc: 0.5652 test_loss: 1.3537, test_acc: 0.5350, best: 0.5925, time: 0:01:31
 Epoch: 29, lr: 1.0e-02, train_loss: 1.1790, train_acc: 0.5646 test_loss: 1.1473, test_acc: 0.5955, best: 0.5955, time: 0:01:31
 Epoch: 30, lr: 1.0e-02, train_loss: 1.1825, train_acc: 0.5686 test_loss: 1.0612, test_acc: 0.6121, best: 0.6121, time: 0:01:31
 Epoch: 31, lr: 1.0e-02, train_loss: 1.1698, train_acc: 0.5754 test_loss: 1.1083, test_acc: 0.6014, best: 0.6121, time: 0:01:31
 Epoch: 32, lr: 1.0e-02, train_loss: 1.1517, train_acc: 0.5856 test_loss: 1.0241, test_acc: 0.6301, best: 0.6301, time: 0:01:31
 Epoch: 33, lr: 1.0e-02, train_loss: 1.1371, train_acc: 0.5916 test_loss: 1.1163, test_acc: 0.6085, best: 0.6301, time: 0:01:31
 Epoch: 34, lr: 1.0e-02, train_loss: 1.1199, train_acc: 0.5954 test_loss: 1.1340, test_acc: 0.6046, best: 0.6301, time: 0:01:31
 Epoch: 35, lr: 1.0e-02, train_loss: 1.0906, train_acc: 0.6118 test_loss: 1.0138, test_acc: 0.6362, best: 0.6362, time: 0:01:31
 Epoch: 36, lr: 1.0e-02, train_loss: 1.1117, train_acc: 0.5966 test_loss: 1.0844, test_acc: 0.6121, best: 0.6362, time: 0:01:31
 Epoch: 37, lr: 1.0e-02, train_loss: 1.0856, train_acc: 0.6088 test_loss: 1.0186, test_acc: 0.6316, best: 0.6362, time: 0:01:31
 Epoch: 38, lr: 1.0e-02, train_loss: 1.0817, train_acc: 0.6112 test_loss: 1.0370, test_acc: 0.6352, best: 0.6362, time: 0:01:31
 Epoch: 39, lr: 1.0e-02, train_loss: 1.0673, train_acc: 0.6100 test_loss: 1.0860, test_acc: 0.6205, best: 0.6362, time: 0:01:31
 Epoch: 40, lr: 1.0e-02, train_loss: 1.0515, train_acc: 0.6270 test_loss: 1.0893, test_acc: 0.6124, best: 0.6362, time: 0:01:31
 Epoch: 41, lr: 1.0e-02, train_loss: 1.0471, train_acc: 0.6148 test_loss: 0.9881, test_acc: 0.6496, best: 0.6496, time: 0:01:35
 Epoch: 42, lr: 1.0e-02, train_loss: 1.0360, train_acc: 0.6246 test_loss: 1.0521, test_acc: 0.6330, best: 0.6496, time: 0:01:34
 Epoch: 43, lr: 1.0e-02, train_loss: 1.0208, train_acc: 0.6258 test_loss: 0.9644, test_acc: 0.6593, best: 0.6593, time: 0:01:31
 Epoch: 44, lr: 1.0e-02, train_loss: 1.0156, train_acc: 0.6324 test_loss: 0.9878, test_acc: 0.6538, best: 0.6593, time: 0:01:31
 Epoch: 45, lr: 1.0e-02, train_loss: 0.9997, train_acc: 0.6374 test_loss: 0.9353, test_acc: 0.6683, best: 0.6683, time: 0:01:31
 Epoch: 46, lr: 1.0e-02, train_loss: 1.0011, train_acc: 0.6416 test_loss: 1.0877, test_acc: 0.6278, best: 0.6683, time: 0:01:31
 Epoch: 47, lr: 1.0e-02, train_loss: 0.9681, train_acc: 0.6474 test_loss: 1.0055, test_acc: 0.6436, best: 0.6683, time: 0:01:32
 Epoch: 48, lr: 1.0e-02, train_loss: 0.9894, train_acc: 0.6420 test_loss: 0.9734, test_acc: 0.6574, best: 0.6683, time: 0:01:31
 Epoch: 49, lr: 1.0e-02, train_loss: 0.9530, train_acc: 0.6604 test_loss: 0.9479, test_acc: 0.6701, best: 0.6701, time: 0:01:31
 Epoch: 50, lr: 1.0e-02, train_loss: 0.9260, train_acc: 0.6664 test_loss: 0.9582, test_acc: 0.6625, best: 0.6701, time: 0:01:31
 Epoch: 51, lr: 1.0e-02, train_loss: 0.9571, train_acc: 0.6610 test_loss: 0.9105, test_acc: 0.6757, best: 0.6757, time: 0:01:31
 Epoch: 52, lr: 1.0e-02, train_loss: 0.9222, train_acc: 0.6724 test_loss: 1.0413, test_acc: 0.6426, best: 0.6757, time: 0:01:31
 Epoch: 53, lr: 1.0e-02, train_loss: 0.9464, train_acc: 0.6576 test_loss: 1.0092, test_acc: 0.6499, best: 0.6757, time: 0:01:31
 Epoch: 54, lr: 1.0e-02, train_loss: 0.9244, train_acc: 0.6686 test_loss: 0.9503, test_acc: 0.6667, best: 0.6757, time: 0:01:31
 Epoch: 55, lr: 1.0e-02, train_loss: 0.9438, train_acc: 0.6640 test_loss: 0.9135, test_acc: 0.6823, best: 0.6823, time: 0:01:31
 Epoch: 56, lr: 1.0e-02, train_loss: 0.9015, train_acc: 0.6720 test_loss: 0.9679, test_acc: 0.6680, best: 0.6823, time: 0:01:31
 Epoch: 57, lr: 1.0e-02, train_loss: 0.8912, train_acc: 0.6762 test_loss: 0.8902, test_acc: 0.6890, best: 0.6890, time: 0:01:31
 Epoch: 58, lr: 1.0e-02, train_loss: 0.8879, train_acc: 0.6832 test_loss: 0.9283, test_acc: 0.6850, best: 0.6890, time: 0:01:36
 Epoch: 59, lr: 1.0e-02, train_loss: 0.8883, train_acc: 0.6780 test_loss: 0.9085, test_acc: 0.6850, best: 0.6890, time: 0:01:35
 Epoch: 60, lr: 1.0e-02, train_loss: 0.8625, train_acc: 0.6932 test_loss: 0.9703, test_acc: 0.6730, best: 0.6890, time: 0:01:34
 Epoch: 61, lr: 1.0e-02, train_loss: 0.8670, train_acc: 0.6884 test_loss: 0.9468, test_acc: 0.6746, best: 0.6890, time: 0:01:33
 Epoch: 62, lr: 1.0e-02, train_loss: 0.8459, train_acc: 0.6996 test_loss: 0.9243, test_acc: 0.6731, best: 0.6890, time: 0:01:33
 Epoch: 63, lr: 1.0e-02, train_loss: 0.8612, train_acc: 0.6970 test_loss: 0.9765, test_acc: 0.6784, best: 0.6890, time: 0:01:31
 Epoch: 64, lr: 1.0e-02, train_loss: 0.8243, train_acc: 0.7010 test_loss: 0.9459, test_acc: 0.6781, best: 0.6890, time: 0:01:31
 Epoch: 65, lr: 1.0e-02, train_loss: 0.8130, train_acc: 0.7084 test_loss: 0.9017, test_acc: 0.6981, best: 0.6981, time: 0:01:31
 Epoch: 66, lr: 1.0e-02, train_loss: 0.8189, train_acc: 0.7082 test_loss: 0.9307, test_acc: 0.6801, best: 0.6981, time: 0:01:31
 Epoch: 67, lr: 1.0e-02, train_loss: 0.7921, train_acc: 0.7218 test_loss: 0.9109, test_acc: 0.6884, best: 0.6981, time: 0:01:30
 Epoch: 68, lr: 1.0e-02, train_loss: 0.7999, train_acc: 0.7146 test_loss: 0.9619, test_acc: 0.6919, best: 0.6981, time: 0:01:31
 Epoch: 69, lr: 1.0e-02, train_loss: 0.7959, train_acc: 0.7166 test_loss: 0.8895, test_acc: 0.6975, best: 0.6981, time: 0:01:31
 Epoch: 70, lr: 1.0e-02, train_loss: 0.8033, train_acc: 0.7220 test_loss: 0.9654, test_acc: 0.6775, best: 0.6981, time: 0:01:31
 Epoch: 71, lr: 1.0e-02, train_loss: 0.7956, train_acc: 0.7200 test_loss: 0.9426, test_acc: 0.6794, best: 0.6981, time: 0:01:31
 Epoch: 72, lr: 1.0e-02, train_loss: 0.7627, train_acc: 0.7260 test_loss: 0.9145, test_acc: 0.6930, best: 0.6981, time: 0:01:31
 Epoch: 73, lr: 1.0e-02, train_loss: 0.7841, train_acc: 0.7194 test_loss: 0.9308, test_acc: 0.6934, best: 0.6981, time: 0:01:31
 Epoch: 74, lr: 1.0e-02, train_loss: 0.7794, train_acc: 0.7270 test_loss: 0.9663, test_acc: 0.6786, best: 0.6981, time: 0:01:31
 Epoch: 75, lr: 1.0e-02, train_loss: 0.7536, train_acc: 0.7366 test_loss: 0.9534, test_acc: 0.6914, best: 0.6981, time: 0:01:31
 Epoch: 76, lr: 1.0e-02, train_loss: 0.7505, train_acc: 0.7342 test_loss: 0.9426, test_acc: 0.6889, best: 0.6981, time: 0:01:31
 Epoch: 77, lr: 1.0e-02, train_loss: 0.7502, train_acc: 0.7340 test_loss: 0.9784, test_acc: 0.6796, best: 0.6981, time: 0:01:31
 Epoch: 78, lr: 1.0e-02, train_loss: 0.7488, train_acc: 0.7342 test_loss: 0.9119, test_acc: 0.7047, best: 0.7047, time: 0:01:31
 Epoch: 79, lr: 1.0e-02, train_loss: 0.7331, train_acc: 0.7436 test_loss: 0.8718, test_acc: 0.7186, best: 0.7186, time: 0:01:31
 Epoch: 80, lr: 1.0e-02, train_loss: 0.7134, train_acc: 0.7510 test_loss: 0.9298, test_acc: 0.6969, best: 0.7186, time: 0:01:31
 Epoch: 81, lr: 1.0e-02, train_loss: 0.7358, train_acc: 0.7390 test_loss: 0.9528, test_acc: 0.6876, best: 0.7186, time: 0:01:31
 Epoch: 82, lr: 1.0e-02, train_loss: 0.7209, train_acc: 0.7460 test_loss: 0.9071, test_acc: 0.7005, best: 0.7186, time: 0:01:31
 Epoch: 83, lr: 1.0e-02, train_loss: 0.7216, train_acc: 0.7470 test_loss: 0.9468, test_acc: 0.6946, best: 0.7186, time: 0:01:31
 Epoch: 84, lr: 1.0e-02, train_loss: 0.7267, train_acc: 0.7436 test_loss: 0.9025, test_acc: 0.7007, best: 0.7186, time: 0:01:31
 Epoch: 85, lr: 1.0e-02, train_loss: 0.6982, train_acc: 0.7488 test_loss: 0.9265, test_acc: 0.7044, best: 0.7186, time: 0:01:37
 Epoch: 86, lr: 1.0e-02, train_loss: 0.7150, train_acc: 0.7458 test_loss: 0.9267, test_acc: 0.6886, best: 0.7186, time: 0:01:32
 Epoch: 87, lr: 1.0e-02, train_loss: 0.6905, train_acc: 0.7542 test_loss: 1.0312, test_acc: 0.6850, best: 0.7186, time: 0:01:31
 Epoch: 88, lr: 1.0e-02, train_loss: 0.7103, train_acc: 0.7460 test_loss: 0.9155, test_acc: 0.6974, best: 0.7186, time: 0:01:31
 Epoch: 89, lr: 1.0e-02, train_loss: 0.6887, train_acc: 0.7586 test_loss: 0.9288, test_acc: 0.7074, best: 0.7186, time: 0:01:31
 Epoch: 90, lr: 1.0e-02, train_loss: 0.6608, train_acc: 0.7626 test_loss: 0.9233, test_acc: 0.7055, best: 0.7186, time: 0:01:37
 Epoch: 91, lr: 1.0e-02, train_loss: 0.6950, train_acc: 0.7488 test_loss: 0.8825, test_acc: 0.7086, best: 0.7186, time: 0:01:37
 Epoch: 92, lr: 1.0e-02, train_loss: 0.6517, train_acc: 0.7756 test_loss: 1.0109, test_acc: 0.6959, best: 0.7186, time: 0:01:36
 Epoch: 93, lr: 1.0e-02, train_loss: 0.6677, train_acc: 0.7660 test_loss: 0.8996, test_acc: 0.7071, best: 0.7186, time: 0:01:37
 Epoch: 94, lr: 1.0e-02, train_loss: 0.6565, train_acc: 0.7706 test_loss: 0.8928, test_acc: 0.7163, best: 0.7186, time: 0:01:37
 Epoch: 95, lr: 1.0e-02, train_loss: 0.6381, train_acc: 0.7758 test_loss: 0.8846, test_acc: 0.7198, best: 0.7198, time: 0:01:37
 Epoch: 96, lr: 1.0e-02, train_loss: 0.6285, train_acc: 0.7822 test_loss: 0.9260, test_acc: 0.7111, best: 0.7198, time: 0:01:36
 Epoch: 97, lr: 1.0e-02, train_loss: 0.6396, train_acc: 0.7748 test_loss: 0.8670, test_acc: 0.7173, best: 0.7198, time: 0:01:37
 Epoch: 98, lr: 1.0e-02, train_loss: 0.6395, train_acc: 0.7746 test_loss: 0.8245, test_acc: 0.7236, best: 0.7236, time: 0:01:36
 Epoch: 99, lr: 1.0e-02, train_loss: 0.6255, train_acc: 0.7782 test_loss: 0.8809, test_acc: 0.7256, best: 0.7256, time: 0:01:36
 Epoch: 100, lr: 1.0e-02, train_loss: 0.6467, train_acc: 0.7718 test_loss: 0.8511, test_acc: 0.7177, best: 0.7256, time: 0:01:36
 Epoch: 101, lr: 1.0e-02, train_loss: 0.6115, train_acc: 0.7862 test_loss: 0.9040, test_acc: 0.7084, best: 0.7256, time: 0:01:34
 Epoch: 102, lr: 1.0e-02, train_loss: 0.6325, train_acc: 0.7768 test_loss: 0.9201, test_acc: 0.7127, best: 0.7256, time: 0:01:36
 Epoch: 103, lr: 1.0e-02, train_loss: 0.6202, train_acc: 0.7840 test_loss: 0.8919, test_acc: 0.7117, best: 0.7256, time: 0:01:36
 Epoch: 104, lr: 1.0e-02, train_loss: 0.5996, train_acc: 0.7858 test_loss: 0.9572, test_acc: 0.7039, best: 0.7256, time: 0:01:36
 Epoch: 105, lr: 1.0e-02, train_loss: 0.6018, train_acc: 0.7858 test_loss: 0.9349, test_acc: 0.7129, best: 0.7256, time: 0:01:35
 Epoch: 106, lr: 1.0e-02, train_loss: 0.5820, train_acc: 0.7944 test_loss: 1.0073, test_acc: 0.7015, best: 0.7256, time: 0:01:35
 Epoch: 107, lr: 1.0e-02, train_loss: 0.6027, train_acc: 0.7918 test_loss: 0.8756, test_acc: 0.7200, best: 0.7256, time: 0:01:36
 Epoch: 108, lr: 1.0e-02, train_loss: 0.6019, train_acc: 0.7830 test_loss: 0.9461, test_acc: 0.7077, best: 0.7256, time: 0:01:37
 Epoch: 109, lr: 1.0e-02, train_loss: 0.5815, train_acc: 0.7962 test_loss: 0.9435, test_acc: 0.7177, best: 0.7256, time: 0:01:35
 Epoch: 110, lr: 1.0e-02, train_loss: 0.5687, train_acc: 0.8028 test_loss: 0.8683, test_acc: 0.7232, best: 0.7256, time: 0:01:36
 Epoch: 111, lr: 1.0e-02, train_loss: 0.5849, train_acc: 0.7976 test_loss: 0.9583, test_acc: 0.7084, best: 0.7256, time: 0:01:36
 Epoch: 112, lr: 1.0e-02, train_loss: 0.6045, train_acc: 0.7920 test_loss: 0.8726, test_acc: 0.7282, best: 0.7282, time: 0:01:35
 Epoch: 113, lr: 1.0e-02, train_loss: 0.5641, train_acc: 0.7952 test_loss: 0.9132, test_acc: 0.7175, best: 0.7282, time: 0:01:34
 Epoch: 114, lr: 1.0e-02, train_loss: 0.5466, train_acc: 0.8014 test_loss: 0.9416, test_acc: 0.7228, best: 0.7282, time: 0:01:35
 Epoch: 115, lr: 1.0e-02, train_loss: 0.5675, train_acc: 0.7976 test_loss: 1.0041, test_acc: 0.7143, best: 0.7282, time: 0:01:35
 Epoch: 116, lr: 1.0e-02, train_loss: 0.5525, train_acc: 0.8046 test_loss: 0.8847, test_acc: 0.7290, best: 0.7290, time: 0:01:36
 Epoch: 117, lr: 1.0e-02, train_loss: 0.5573, train_acc: 0.8074 test_loss: 0.9191, test_acc: 0.7272, best: 0.7290, time: 0:01:35
 Epoch: 118, lr: 1.0e-02, train_loss: 0.5542, train_acc: 0.8072 test_loss: 0.9571, test_acc: 0.7210, best: 0.7290, time: 0:01:35
 Epoch: 119, lr: 1.0e-02, train_loss: 0.5476, train_acc: 0.8094 test_loss: 0.9630, test_acc: 0.7089, best: 0.7290, time: 0:01:35
 Epoch: 120, lr: 1.0e-02, train_loss: 0.5473, train_acc: 0.8078 test_loss: 0.8961, test_acc: 0.7300, best: 0.7300, time: 0:01:34
 Epoch: 121, lr: 1.0e-02, train_loss: 0.5527, train_acc: 0.8046 test_loss: 0.9115, test_acc: 0.7286, best: 0.7300, time: 0:01:35
 Epoch: 122, lr: 1.0e-02, train_loss: 0.5525, train_acc: 0.8080 test_loss: 0.9464, test_acc: 0.7173, best: 0.7300, time: 0:01:36
 Epoch: 123, lr: 1.0e-02, train_loss: 0.5356, train_acc: 0.8164 test_loss: 0.9796, test_acc: 0.7006, best: 0.7300, time: 0:01:35
 Epoch: 124, lr: 1.0e-02, train_loss: 0.5194, train_acc: 0.8098 test_loss: 0.9730, test_acc: 0.7153, best: 0.7300, time: 0:01:34
 Epoch: 125, lr: 1.0e-02, train_loss: 0.5328, train_acc: 0.8162 test_loss: 0.9152, test_acc: 0.7242, best: 0.7300, time: 0:01:39
 Epoch: 126, lr: 1.0e-02, train_loss: 0.5421, train_acc: 0.8090 test_loss: 0.9183, test_acc: 0.7288, best: 0.7300, time: 0:01:35
 Epoch: 127, lr: 1.0e-02, train_loss: 0.5291, train_acc: 0.8164 test_loss: 0.9460, test_acc: 0.7198, best: 0.7300, time: 0:01:34
 Epoch: 128, lr: 1.0e-02, train_loss: 0.5380, train_acc: 0.8118 test_loss: 0.9489, test_acc: 0.7180, best: 0.7300, time: 0:01:35
 Epoch: 129, lr: 1.0e-02, train_loss: 0.5168, train_acc: 0.8180 test_loss: 0.9416, test_acc: 0.7268, best: 0.7300, time: 0:01:36
 Epoch: 130, lr: 1.0e-02, train_loss: 0.5112, train_acc: 0.8222 test_loss: 0.9314, test_acc: 0.7358, best: 0.7358, time: 0:01:37
 Epoch: 131, lr: 1.0e-02, train_loss: 0.5503, train_acc: 0.8098 test_loss: 0.9012, test_acc: 0.7361, best: 0.7361, time: 0:01:35
 Epoch: 132, lr: 1.0e-02, train_loss: 0.5135, train_acc: 0.8242 test_loss: 0.9708, test_acc: 0.7119, best: 0.7361, time: 0:01:35
 Epoch: 133, lr: 1.0e-02, train_loss: 0.4965, train_acc: 0.8296 test_loss: 0.9822, test_acc: 0.7134, best: 0.7361, time: 0:01:35
 Epoch: 134, lr: 1.0e-02, train_loss: 0.4993, train_acc: 0.8256 test_loss: 0.9531, test_acc: 0.7314, best: 0.7361, time: 0:01:35
 Epoch: 135, lr: 1.0e-02, train_loss: 0.5111, train_acc: 0.8244 test_loss: 0.9832, test_acc: 0.7221, best: 0.7361, time: 0:01:37
 Epoch: 136, lr: 1.0e-02, train_loss: 0.5042, train_acc: 0.8210 test_loss: 0.9195, test_acc: 0.7281, best: 0.7361, time: 0:01:37
 Epoch: 137, lr: 1.0e-02, train_loss: 0.4942, train_acc: 0.8276 test_loss: 0.9075, test_acc: 0.7256, best: 0.7361, time: 0:01:34
 Epoch: 138, lr: 1.0e-02, train_loss: 0.4847, train_acc: 0.8290 test_loss: 0.9527, test_acc: 0.7242, best: 0.7361, time: 0:01:35
 Epoch: 139, lr: 1.0e-02, train_loss: 0.5059, train_acc: 0.8284 test_loss: 0.9433, test_acc: 0.7315, best: 0.7361, time: 0:01:36
 Epoch: 140, lr: 1.0e-02, train_loss: 0.4888, train_acc: 0.8322 test_loss: 0.9316, test_acc: 0.7315, best: 0.7361, time: 0:01:34
 Epoch: 141, lr: 1.0e-02, train_loss: 0.4967, train_acc: 0.8308 test_loss: 0.9875, test_acc: 0.7201, best: 0.7361, time: 0:01:36
 Epoch: 142, lr: 1.0e-02, train_loss: 0.4886, train_acc: 0.8322 test_loss: 0.9939, test_acc: 0.7173, best: 0.7361, time: 0:01:34
 Epoch: 143, lr: 1.0e-02, train_loss: 0.4733, train_acc: 0.8334 test_loss: 0.9771, test_acc: 0.7186, best: 0.7361, time: 0:01:36
 Epoch: 144, lr: 1.0e-02, train_loss: 0.4714, train_acc: 0.8354 test_loss: 0.9189, test_acc: 0.7331, best: 0.7361, time: 0:01:35
 Epoch: 145, lr: 1.0e-02, train_loss: 0.4789, train_acc: 0.8332 test_loss: 0.9608, test_acc: 0.7334, best: 0.7361, time: 0:01:36
 Epoch: 146, lr: 1.0e-02, train_loss: 0.4801, train_acc: 0.8274 test_loss: 1.0229, test_acc: 0.7119, best: 0.7361, time: 0:01:35
 Epoch: 147, lr: 1.0e-02, train_loss: 0.4841, train_acc: 0.8328 test_loss: 0.9745, test_acc: 0.7281, best: 0.7361, time: 0:01:36
 Epoch: 148, lr: 1.0e-02, train_loss: 0.4711, train_acc: 0.8334 test_loss: 0.9806, test_acc: 0.7248, best: 0.7361, time: 0:01:37
 Epoch: 149, lr: 1.0e-02, train_loss: 0.4667, train_acc: 0.8370 test_loss: 1.0453, test_acc: 0.7143, best: 0.7361, time: 0:01:36
 Epoch: 150, lr: 1.0e-02, train_loss: 0.4646, train_acc: 0.8410 test_loss: 0.9340, test_acc: 0.7234, best: 0.7361, time: 0:01:35
 Epoch: 151, lr: 1.0e-02, train_loss: 0.4732, train_acc: 0.8318 test_loss: 0.8958, test_acc: 0.7388, best: 0.7388, time: 0:01:36
 Epoch: 152, lr: 1.0e-02, train_loss: 0.4559, train_acc: 0.8424 test_loss: 0.9854, test_acc: 0.7238, best: 0.7388, time: 0:01:35
 Epoch: 153, lr: 1.0e-02, train_loss: 0.4545, train_acc: 0.8482 test_loss: 1.0877, test_acc: 0.7121, best: 0.7388, time: 0:01:36
 Epoch: 154, lr: 1.0e-02, train_loss: 0.4421, train_acc: 0.8516 test_loss: 1.0213, test_acc: 0.7215, best: 0.7388, time: 0:01:35
 Epoch: 155, lr: 1.0e-02, train_loss: 0.4630, train_acc: 0.8428 test_loss: 0.9286, test_acc: 0.7388, best: 0.7388, time: 0:01:35
 Epoch: 156, lr: 1.0e-02, train_loss: 0.4373, train_acc: 0.8486 test_loss: 0.9633, test_acc: 0.7261, best: 0.7388, time: 0:01:34
 Epoch: 157, lr: 1.0e-02, train_loss: 0.4532, train_acc: 0.8390 test_loss: 0.9211, test_acc: 0.7299, best: 0.7388, time: 0:01:36
 Epoch: 158, lr: 1.0e-02, train_loss: 0.4501, train_acc: 0.8478 test_loss: 0.9857, test_acc: 0.7209, best: 0.7388, time: 0:01:36
 Epoch: 159, lr: 1.0e-02, train_loss: 0.4364, train_acc: 0.8516 test_loss: 0.9996, test_acc: 0.7232, best: 0.7388, time: 0:01:35
 Epoch: 160, lr: 1.0e-02, train_loss: 0.4415, train_acc: 0.8532 test_loss: 0.9825, test_acc: 0.7250, best: 0.7388, time: 0:01:35
 Epoch: 161, lr: 1.0e-02, train_loss: 0.4334, train_acc: 0.8434 test_loss: 1.0526, test_acc: 0.7147, best: 0.7388, time: 0:01:35
 Epoch: 162, lr: 1.0e-02, train_loss: 0.4321, train_acc: 0.8510 test_loss: 1.0023, test_acc: 0.7198, best: 0.7388, time: 0:01:36
 Epoch: 163, lr: 1.0e-02, train_loss: 0.4338, train_acc: 0.8492 test_loss: 0.9506, test_acc: 0.7284, best: 0.7388, time: 0:01:34
 Epoch: 164, lr: 1.0e-02, train_loss: 0.4312, train_acc: 0.8548 test_loss: 0.9843, test_acc: 0.7218, best: 0.7388, time: 0:01:36
 Epoch: 165, lr: 1.0e-02, train_loss: 0.4089, train_acc: 0.8610 test_loss: 0.9587, test_acc: 0.7340, best: 0.7388, time: 0:01:37
 Epoch: 166, lr: 1.0e-02, train_loss: 0.4272, train_acc: 0.8540 test_loss: 1.0001, test_acc: 0.7265, best: 0.7388, time: 0:01:37
 Epoch: 167, lr: 1.0e-02, train_loss: 0.4383, train_acc: 0.8510 test_loss: 0.9500, test_acc: 0.7308, best: 0.7388, time: 0:01:35
 Epoch: 168, lr: 1.0e-02, train_loss: 0.4126, train_acc: 0.8600 test_loss: 0.9895, test_acc: 0.7372, best: 0.7388, time: 0:01:35
 Epoch: 169, lr: 1.0e-02, train_loss: 0.4150, train_acc: 0.8580 test_loss: 1.0739, test_acc: 0.7226, best: 0.7388, time: 0:01:37
 Epoch: 170, lr: 1.0e-02, train_loss: 0.4208, train_acc: 0.8570 test_loss: 0.9884, test_acc: 0.7309, best: 0.7388, time: 0:01:36
 Epoch: 171, lr: 1.0e-02, train_loss: 0.4122, train_acc: 0.8534 test_loss: 1.0101, test_acc: 0.7306, best: 0.7388, time: 0:01:37
 Epoch: 172, lr: 1.0e-02, train_loss: 0.4187, train_acc: 0.8614 test_loss: 1.0105, test_acc: 0.7246, best: 0.7388, time: 0:01:35
 Epoch: 173, lr: 1.0e-02, train_loss: 0.4034, train_acc: 0.8636 test_loss: 1.0147, test_acc: 0.7335, best: 0.7388, time: 0:01:34
 Epoch: 174, lr: 1.0e-02, train_loss: 0.4129, train_acc: 0.8598 test_loss: 0.9681, test_acc: 0.7380, best: 0.7388, time: 0:01:35
 Epoch: 175, lr: 1.0e-02, train_loss: 0.4045, train_acc: 0.8624 test_loss: 0.9565, test_acc: 0.7378, best: 0.7388, time: 0:01:34
 Epoch: 176, lr: 1.0e-02, train_loss: 0.4081, train_acc: 0.8590 test_loss: 1.0445, test_acc: 0.7194, best: 0.7388, time: 0:01:35
 Epoch: 177, lr: 1.0e-02, train_loss: 0.4360, train_acc: 0.8494 test_loss: 0.9929, test_acc: 0.7274, best: 0.7388, time: 0:01:36
 Epoch: 178, lr: 1.0e-02, train_loss: 0.4116, train_acc: 0.8600 test_loss: 1.0641, test_acc: 0.7259, best: 0.7388, time: 0:01:35
 Epoch: 179, lr: 1.0e-02, train_loss: 0.4114, train_acc: 0.8596 test_loss: 1.0567, test_acc: 0.7221, best: 0.7388, time: 0:01:34
 Epoch: 180, lr: 2.0e-03, train_loss: 0.3693, train_acc: 0.8768 test_loss: 0.9521, test_acc: 0.7402, best: 0.7402, time: 0:01:35
 Epoch: 181, lr: 2.0e-03, train_loss: 0.3157, train_acc: 0.8894 test_loss: 0.9513, test_acc: 0.7470, best: 0.7470, time: 0:01:35
 Epoch: 182, lr: 2.0e-03, train_loss: 0.3357, train_acc: 0.8876 test_loss: 0.9437, test_acc: 0.7481, best: 0.7481, time: 0:01:34
 Epoch: 183, lr: 2.0e-03, train_loss: 0.3102, train_acc: 0.8928 test_loss: 0.9207, test_acc: 0.7516, best: 0.7516, time: 0:01:35
 Epoch: 184, lr: 2.0e-03, train_loss: 0.3305, train_acc: 0.8888 test_loss: 0.9270, test_acc: 0.7466, best: 0.7516, time: 0:01:35
 Epoch: 185, lr: 2.0e-03, train_loss: 0.3263, train_acc: 0.8916 test_loss: 0.9485, test_acc: 0.7454, best: 0.7516, time: 0:01:36
 Epoch: 186, lr: 2.0e-03, train_loss: 0.3076, train_acc: 0.8904 test_loss: 0.9381, test_acc: 0.7508, best: 0.7516, time: 0:01:34
 Epoch: 187, lr: 2.0e-03, train_loss: 0.2910, train_acc: 0.9044 test_loss: 0.9285, test_acc: 0.7516, best: 0.7516, time: 0:01:35
 Epoch: 188, lr: 2.0e-03, train_loss: 0.2907, train_acc: 0.9032 test_loss: 0.9471, test_acc: 0.7498, best: 0.7516, time: 0:01:35
 Epoch: 189, lr: 2.0e-03, train_loss: 0.3193, train_acc: 0.8894 test_loss: 0.9319, test_acc: 0.7491, best: 0.7516, time: 0:01:35
 Epoch: 190, lr: 2.0e-03, train_loss: 0.2818, train_acc: 0.9082 test_loss: 0.9287, test_acc: 0.7516, best: 0.7516, time: 0:01:34
 Epoch: 191, lr: 2.0e-03, train_loss: 0.3118, train_acc: 0.8944 test_loss: 0.9439, test_acc: 0.7512, best: 0.7516, time: 0:01:35
 Epoch: 192, lr: 2.0e-03, train_loss: 0.2846, train_acc: 0.9040 test_loss: 0.9441, test_acc: 0.7479, best: 0.7516, time: 0:01:35
 Epoch: 193, lr: 2.0e-03, train_loss: 0.3012, train_acc: 0.8968 test_loss: 0.9627, test_acc: 0.7525, best: 0.7525, time: 0:01:36
 Epoch: 194, lr: 2.0e-03, train_loss: 0.2981, train_acc: 0.9040 test_loss: 0.9563, test_acc: 0.7528, best: 0.7528, time: 0:01:37
 Epoch: 195, lr: 2.0e-03, train_loss: 0.2955, train_acc: 0.9016 test_loss: 0.9253, test_acc: 0.7515, best: 0.7528, time: 0:01:35
 Epoch: 196, lr: 2.0e-03, train_loss: 0.2878, train_acc: 0.9006 test_loss: 0.9595, test_acc: 0.7542, best: 0.7542, time: 0:01:34
 Epoch: 197, lr: 2.0e-03, train_loss: 0.2981, train_acc: 0.9010 test_loss: 0.9329, test_acc: 0.7521, best: 0.7542, time: 0:01:35
 Epoch: 198, lr: 2.0e-03, train_loss: 0.2777, train_acc: 0.9042 test_loss: 0.9923, test_acc: 0.7464, best: 0.7542, time: 0:01:35
 Epoch: 199, lr: 2.0e-03, train_loss: 0.2626, train_acc: 0.9102 test_loss: 0.9726, test_acc: 0.7444, best: 0.7542, time: 0:01:35
 Epoch: 200, lr: 2.0e-03, train_loss: 0.2671, train_acc: 0.9102 test_loss: 0.9659, test_acc: 0.7535, best: 0.7542, time: 0:01:36
 Epoch: 201, lr: 2.0e-03, train_loss: 0.2987, train_acc: 0.8952 test_loss: 0.9749, test_acc: 0.7500, best: 0.7542, time: 0:01:37
 Epoch: 202, lr: 2.0e-03, train_loss: 0.2893, train_acc: 0.8990 test_loss: 0.9549, test_acc: 0.7520, best: 0.7542, time: 0:01:36
 Epoch: 203, lr: 2.0e-03, train_loss: 0.2784, train_acc: 0.9056 test_loss: 0.9263, test_acc: 0.7469, best: 0.7542, time: 0:01:35
 Epoch: 204, lr: 2.0e-03, train_loss: 0.2721, train_acc: 0.9090 test_loss: 0.9693, test_acc: 0.7519, best: 0.7542, time: 0:01:36
 Epoch: 205, lr: 2.0e-03, train_loss: 0.2677, train_acc: 0.9110 test_loss: 0.9864, test_acc: 0.7445, best: 0.7542, time: 0:01:35
 Epoch: 206, lr: 2.0e-03, train_loss: 0.2671, train_acc: 0.9094 test_loss: 0.9899, test_acc: 0.7469, best: 0.7542, time: 0:01:37
 Epoch: 207, lr: 2.0e-03, train_loss: 0.2724, train_acc: 0.9064 test_loss: 0.9797, test_acc: 0.7479, best: 0.7542, time: 0:01:35
 Epoch: 208, lr: 2.0e-03, train_loss: 0.2884, train_acc: 0.9026 test_loss: 0.9755, test_acc: 0.7480, best: 0.7542, time: 0:01:35
 Epoch: 209, lr: 2.0e-03, train_loss: 0.2661, train_acc: 0.9114 test_loss: 0.9462, test_acc: 0.7504, best: 0.7542, time: 0:01:36
 Epoch: 210, lr: 2.0e-03, train_loss: 0.2703, train_acc: 0.9096 test_loss: 0.9626, test_acc: 0.7519, best: 0.7542, time: 0:01:36
 Epoch: 211, lr: 2.0e-03, train_loss: 0.2801, train_acc: 0.9084 test_loss: 0.9603, test_acc: 0.7552, best: 0.7552, time: 0:01:37
 Epoch: 212, lr: 2.0e-03, train_loss: 0.2677, train_acc: 0.9102 test_loss: 0.9945, test_acc: 0.7475, best: 0.7552, time: 0:01:34
 Epoch: 213, lr: 2.0e-03, train_loss: 0.2686, train_acc: 0.9074 test_loss: 0.9808, test_acc: 0.7505, best: 0.7552, time: 0:01:36
 Epoch: 214, lr: 2.0e-03, train_loss: 0.2677, train_acc: 0.9108 test_loss: 0.9728, test_acc: 0.7494, best: 0.7552, time: 0:01:35
 Epoch: 215, lr: 2.0e-03, train_loss: 0.2835, train_acc: 0.8994 test_loss: 0.9704, test_acc: 0.7510, best: 0.7552, time: 0:01:35
 Epoch: 216, lr: 2.0e-03, train_loss: 0.2615, train_acc: 0.9100 test_loss: 0.9592, test_acc: 0.7515, best: 0.7552, time: 0:01:36
 Epoch: 217, lr: 2.0e-03, train_loss: 0.2662, train_acc: 0.9094 test_loss: 0.9604, test_acc: 0.7549, best: 0.7552, time: 0:01:35
 Epoch: 218, lr: 2.0e-03, train_loss: 0.2506, train_acc: 0.9172 test_loss: 0.9571, test_acc: 0.7544, best: 0.7552, time: 0:01:34
 Epoch: 219, lr: 2.0e-03, train_loss: 0.2676, train_acc: 0.9074 test_loss: 0.9882, test_acc: 0.7508, best: 0.7552, time: 0:01:34
 Epoch: 220, lr: 2.0e-03, train_loss: 0.2785, train_acc: 0.9006 test_loss: 0.9781, test_acc: 0.7512, best: 0.7552, time: 0:01:33
 Epoch: 221, lr: 2.0e-03, train_loss: 0.2594, train_acc: 0.9108 test_loss: 0.9554, test_acc: 0.7579, best: 0.7579, time: 0:01:34
 Epoch: 222, lr: 2.0e-03, train_loss: 0.2716, train_acc: 0.9086 test_loss: 0.9554, test_acc: 0.7578, best: 0.7579, time: 0:01:35
 Epoch: 223, lr: 2.0e-03, train_loss: 0.2546, train_acc: 0.9122 test_loss: 0.9598, test_acc: 0.7514, best: 0.7579, time: 0:01:35
 Epoch: 224, lr: 2.0e-03, train_loss: 0.2741, train_acc: 0.9018 test_loss: 0.9803, test_acc: 0.7505, best: 0.7579, time: 0:01:34
 Epoch: 225, lr: 2.0e-03, train_loss: 0.2541, train_acc: 0.9142 test_loss: 0.9999, test_acc: 0.7489, best: 0.7579, time: 0:01:34
 Epoch: 226, lr: 2.0e-03, train_loss: 0.2577, train_acc: 0.9136 test_loss: 0.9750, test_acc: 0.7451, best: 0.7579, time: 0:01:35
 Epoch: 227, lr: 2.0e-03, train_loss: 0.2635, train_acc: 0.9114 test_loss: 0.9521, test_acc: 0.7515, best: 0.7579, time: 0:01:35
 Epoch: 228, lr: 2.0e-03, train_loss: 0.2562, train_acc: 0.9084 test_loss: 0.9817, test_acc: 0.7465, best: 0.7579, time: 0:01:36
 Epoch: 229, lr: 2.0e-03, train_loss: 0.2442, train_acc: 0.9246 test_loss: 0.9920, test_acc: 0.7450, best: 0.7579, time: 0:01:35
 Epoch: 230, lr: 2.0e-03, train_loss: 0.2564, train_acc: 0.9110 test_loss: 0.9657, test_acc: 0.7524, best: 0.7579, time: 0:01:35
 Epoch: 231, lr: 2.0e-03, train_loss: 0.2515, train_acc: 0.9172 test_loss: 0.9658, test_acc: 0.7515, best: 0.7579, time: 0:01:36
 Epoch: 232, lr: 2.0e-03, train_loss: 0.2601, train_acc: 0.9126 test_loss: 0.9695, test_acc: 0.7544, best: 0.7579, time: 0:01:35
 Epoch: 233, lr: 2.0e-03, train_loss: 0.2620, train_acc: 0.9142 test_loss: 1.0030, test_acc: 0.7462, best: 0.7579, time: 0:01:37
 Epoch: 234, lr: 2.0e-03, train_loss: 0.2473, train_acc: 0.9148 test_loss: 1.0099, test_acc: 0.7471, best: 0.7579, time: 0:01:34
 Epoch: 235, lr: 2.0e-03, train_loss: 0.2515, train_acc: 0.9128 test_loss: 0.9852, test_acc: 0.7550, best: 0.7579, time: 0:01:35
 Epoch: 236, lr: 2.0e-03, train_loss: 0.2435, train_acc: 0.9188 test_loss: 0.9637, test_acc: 0.7554, best: 0.7579, time: 0:01:36
 Epoch: 237, lr: 2.0e-03, train_loss: 0.2578, train_acc: 0.9122 test_loss: 0.9734, test_acc: 0.7511, best: 0.7579, time: 0:01:34
 Epoch: 238, lr: 2.0e-03, train_loss: 0.2562, train_acc: 0.9154 test_loss: 0.9525, test_acc: 0.7542, best: 0.7579, time: 0:01:35
 Epoch: 239, lr: 2.0e-03, train_loss: 0.2508, train_acc: 0.9176 test_loss: 0.9523, test_acc: 0.7545, best: 0.7579, time: 0:01:33
 Epoch: 240, lr: 4.0e-04, train_loss: 0.2401, train_acc: 0.9148 test_loss: 0.9689, test_acc: 0.7552, best: 0.7579, time: 0:01:34
 Epoch: 241, lr: 4.0e-04, train_loss: 0.2494, train_acc: 0.9148 test_loss: 0.9467, test_acc: 0.7602, best: 0.7602, time: 0:01:36
 Epoch: 242, lr: 4.0e-04, train_loss: 0.2352, train_acc: 0.9188 test_loss: 0.9773, test_acc: 0.7544, best: 0.7602, time: 0:01:35
 Epoch: 243, lr: 4.0e-04, train_loss: 0.2393, train_acc: 0.9212 test_loss: 0.9578, test_acc: 0.7580, best: 0.7602, time: 0:01:35
 Epoch: 244, lr: 4.0e-04, train_loss: 0.2478, train_acc: 0.9176 test_loss: 0.9753, test_acc: 0.7571, best: 0.7602, time: 0:01:34
 Epoch: 245, lr: 4.0e-04, train_loss: 0.2366, train_acc: 0.9222 test_loss: 0.9782, test_acc: 0.7588, best: 0.7602, time: 0:01:35
 Epoch: 246, lr: 4.0e-04, train_loss: 0.2331, train_acc: 0.9172 test_loss: 0.9666, test_acc: 0.7531, best: 0.7602, time: 0:01:35
 Epoch: 247, lr: 4.0e-04, train_loss: 0.2367, train_acc: 0.9208 test_loss: 0.9855, test_acc: 0.7508, best: 0.7602, time: 0:01:35
 Epoch: 248, lr: 4.0e-04, train_loss: 0.2384, train_acc: 0.9204 test_loss: 0.9602, test_acc: 0.7566, best: 0.7602, time: 0:01:35
 Epoch: 249, lr: 4.0e-04, train_loss: 0.2360, train_acc: 0.9194 test_loss: 0.9657, test_acc: 0.7574, best: 0.7602, time: 0:01:36
 Epoch: 250, lr: 4.0e-04, train_loss: 0.2258, train_acc: 0.9268 test_loss: 0.9573, test_acc: 0.7584, best: 0.7602, time: 0:01:36
 Epoch: 251, lr: 4.0e-04, train_loss: 0.2429, train_acc: 0.9200 test_loss: 0.9706, test_acc: 0.7546, best: 0.7602, time: 0:01:36
 Epoch: 252, lr: 4.0e-04, train_loss: 0.2452, train_acc: 0.9178 test_loss: 0.9537, test_acc: 0.7554, best: 0.7602, time: 0:01:37
 Epoch: 253, lr: 4.0e-04, train_loss: 0.2356, train_acc: 0.9234 test_loss: 0.9660, test_acc: 0.7545, best: 0.7602, time: 0:01:35
 Epoch: 254, lr: 4.0e-04, train_loss: 0.2470, train_acc: 0.9152 test_loss: 0.9589, test_acc: 0.7568, best: 0.7602, time: 0:01:34
 Epoch: 255, lr: 4.0e-04, train_loss: 0.2303, train_acc: 0.9246 test_loss: 0.9602, test_acc: 0.7534, best: 0.7602, time: 0:01:35
 Epoch: 256, lr: 4.0e-04, train_loss: 0.2281, train_acc: 0.9230 test_loss: 0.9785, test_acc: 0.7516, best: 0.7602, time: 0:01:34
 Epoch: 257, lr: 4.0e-04, train_loss: 0.2213, train_acc: 0.9218 test_loss: 0.9583, test_acc: 0.7539, best: 0.7602, time: 0:01:35
 Epoch: 258, lr: 4.0e-04, train_loss: 0.2313, train_acc: 0.9208 test_loss: 0.9759, test_acc: 0.7541, best: 0.7602, time: 0:01:34
 Epoch: 259, lr: 4.0e-04, train_loss: 0.2432, train_acc: 0.9170 test_loss: 0.9687, test_acc: 0.7564, best: 0.7602, time: 0:01:36
 Epoch: 260, lr: 4.0e-04, train_loss: 0.2310, train_acc: 0.9204 test_loss: 0.9861, test_acc: 0.7541, best: 0.7602, time: 0:01:36
 Epoch: 261, lr: 4.0e-04, train_loss: 0.2235, train_acc: 0.9270 test_loss: 0.9716, test_acc: 0.7582, best: 0.7602, time: 0:01:35
 Epoch: 262, lr: 4.0e-04, train_loss: 0.2220, train_acc: 0.9248 test_loss: 0.9859, test_acc: 0.7522, best: 0.7602, time: 0:01:36
 Epoch: 263, lr: 4.0e-04, train_loss: 0.2500, train_acc: 0.9192 test_loss: 0.9418, test_acc: 0.7575, best: 0.7602, time: 0:01:35
 Epoch: 264, lr: 4.0e-04, train_loss: 0.2362, train_acc: 0.9216 test_loss: 0.9721, test_acc: 0.7515, best: 0.7602, time: 0:01:36
 Epoch: 265, lr: 4.0e-04, train_loss: 0.2256, train_acc: 0.9224 test_loss: 0.9807, test_acc: 0.7532, best: 0.7602, time: 0:01:35
 Epoch: 266, lr: 4.0e-04, train_loss: 0.2473, train_acc: 0.9156 test_loss: 0.9690, test_acc: 0.7562, best: 0.7602, time: 0:01:35
 Epoch: 267, lr: 4.0e-04, train_loss: 0.2239, train_acc: 0.9240 test_loss: 0.9765, test_acc: 0.7518, best: 0.7602, time: 0:01:36
 Epoch: 268, lr: 4.0e-04, train_loss: 0.2100, train_acc: 0.9288 test_loss: 0.9681, test_acc: 0.7514, best: 0.7602, time: 0:01:35
 Epoch: 269, lr: 4.0e-04, train_loss: 0.2472, train_acc: 0.9162 test_loss: 0.9805, test_acc: 0.7570, best: 0.7602, time: 0:01:34
 Epoch: 270, lr: 8.0e-05, train_loss: 0.2255, train_acc: 0.9270 test_loss: 0.9591, test_acc: 0.7529, best: 0.7602, time: 0:01:35
 Epoch: 271, lr: 8.0e-05, train_loss: 0.2235, train_acc: 0.9248 test_loss: 0.9768, test_acc: 0.7540, best: 0.7602, time: 0:01:35
 Epoch: 272, lr: 8.0e-05, train_loss: 0.2296, train_acc: 0.9244 test_loss: 0.9822, test_acc: 0.7558, best: 0.7602, time: 0:01:34
 Epoch: 273, lr: 8.0e-05, train_loss: 0.2326, train_acc: 0.9214 test_loss: 0.9588, test_acc: 0.7574, best: 0.7602, time: 0:01:35
 Epoch: 274, lr: 8.0e-05, train_loss: 0.2316, train_acc: 0.9200 test_loss: 0.9733, test_acc: 0.7569, best: 0.7602, time: 0:01:35
 Epoch: 275, lr: 8.0e-05, train_loss: 0.2226, train_acc: 0.9236 test_loss: 0.9795, test_acc: 0.7504, best: 0.7602, time: 0:01:34
 Epoch: 276, lr: 8.0e-05, train_loss: 0.2358, train_acc: 0.9240 test_loss: 0.9754, test_acc: 0.7535, best: 0.7602, time: 0:01:35
 Epoch: 277, lr: 8.0e-05, train_loss: 0.2312, train_acc: 0.9230 test_loss: 0.9723, test_acc: 0.7525, best: 0.7602, time: 0:01:36
 Epoch: 278, lr: 8.0e-05, train_loss: 0.2247, train_acc: 0.9214 test_loss: 0.9747, test_acc: 0.7536, best: 0.7602, time: 0:01:35
 Epoch: 279, lr: 8.0e-05, train_loss: 0.2345, train_acc: 0.9204 test_loss: 0.9801, test_acc: 0.7561, best: 0.7602, time: 0:01:36
 Epoch: 280, lr: 8.0e-05, train_loss: 0.2341, train_acc: 0.9228 test_loss: 0.9771, test_acc: 0.7564, best: 0.7602, time: 0:01:35
 Epoch: 281, lr: 8.0e-05, train_loss: 0.2141, train_acc: 0.9238 test_loss: 0.9550, test_acc: 0.7521, best: 0.7602, time: 0:01:35
 Epoch: 282, lr: 8.0e-05, train_loss: 0.2162, train_acc: 0.9268 test_loss: 0.9993, test_acc: 0.7538, best: 0.7602, time: 0:01:36
 Epoch: 283, lr: 8.0e-05, train_loss: 0.2337, train_acc: 0.9216 test_loss: 0.9629, test_acc: 0.7568, best: 0.7602, time: 0:01:36
 Epoch: 284, lr: 8.0e-05, train_loss: 0.2241, train_acc: 0.9246 test_loss: 0.9738, test_acc: 0.7541, best: 0.7602, time: 0:01:36
 Epoch: 285, lr: 8.0e-05, train_loss: 0.2432, train_acc: 0.9172 test_loss: 0.9644, test_acc: 0.7530, best: 0.7602, time: 0:01:35
 Epoch: 286, lr: 8.0e-05, train_loss: 0.2182, train_acc: 0.9242 test_loss: 0.9724, test_acc: 0.7544, best: 0.7602, time: 0:01:37
 Epoch: 287, lr: 8.0e-05, train_loss: 0.2361, train_acc: 0.9208 test_loss: 0.9878, test_acc: 0.7525, best: 0.7602, time: 0:01:35
 Epoch: 288, lr: 8.0e-05, train_loss: 0.2232, train_acc: 0.9274 test_loss: 0.9737, test_acc: 0.7545, best: 0.7602, time: 0:01:37
 Epoch: 289, lr: 8.0e-05, train_loss: 0.2258, train_acc: 0.9220 test_loss: 0.9771, test_acc: 0.7528, best: 0.7602, time: 0:01:36
 Epoch: 290, lr: 8.0e-05, train_loss: 0.2191, train_acc: 0.9222 test_loss: 0.9642, test_acc: 0.7571, best: 0.7602, time: 0:01:35
 Epoch: 291, lr: 8.0e-05, train_loss: 0.2262, train_acc: 0.9214 test_loss: 0.9974, test_acc: 0.7542, best: 0.7602, time: 0:01:36
 Epoch: 292, lr: 8.0e-05, train_loss: 0.2211, train_acc: 0.9204 test_loss: 0.9614, test_acc: 0.7556, best: 0.7602, time: 0:01:37
 Epoch: 293, lr: 8.0e-05, train_loss: 0.2243, train_acc: 0.9200 test_loss: 0.9828, test_acc: 0.7540, best: 0.7602, time: 0:01:35
 Epoch: 294, lr: 8.0e-05, train_loss: 0.2180, train_acc: 0.9228 test_loss: 0.9538, test_acc: 0.7538, best: 0.7602, time: 0:01:35
 Epoch: 295, lr: 8.0e-05, train_loss: 0.2452, train_acc: 0.9166 test_loss: 0.9611, test_acc: 0.7539, best: 0.7602, time: 0:01:35
 Epoch: 296, lr: 8.0e-05, train_loss: 0.2222, train_acc: 0.9246 test_loss: 0.9638, test_acc: 0.7548, best: 0.7602, time: 0:01:34
 Epoch: 297, lr: 8.0e-05, train_loss: 0.2270, train_acc: 0.9258 test_loss: 0.9456, test_acc: 0.7586, best: 0.7602, time: 0:01:35
 Epoch: 298, lr: 8.0e-05, train_loss: 0.2188, train_acc: 0.9264 test_loss: 0.9723, test_acc: 0.7511, best: 0.7602, time: 0:01:36
 Epoch: 299, lr: 8.0e-05, train_loss: 0.2326, train_acc: 0.9202 test_loss: 0.9892, test_acc: 0.7540, best: 0.7602, time: 0:01:35
 Highest accuracy: 0.7602