
 Run on time: 2022-06-30 11:30:16.929221

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : PREPOOL_RESNET18_NLP_8
	 im_size              : None
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): NetworkByName(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): Pool2d(
        (logit): Sequential(
          (pool_weight): NLP_BASE(
            (downsample): Sequential(
              (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (restore): Sequential(
              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Sigmoid()
            )
            (pos_embed): PositionEmbeddingLearned(
              (row_embed): Embedding(256, 32)
              (col_embed): Embedding(256, 32)
            )
          )
        )
        (pool): AvgPool2d(kernel_size=8, stride=8, padding=0)
      )
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3905, train_acc: 0.1792 test_loss: 2.0531, test_acc: 0.2343, best: 0.2343, time: 0:02:55
 Epoch: 2, lr: 1.0e-02, train_loss: 2.0152, train_acc: 0.2334 test_loss: 1.8768, test_acc: 0.2831, best: 0.2831, time: 0:02:55
 Epoch: 3, lr: 1.0e-02, train_loss: 1.9244, train_acc: 0.2662 test_loss: 1.7232, test_acc: 0.3519, best: 0.3519, time: 0:02:55
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8834, train_acc: 0.2892 test_loss: 1.6371, test_acc: 0.3766, best: 0.3766, time: 0:02:55
 Epoch: 5, lr: 1.0e-02, train_loss: 1.8343, train_acc: 0.2970 test_loss: 1.6444, test_acc: 0.3837, best: 0.3837, time: 0:02:55
 Epoch: 6, lr: 1.0e-02, train_loss: 1.8062, train_acc: 0.3210 test_loss: 1.5815, test_acc: 0.4000, best: 0.4000, time: 0:02:55
 Epoch: 7, lr: 1.0e-02, train_loss: 1.7858, train_acc: 0.3284 test_loss: 1.5372, test_acc: 0.4109, best: 0.4109, time: 0:02:55
 Epoch: 8, lr: 1.0e-02, train_loss: 1.7606, train_acc: 0.3520 test_loss: 1.5534, test_acc: 0.4110, best: 0.4110, time: 0:02:55
 Epoch: 9, lr: 1.0e-02, train_loss: 1.7545, train_acc: 0.3366 test_loss: 1.5152, test_acc: 0.4300, best: 0.4300, time: 0:02:55
 Epoch: 10, lr: 1.0e-02, train_loss: 1.7056, train_acc: 0.3672 test_loss: 1.4720, test_acc: 0.4462, best: 0.4462, time: 0:02:55
 Epoch: 11, lr: 1.0e-02, train_loss: 1.6718, train_acc: 0.3730 test_loss: 1.5023, test_acc: 0.4409, best: 0.4462, time: 0:02:55
 Epoch: 12, lr: 1.0e-02, train_loss: 1.6520, train_acc: 0.3854 test_loss: 1.4508, test_acc: 0.4596, best: 0.4596, time: 0:02:55
 Epoch: 13, lr: 1.0e-02, train_loss: 1.6232, train_acc: 0.3942 test_loss: 1.4743, test_acc: 0.4504, best: 0.4596, time: 0:02:55
 Epoch: 14, lr: 1.0e-02, train_loss: 1.5971, train_acc: 0.4062 test_loss: 1.3629, test_acc: 0.4993, best: 0.4993, time: 0:02:55
 Epoch: 15, lr: 1.0e-02, train_loss: 1.5855, train_acc: 0.4122 test_loss: 1.3742, test_acc: 0.4899, best: 0.4993, time: 0:02:55
 Epoch: 16, lr: 1.0e-02, train_loss: 1.5553, train_acc: 0.4334 test_loss: 1.4052, test_acc: 0.4739, best: 0.4993, time: 0:02:55
 Epoch: 17, lr: 1.0e-02, train_loss: 1.5397, train_acc: 0.4292 test_loss: 1.3737, test_acc: 0.4870, best: 0.4993, time: 0:02:55
 Epoch: 18, lr: 1.0e-02, train_loss: 1.5205, train_acc: 0.4390 test_loss: 1.3262, test_acc: 0.5024, best: 0.5024, time: 0:02:55
 Epoch: 19, lr: 1.0e-02, train_loss: 1.5002, train_acc: 0.4534 test_loss: 1.3698, test_acc: 0.4901, best: 0.5024, time: 0:02:54
 Epoch: 20, lr: 1.0e-02, train_loss: 1.4554, train_acc: 0.4576 test_loss: 1.2887, test_acc: 0.5175, best: 0.5175, time: 0:02:55
 Epoch: 21, lr: 1.0e-02, train_loss: 1.4572, train_acc: 0.4528 test_loss: 1.2843, test_acc: 0.5208, best: 0.5208, time: 0:02:55
 Epoch: 22, lr: 1.0e-02, train_loss: 1.4523, train_acc: 0.4636 test_loss: 1.2793, test_acc: 0.5280, best: 0.5280, time: 0:02:55
 Epoch: 23, lr: 1.0e-02, train_loss: 1.4116, train_acc: 0.4812 test_loss: 1.2728, test_acc: 0.5344, best: 0.5344, time: 0:02:55
 Epoch: 24, lr: 1.0e-02, train_loss: 1.4151, train_acc: 0.4776 test_loss: 1.2141, test_acc: 0.5501, best: 0.5501, time: 0:02:55
 Epoch: 25, lr: 1.0e-02, train_loss: 1.4031, train_acc: 0.4876 test_loss: 1.3168, test_acc: 0.5425, best: 0.5501, time: 0:02:54
 Epoch: 26, lr: 1.0e-02, train_loss: 1.3796, train_acc: 0.4902 test_loss: 1.2925, test_acc: 0.5239, best: 0.5501, time: 0:02:54
 Epoch: 27, lr: 1.0e-02, train_loss: 1.3580, train_acc: 0.5064 test_loss: 1.2153, test_acc: 0.5555, best: 0.5555, time: 0:02:55
 Epoch: 28, lr: 1.0e-02, train_loss: 1.3404, train_acc: 0.5070 test_loss: 1.2177, test_acc: 0.5570, best: 0.5570, time: 0:02:55
 Epoch: 29, lr: 1.0e-02, train_loss: 1.3179, train_acc: 0.5156 test_loss: 1.2164, test_acc: 0.5623, best: 0.5623, time: 0:02:55
 Epoch: 30, lr: 1.0e-02, train_loss: 1.3273, train_acc: 0.5072 test_loss: 1.1261, test_acc: 0.5883, best: 0.5883, time: 0:02:55
 Epoch: 31, lr: 1.0e-02, train_loss: 1.3216, train_acc: 0.5178 test_loss: 1.1711, test_acc: 0.5795, best: 0.5883, time: 0:02:54
 Epoch: 32, lr: 1.0e-02, train_loss: 1.2886, train_acc: 0.5358 test_loss: 1.1024, test_acc: 0.6024, best: 0.6024, time: 0:02:55
 Epoch: 33, lr: 1.0e-02, train_loss: 1.2868, train_acc: 0.5238 test_loss: 1.1735, test_acc: 0.5770, best: 0.6024, time: 0:02:54
 Epoch: 34, lr: 1.0e-02, train_loss: 1.2573, train_acc: 0.5388 test_loss: 1.2244, test_acc: 0.5664, best: 0.6024, time: 0:02:54
 Epoch: 35, lr: 1.0e-02, train_loss: 1.2539, train_acc: 0.5458 test_loss: 1.0778, test_acc: 0.6076, best: 0.6076, time: 0:02:55
 Epoch: 36, lr: 1.0e-02, train_loss: 1.2544, train_acc: 0.5426 test_loss: 1.1573, test_acc: 0.5835, best: 0.6076, time: 0:02:54
 Epoch: 37, lr: 1.0e-02, train_loss: 1.2254, train_acc: 0.5570 test_loss: 1.1164, test_acc: 0.6045, best: 0.6076, time: 0:02:54
 Epoch: 38, lr: 1.0e-02, train_loss: 1.2312, train_acc: 0.5576 test_loss: 1.1607, test_acc: 0.5907, best: 0.6076, time: 0:02:54
 Epoch: 39, lr: 1.0e-02, train_loss: 1.2202, train_acc: 0.5592 test_loss: 1.2697, test_acc: 0.5496, best: 0.6076, time: 0:02:54
 Epoch: 40, lr: 1.0e-02, train_loss: 1.2213, train_acc: 0.5550 test_loss: 1.1971, test_acc: 0.5856, best: 0.6076, time: 0:02:54
 Epoch: 41, lr: 1.0e-02, train_loss: 1.1916, train_acc: 0.5732 test_loss: 1.0930, test_acc: 0.6091, best: 0.6091, time: 0:02:55
 Epoch: 42, lr: 1.0e-02, train_loss: 1.1819, train_acc: 0.5716 test_loss: 1.1852, test_acc: 0.5913, best: 0.6091, time: 0:02:54
 Epoch: 43, lr: 1.0e-02, train_loss: 1.1838, train_acc: 0.5608 test_loss: 1.1230, test_acc: 0.5958, best: 0.6091, time: 0:02:54
 Epoch: 44, lr: 1.0e-02, train_loss: 1.1729, train_acc: 0.5720 test_loss: 1.0449, test_acc: 0.6231, best: 0.6231, time: 0:02:55
 Epoch: 45, lr: 1.0e-02, train_loss: 1.1409, train_acc: 0.5854 test_loss: 1.0259, test_acc: 0.6358, best: 0.6358, time: 0:02:55
 Epoch: 46, lr: 1.0e-02, train_loss: 1.1577, train_acc: 0.5776 test_loss: 1.3676, test_acc: 0.5520, best: 0.6358, time: 0:02:54
 Epoch: 47, lr: 1.0e-02, train_loss: 1.1374, train_acc: 0.5872 test_loss: 1.0855, test_acc: 0.6178, best: 0.6358, time: 0:02:54
 Epoch: 48, lr: 1.0e-02, train_loss: 1.1390, train_acc: 0.5898 test_loss: 1.1179, test_acc: 0.6104, best: 0.6358, time: 0:02:54
 Epoch: 49, lr: 1.0e-02, train_loss: 1.1216, train_acc: 0.5950 test_loss: 1.0503, test_acc: 0.6269, best: 0.6358, time: 0:02:54
 Epoch: 50, lr: 1.0e-02, train_loss: 1.0945, train_acc: 0.6046 test_loss: 1.1301, test_acc: 0.6048, best: 0.6358, time: 0:02:54
 Epoch: 51, lr: 1.0e-02, train_loss: 1.1210, train_acc: 0.5872 test_loss: 1.0509, test_acc: 0.6324, best: 0.6358, time: 0:02:54
 Epoch: 52, lr: 1.0e-02, train_loss: 1.0995, train_acc: 0.6062 test_loss: 1.2274, test_acc: 0.5910, best: 0.6358, time: 0:02:54
 Epoch: 53, lr: 1.0e-02, train_loss: 1.1033, train_acc: 0.6022 test_loss: 1.1254, test_acc: 0.6078, best: 0.6358, time: 0:02:54
 Epoch: 54, lr: 1.0e-02, train_loss: 1.0908, train_acc: 0.5990 test_loss: 1.0837, test_acc: 0.6240, best: 0.6358, time: 0:02:54
 Epoch: 55, lr: 1.0e-02, train_loss: 1.1044, train_acc: 0.6044 test_loss: 1.0144, test_acc: 0.6409, best: 0.6409, time: 0:02:55
 Epoch: 56, lr: 1.0e-02, train_loss: 1.0617, train_acc: 0.6136 test_loss: 1.0411, test_acc: 0.6388, best: 0.6409, time: 0:02:54
 Epoch: 57, lr: 1.0e-02, train_loss: 1.0538, train_acc: 0.6172 test_loss: 0.9733, test_acc: 0.6498, best: 0.6498, time: 0:02:55
 Epoch: 58, lr: 1.0e-02, train_loss: 1.0444, train_acc: 0.6244 test_loss: 1.0922, test_acc: 0.6286, best: 0.6498, time: 0:02:54
 Epoch: 59, lr: 1.0e-02, train_loss: 1.0514, train_acc: 0.6204 test_loss: 1.0257, test_acc: 0.6379, best: 0.6498, time: 0:02:54
 Epoch: 60, lr: 1.0e-02, train_loss: 1.0288, train_acc: 0.6190 test_loss: 1.0886, test_acc: 0.6371, best: 0.6498, time: 0:02:54
 Epoch: 61, lr: 1.0e-02, train_loss: 1.0400, train_acc: 0.6188 test_loss: 1.0305, test_acc: 0.6422, best: 0.6498, time: 0:02:54
 Epoch: 62, lr: 1.0e-02, train_loss: 1.0181, train_acc: 0.6362 test_loss: 1.0765, test_acc: 0.6240, best: 0.6498, time: 0:02:53
 Epoch: 63, lr: 1.0e-02, train_loss: 1.0360, train_acc: 0.6338 test_loss: 1.0969, test_acc: 0.6389, best: 0.6498, time: 0:02:53
 Epoch: 64, lr: 1.0e-02, train_loss: 0.9935, train_acc: 0.6420 test_loss: 1.0622, test_acc: 0.6344, best: 0.6498, time: 0:02:53
 Epoch: 65, lr: 1.0e-02, train_loss: 0.9902, train_acc: 0.6394 test_loss: 1.0227, test_acc: 0.6475, best: 0.6498, time: 0:02:53
 Epoch: 66, lr: 1.0e-02, train_loss: 0.9976, train_acc: 0.6300 test_loss: 1.0324, test_acc: 0.6466, best: 0.6498, time: 0:02:53
 Epoch: 67, lr: 1.0e-02, train_loss: 0.9749, train_acc: 0.6454 test_loss: 0.9958, test_acc: 0.6640, best: 0.6640, time: 0:02:54
 Epoch: 68, lr: 1.0e-02, train_loss: 0.9770, train_acc: 0.6470 test_loss: 1.0461, test_acc: 0.6428, best: 0.6640, time: 0:02:53
 Epoch: 69, lr: 1.0e-02, train_loss: 0.9807, train_acc: 0.6420 test_loss: 0.9988, test_acc: 0.6576, best: 0.6640, time: 0:02:53
 Epoch: 70, lr: 1.0e-02, train_loss: 0.9796, train_acc: 0.6550 test_loss: 0.9921, test_acc: 0.6529, best: 0.6640, time: 0:02:53
 Epoch: 71, lr: 1.0e-02, train_loss: 0.9747, train_acc: 0.6540 test_loss: 0.9975, test_acc: 0.6577, best: 0.6640, time: 0:02:53
 Epoch: 72, lr: 1.0e-02, train_loss: 0.9359, train_acc: 0.6602 test_loss: 1.0419, test_acc: 0.6571, best: 0.6640, time: 0:02:53
 Epoch: 73, lr: 1.0e-02, train_loss: 0.9653, train_acc: 0.6474 test_loss: 0.9971, test_acc: 0.6663, best: 0.6663, time: 0:02:53
 Epoch: 74, lr: 1.0e-02, train_loss: 0.9533, train_acc: 0.6564 test_loss: 1.0276, test_acc: 0.6451, best: 0.6663, time: 0:02:53
 Epoch: 75, lr: 1.0e-02, train_loss: 0.9322, train_acc: 0.6694 test_loss: 1.0497, test_acc: 0.6542, best: 0.6663, time: 0:02:53
 Epoch: 76, lr: 1.0e-02, train_loss: 0.9397, train_acc: 0.6708 test_loss: 1.0034, test_acc: 0.6649, best: 0.6663, time: 0:02:53
 Epoch: 77, lr: 1.0e-02, train_loss: 0.9222, train_acc: 0.6716 test_loss: 1.0841, test_acc: 0.6518, best: 0.6663, time: 0:02:53
 Epoch: 78, lr: 1.0e-02, train_loss: 0.9253, train_acc: 0.6710 test_loss: 1.1103, test_acc: 0.6362, best: 0.6663, time: 0:02:53
 Epoch: 79, lr: 1.0e-02, train_loss: 0.9055, train_acc: 0.6776 test_loss: 0.9779, test_acc: 0.6753, best: 0.6753, time: 0:02:53
 Epoch: 80, lr: 1.0e-02, train_loss: 0.9156, train_acc: 0.6654 test_loss: 0.9886, test_acc: 0.6700, best: 0.6753, time: 0:02:53
 Epoch: 81, lr: 1.0e-02, train_loss: 0.9134, train_acc: 0.6728 test_loss: 0.9649, test_acc: 0.6755, best: 0.6755, time: 0:02:53
 Epoch: 82, lr: 1.0e-02, train_loss: 0.8942, train_acc: 0.6838 test_loss: 1.0017, test_acc: 0.6687, best: 0.6755, time: 0:02:53
 Epoch: 83, lr: 1.0e-02, train_loss: 0.8975, train_acc: 0.6868 test_loss: 0.9993, test_acc: 0.6719, best: 0.6755, time: 0:02:53
 Epoch: 84, lr: 1.0e-02, train_loss: 0.8881, train_acc: 0.6806 test_loss: 0.9664, test_acc: 0.6753, best: 0.6755, time: 0:02:53
 Epoch: 85, lr: 1.0e-02, train_loss: 0.8805, train_acc: 0.6842 test_loss: 0.9730, test_acc: 0.6753, best: 0.6755, time: 0:02:53
 Epoch: 86, lr: 1.0e-02, train_loss: 0.8959, train_acc: 0.6858 test_loss: 1.0279, test_acc: 0.6521, best: 0.6755, time: 0:02:53
 Epoch: 87, lr: 1.0e-02, train_loss: 0.8544, train_acc: 0.6956 test_loss: 1.0399, test_acc: 0.6657, best: 0.6755, time: 0:02:53
 Epoch: 88, lr: 1.0e-02, train_loss: 0.8909, train_acc: 0.6818 test_loss: 0.9834, test_acc: 0.6726, best: 0.6755, time: 0:02:53
 Epoch: 89, lr: 1.0e-02, train_loss: 0.8812, train_acc: 0.6824 test_loss: 0.9892, test_acc: 0.6721, best: 0.6755, time: 0:02:53
 Epoch: 90, lr: 1.0e-02, train_loss: 0.8604, train_acc: 0.6932 test_loss: 0.9962, test_acc: 0.6705, best: 0.6755, time: 0:02:53
 Epoch: 91, lr: 1.0e-02, train_loss: 0.8809, train_acc: 0.6796 test_loss: 0.9404, test_acc: 0.6860, best: 0.6860, time: 0:02:53
 Epoch: 92, lr: 1.0e-02, train_loss: 0.8479, train_acc: 0.7022 test_loss: 1.1416, test_acc: 0.6560, best: 0.6860, time: 0:02:53
 Epoch: 93, lr: 1.0e-02, train_loss: 0.8574, train_acc: 0.6908 test_loss: 0.9838, test_acc: 0.6723, best: 0.6860, time: 0:02:53
 Epoch: 94, lr: 1.0e-02, train_loss: 0.8305, train_acc: 0.7064 test_loss: 1.0639, test_acc: 0.6705, best: 0.6860, time: 0:02:53
 Epoch: 95, lr: 1.0e-02, train_loss: 0.8136, train_acc: 0.7120 test_loss: 0.9529, test_acc: 0.6847, best: 0.6860, time: 0:02:53
 Epoch: 96, lr: 1.0e-02, train_loss: 0.8372, train_acc: 0.7042 test_loss: 0.9629, test_acc: 0.6783, best: 0.6860, time: 0:02:53
 Epoch: 97, lr: 1.0e-02, train_loss: 0.8272, train_acc: 0.7068 test_loss: 0.9559, test_acc: 0.6829, best: 0.6860, time: 0:02:53
 Epoch: 98, lr: 1.0e-02, train_loss: 0.8272, train_acc: 0.7036 test_loss: 0.9580, test_acc: 0.6770, best: 0.6860, time: 0:02:53
 Epoch: 99, lr: 1.0e-02, train_loss: 0.8166, train_acc: 0.7080 test_loss: 1.1281, test_acc: 0.6564, best: 0.6860, time: 0:02:53
 Epoch: 100, lr: 1.0e-02, train_loss: 0.8298, train_acc: 0.7062 test_loss: 0.9859, test_acc: 0.6819, best: 0.6860, time: 0:02:53
 Epoch: 101, lr: 1.0e-02, train_loss: 0.8135, train_acc: 0.7108 test_loss: 0.9738, test_acc: 0.6856, best: 0.6860, time: 0:02:53
 Epoch: 102, lr: 1.0e-02, train_loss: 0.8139, train_acc: 0.7106 test_loss: 0.9873, test_acc: 0.6814, best: 0.6860, time: 0:02:53
 Epoch: 103, lr: 1.0e-02, train_loss: 0.8118, train_acc: 0.7144 test_loss: 0.9194, test_acc: 0.6970, best: 0.6970, time: 0:02:53
 Epoch: 104, lr: 1.0e-02, train_loss: 0.7940, train_acc: 0.7198 test_loss: 0.9979, test_acc: 0.6815, best: 0.6970, time: 0:02:53
 Epoch: 105, lr: 1.0e-02, train_loss: 0.8090, train_acc: 0.7136 test_loss: 1.0566, test_acc: 0.6706, best: 0.6970, time: 0:02:53
 Epoch: 106, lr: 1.0e-02, train_loss: 0.7756, train_acc: 0.7322 test_loss: 0.9685, test_acc: 0.6880, best: 0.6970, time: 0:02:53
 Epoch: 107, lr: 1.0e-02, train_loss: 0.7827, train_acc: 0.7216 test_loss: 1.0286, test_acc: 0.6775, best: 0.6970, time: 0:02:53
 Epoch: 108, lr: 1.0e-02, train_loss: 0.7971, train_acc: 0.7206 test_loss: 1.0208, test_acc: 0.6855, best: 0.6970, time: 0:02:53
 Epoch: 109, lr: 1.0e-02, train_loss: 0.7671, train_acc: 0.7332 test_loss: 0.9773, test_acc: 0.6886, best: 0.6970, time: 0:02:53
 Epoch: 110, lr: 1.0e-02, train_loss: 0.7599, train_acc: 0.7270 test_loss: 0.9600, test_acc: 0.6905, best: 0.6970, time: 0:02:53
 Epoch: 111, lr: 1.0e-02, train_loss: 0.7857, train_acc: 0.7218 test_loss: 0.9454, test_acc: 0.6973, best: 0.6973, time: 0:02:53
 Epoch: 112, lr: 1.0e-02, train_loss: 0.7860, train_acc: 0.7168 test_loss: 0.9804, test_acc: 0.6907, best: 0.6973, time: 0:02:53
 Epoch: 113, lr: 1.0e-02, train_loss: 0.7618, train_acc: 0.7268 test_loss: 0.9941, test_acc: 0.6879, best: 0.6973, time: 0:02:53
 Epoch: 114, lr: 1.0e-02, train_loss: 0.7242, train_acc: 0.7386 test_loss: 0.9834, test_acc: 0.6911, best: 0.6973, time: 0:02:53
 Epoch: 115, lr: 1.0e-02, train_loss: 0.7613, train_acc: 0.7266 test_loss: 1.0342, test_acc: 0.6805, best: 0.6973, time: 0:02:53
 Epoch: 116, lr: 1.0e-02, train_loss: 0.7369, train_acc: 0.7472 test_loss: 0.9434, test_acc: 0.7089, best: 0.7089, time: 0:02:53
 Epoch: 117, lr: 1.0e-02, train_loss: 0.7579, train_acc: 0.7352 test_loss: 0.9737, test_acc: 0.6859, best: 0.7089, time: 0:02:53
 Epoch: 118, lr: 1.0e-02, train_loss: 0.7250, train_acc: 0.7428 test_loss: 1.0181, test_acc: 0.6953, best: 0.7089, time: 0:02:53
 Epoch: 119, lr: 1.0e-02, train_loss: 0.7213, train_acc: 0.7490 test_loss: 1.0439, test_acc: 0.6861, best: 0.7089, time: 0:02:53
 Epoch: 120, lr: 1.0e-02, train_loss: 0.7297, train_acc: 0.7448 test_loss: 0.9356, test_acc: 0.7003, best: 0.7089, time: 0:02:53
 Epoch: 121, lr: 1.0e-02, train_loss: 0.7381, train_acc: 0.7414 test_loss: 0.9911, test_acc: 0.6915, best: 0.7089, time: 0:02:53
 Epoch: 122, lr: 1.0e-02, train_loss: 0.7322, train_acc: 0.7468 test_loss: 0.9359, test_acc: 0.7011, best: 0.7089, time: 0:02:53
 Epoch: 123, lr: 1.0e-02, train_loss: 0.7364, train_acc: 0.7414 test_loss: 1.0045, test_acc: 0.6817, best: 0.7089, time: 0:02:53
 Epoch: 124, lr: 1.0e-02, train_loss: 0.7109, train_acc: 0.7478 test_loss: 1.0094, test_acc: 0.6979, best: 0.7089, time: 0:02:53
 Epoch: 125, lr: 1.0e-02, train_loss: 0.7195, train_acc: 0.7378 test_loss: 0.9960, test_acc: 0.6911, best: 0.7089, time: 0:02:53
 Epoch: 126, lr: 1.0e-02, train_loss: 0.7166, train_acc: 0.7558 test_loss: 1.0187, test_acc: 0.6930, best: 0.7089, time: 0:02:53
 Epoch: 127, lr: 1.0e-02, train_loss: 0.7171, train_acc: 0.7458 test_loss: 0.9052, test_acc: 0.7106, best: 0.7106, time: 0:02:53
 Epoch: 128, lr: 1.0e-02, train_loss: 0.7162, train_acc: 0.7562 test_loss: 1.0379, test_acc: 0.6890, best: 0.7106, time: 0:02:53
 Epoch: 129, lr: 1.0e-02, train_loss: 0.6956, train_acc: 0.7544 test_loss: 1.0307, test_acc: 0.6814, best: 0.7106, time: 0:02:53
 Epoch: 130, lr: 1.0e-02, train_loss: 0.6894, train_acc: 0.7594 test_loss: 0.9968, test_acc: 0.6969, best: 0.7106, time: 0:02:53
 Epoch: 131, lr: 1.0e-02, train_loss: 0.7149, train_acc: 0.7506 test_loss: 1.0254, test_acc: 0.6941, best: 0.7106, time: 0:02:53
 Epoch: 132, lr: 1.0e-02, train_loss: 0.6882, train_acc: 0.7656 test_loss: 1.1566, test_acc: 0.6635, best: 0.7106, time: 0:02:53
 Epoch: 133, lr: 1.0e-02, train_loss: 0.6965, train_acc: 0.7590 test_loss: 1.0504, test_acc: 0.6807, best: 0.7106, time: 0:02:53
 Epoch: 134, lr: 1.0e-02, train_loss: 0.6751, train_acc: 0.7602 test_loss: 0.9991, test_acc: 0.7011, best: 0.7106, time: 0:02:53
 Epoch: 135, lr: 1.0e-02, train_loss: 0.6853, train_acc: 0.7594 test_loss: 1.1023, test_acc: 0.6843, best: 0.7106, time: 0:02:53
 Epoch: 136, lr: 1.0e-02, train_loss: 0.6951, train_acc: 0.7542 test_loss: 1.0066, test_acc: 0.6979, best: 0.7106, time: 0:02:53
 Epoch: 137, lr: 1.0e-02, train_loss: 0.6859, train_acc: 0.7586 test_loss: 0.9574, test_acc: 0.7059, best: 0.7106, time: 0:02:53
 Epoch: 138, lr: 1.0e-02, train_loss: 0.6714, train_acc: 0.7596 test_loss: 0.9818, test_acc: 0.6949, best: 0.7106, time: 0:02:53
 Epoch: 139, lr: 1.0e-02, train_loss: 0.6971, train_acc: 0.7572 test_loss: 1.0471, test_acc: 0.6807, best: 0.7106, time: 0:02:53
 Epoch: 140, lr: 1.0e-02, train_loss: 0.6833, train_acc: 0.7690 test_loss: 0.9561, test_acc: 0.7027, best: 0.7106, time: 0:02:53
 Epoch: 141, lr: 1.0e-02, train_loss: 0.6856, train_acc: 0.7642 test_loss: 1.0434, test_acc: 0.6946, best: 0.7106, time: 0:02:53
 Epoch: 142, lr: 1.0e-02, train_loss: 0.6686, train_acc: 0.7646 test_loss: 1.0029, test_acc: 0.6990, best: 0.7106, time: 0:02:53
 Epoch: 143, lr: 1.0e-02, train_loss: 0.6607, train_acc: 0.7666 test_loss: 1.0324, test_acc: 0.7006, best: 0.7106, time: 0:02:53
 Epoch: 144, lr: 1.0e-02, train_loss: 0.6482, train_acc: 0.7756 test_loss: 1.0007, test_acc: 0.7014, best: 0.7106, time: 0:02:53
 Epoch: 145, lr: 1.0e-02, train_loss: 0.6615, train_acc: 0.7688 test_loss: 0.9903, test_acc: 0.6966, best: 0.7106, time: 0:02:53
 Epoch: 146, lr: 1.0e-02, train_loss: 0.6614, train_acc: 0.7600 test_loss: 1.0534, test_acc: 0.6907, best: 0.7106, time: 0:02:53
 Epoch: 147, lr: 1.0e-02, train_loss: 0.6408, train_acc: 0.7770 test_loss: 1.0897, test_acc: 0.6839, best: 0.7106, time: 0:02:53
 Epoch: 148, lr: 1.0e-02, train_loss: 0.6683, train_acc: 0.7628 test_loss: 1.0153, test_acc: 0.6937, best: 0.7106, time: 0:02:53
 Epoch: 149, lr: 1.0e-02, train_loss: 0.6439, train_acc: 0.7776 test_loss: 1.0464, test_acc: 0.6911, best: 0.7106, time: 0:02:53
 Epoch: 150, lr: 1.0e-02, train_loss: 0.6525, train_acc: 0.7772 test_loss: 1.0197, test_acc: 0.6981, best: 0.7106, time: 0:02:53
 Epoch: 151, lr: 1.0e-02, train_loss: 0.6381, train_acc: 0.7738 test_loss: 0.9788, test_acc: 0.7119, best: 0.7119, time: 0:02:53
 Epoch: 152, lr: 1.0e-02, train_loss: 0.6443, train_acc: 0.7754 test_loss: 0.9766, test_acc: 0.6940, best: 0.7119, time: 0:02:53
 Epoch: 153, lr: 1.0e-02, train_loss: 0.6353, train_acc: 0.7738 test_loss: 0.9992, test_acc: 0.7045, best: 0.7119, time: 0:02:53
 Epoch: 154, lr: 1.0e-02, train_loss: 0.6338, train_acc: 0.7784 test_loss: 1.0736, test_acc: 0.6854, best: 0.7119, time: 0:02:53
 Epoch: 155, lr: 1.0e-02, train_loss: 0.6283, train_acc: 0.7922 test_loss: 1.0073, test_acc: 0.7107, best: 0.7119, time: 0:02:53
 Epoch: 156, lr: 1.0e-02, train_loss: 0.6174, train_acc: 0.7878 test_loss: 1.0082, test_acc: 0.6957, best: 0.7119, time: 0:02:53
 Epoch: 157, lr: 1.0e-02, train_loss: 0.6333, train_acc: 0.7780 test_loss: 1.0283, test_acc: 0.7050, best: 0.7119, time: 0:02:53
 Epoch: 158, lr: 1.0e-02, train_loss: 0.6296, train_acc: 0.7812 test_loss: 1.0668, test_acc: 0.6959, best: 0.7119, time: 0:02:53
 Epoch: 159, lr: 1.0e-02, train_loss: 0.6206, train_acc: 0.7786 test_loss: 0.9859, test_acc: 0.7074, best: 0.7119, time: 0:02:53
 Epoch: 160, lr: 1.0e-02, train_loss: 0.6164, train_acc: 0.7870 test_loss: 1.0666, test_acc: 0.7039, best: 0.7119, time: 0:02:53
 Epoch: 161, lr: 1.0e-02, train_loss: 0.6168, train_acc: 0.7882 test_loss: 1.1010, test_acc: 0.6830, best: 0.7119, time: 0:02:53
 Epoch: 162, lr: 1.0e-02, train_loss: 0.6019, train_acc: 0.7878 test_loss: 1.0595, test_acc: 0.6889, best: 0.7119, time: 0:02:53
 Epoch: 163, lr: 1.0e-02, train_loss: 0.6026, train_acc: 0.7880 test_loss: 1.0142, test_acc: 0.7075, best: 0.7119, time: 0:02:53
 Epoch: 164, lr: 1.0e-02, train_loss: 0.6074, train_acc: 0.7940 test_loss: 1.1286, test_acc: 0.6884, best: 0.7119, time: 0:02:53
 Epoch: 165, lr: 1.0e-02, train_loss: 0.5911, train_acc: 0.7996 test_loss: 0.9656, test_acc: 0.7141, best: 0.7141, time: 0:02:53
 Epoch: 166, lr: 1.0e-02, train_loss: 0.6095, train_acc: 0.7894 test_loss: 0.9969, test_acc: 0.7109, best: 0.7141, time: 0:02:53
 Epoch: 167, lr: 1.0e-02, train_loss: 0.6186, train_acc: 0.7850 test_loss: 0.9679, test_acc: 0.7043, best: 0.7141, time: 0:02:53
 Epoch: 168, lr: 1.0e-02, train_loss: 0.5884, train_acc: 0.7996 test_loss: 1.1161, test_acc: 0.6934, best: 0.7141, time: 0:02:53
 Epoch: 169, lr: 1.0e-02, train_loss: 0.6019, train_acc: 0.7954 test_loss: 1.0197, test_acc: 0.7050, best: 0.7141, time: 0:02:53
 Epoch: 170, lr: 1.0e-02, train_loss: 0.5980, train_acc: 0.7894 test_loss: 1.0689, test_acc: 0.6973, best: 0.7141, time: 0:02:53
 Epoch: 171, lr: 1.0e-02, train_loss: 0.5871, train_acc: 0.7964 test_loss: 1.0821, test_acc: 0.7046, best: 0.7141, time: 0:02:53
 Epoch: 172, lr: 1.0e-02, train_loss: 0.5900, train_acc: 0.7942 test_loss: 1.0309, test_acc: 0.6994, best: 0.7141, time: 0:02:53
 Epoch: 173, lr: 1.0e-02, train_loss: 0.6100, train_acc: 0.7866 test_loss: 1.0312, test_acc: 0.7051, best: 0.7141, time: 0:02:53
 Epoch: 174, lr: 1.0e-02, train_loss: 0.5762, train_acc: 0.8000 test_loss: 1.0081, test_acc: 0.7065, best: 0.7141, time: 0:02:53
 Epoch: 175, lr: 1.0e-02, train_loss: 0.5745, train_acc: 0.8004 test_loss: 1.1284, test_acc: 0.6931, best: 0.7141, time: 0:02:53
 Epoch: 176, lr: 1.0e-02, train_loss: 0.5985, train_acc: 0.7902 test_loss: 1.0344, test_acc: 0.6999, best: 0.7141, time: 0:02:53
 Epoch: 177, lr: 1.0e-02, train_loss: 0.6101, train_acc: 0.7930 test_loss: 0.9886, test_acc: 0.7107, best: 0.7141, time: 0:02:53
 Epoch: 178, lr: 1.0e-02, train_loss: 0.5921, train_acc: 0.7972 test_loss: 1.0162, test_acc: 0.7195, best: 0.7195, time: 0:02:53
 Epoch: 179, lr: 1.0e-02, train_loss: 0.5867, train_acc: 0.7944 test_loss: 1.0142, test_acc: 0.7063, best: 0.7195, time: 0:02:53
 Epoch: 180, lr: 2.0e-03, train_loss: 0.5341, train_acc: 0.8170 test_loss: 0.9644, test_acc: 0.7260, best: 0.7260, time: 0:02:53
 Epoch: 181, lr: 2.0e-03, train_loss: 0.4873, train_acc: 0.8330 test_loss: 0.9603, test_acc: 0.7282, best: 0.7282, time: 0:02:53
 Epoch: 182, lr: 2.0e-03, train_loss: 0.4841, train_acc: 0.8280 test_loss: 0.9419, test_acc: 0.7272, best: 0.7282, time: 0:02:53
 Epoch: 183, lr: 2.0e-03, train_loss: 0.4704, train_acc: 0.8372 test_loss: 0.9520, test_acc: 0.7318, best: 0.7318, time: 0:02:53
 Epoch: 184, lr: 2.0e-03, train_loss: 0.4794, train_acc: 0.8368 test_loss: 0.9307, test_acc: 0.7344, best: 0.7344, time: 0:02:53
 Epoch: 185, lr: 2.0e-03, train_loss: 0.4768, train_acc: 0.8336 test_loss: 0.9923, test_acc: 0.7280, best: 0.7344, time: 0:02:53
 Epoch: 186, lr: 2.0e-03, train_loss: 0.4612, train_acc: 0.8418 test_loss: 0.9462, test_acc: 0.7362, best: 0.7362, time: 0:02:53
 Epoch: 187, lr: 2.0e-03, train_loss: 0.4493, train_acc: 0.8468 test_loss: 0.9627, test_acc: 0.7305, best: 0.7362, time: 0:02:53
 Epoch: 188, lr: 2.0e-03, train_loss: 0.4540, train_acc: 0.8450 test_loss: 0.9583, test_acc: 0.7308, best: 0.7362, time: 0:02:53
 Epoch: 189, lr: 2.0e-03, train_loss: 0.4668, train_acc: 0.8454 test_loss: 0.9812, test_acc: 0.7294, best: 0.7362, time: 0:02:53
 Epoch: 190, lr: 2.0e-03, train_loss: 0.4379, train_acc: 0.8512 test_loss: 0.9758, test_acc: 0.7322, best: 0.7362, time: 0:02:53
 Epoch: 191, lr: 2.0e-03, train_loss: 0.4403, train_acc: 0.8480 test_loss: 0.9822, test_acc: 0.7290, best: 0.7362, time: 0:02:53
 Epoch: 192, lr: 2.0e-03, train_loss: 0.4338, train_acc: 0.8524 test_loss: 0.9995, test_acc: 0.7316, best: 0.7362, time: 0:02:53
 Epoch: 193, lr: 2.0e-03, train_loss: 0.4527, train_acc: 0.8454 test_loss: 1.0182, test_acc: 0.7304, best: 0.7362, time: 0:02:53
 Epoch: 194, lr: 2.0e-03, train_loss: 0.4421, train_acc: 0.8518 test_loss: 1.0331, test_acc: 0.7231, best: 0.7362, time: 0:02:53
 Epoch: 195, lr: 2.0e-03, train_loss: 0.4367, train_acc: 0.8468 test_loss: 1.0103, test_acc: 0.7291, best: 0.7362, time: 0:02:53
 Epoch: 196, lr: 2.0e-03, train_loss: 0.4344, train_acc: 0.8516 test_loss: 1.0267, test_acc: 0.7281, best: 0.7362, time: 0:02:53
 Epoch: 197, lr: 2.0e-03, train_loss: 0.4526, train_acc: 0.8476 test_loss: 0.9619, test_acc: 0.7339, best: 0.7362, time: 0:02:53
 Epoch: 198, lr: 2.0e-03, train_loss: 0.4287, train_acc: 0.8478 test_loss: 1.0337, test_acc: 0.7320, best: 0.7362, time: 0:02:53
 Epoch: 199, lr: 2.0e-03, train_loss: 0.4109, train_acc: 0.8590 test_loss: 1.0191, test_acc: 0.7316, best: 0.7362, time: 0:02:53
 Epoch: 200, lr: 2.0e-03, train_loss: 0.4145, train_acc: 0.8548 test_loss: 0.9958, test_acc: 0.7351, best: 0.7362, time: 0:02:53
 Epoch: 201, lr: 2.0e-03, train_loss: 0.4392, train_acc: 0.8524 test_loss: 0.9858, test_acc: 0.7396, best: 0.7396, time: 0:02:54
 Epoch: 202, lr: 2.0e-03, train_loss: 0.4347, train_acc: 0.8486 test_loss: 0.9874, test_acc: 0.7355, best: 0.7396, time: 0:02:53
 Epoch: 203, lr: 2.0e-03, train_loss: 0.4091, train_acc: 0.8620 test_loss: 0.9827, test_acc: 0.7345, best: 0.7396, time: 0:02:53
 Epoch: 204, lr: 2.0e-03, train_loss: 0.4261, train_acc: 0.8530 test_loss: 1.0041, test_acc: 0.7314, best: 0.7396, time: 0:02:53
 Epoch: 205, lr: 2.0e-03, train_loss: 0.4310, train_acc: 0.8506 test_loss: 1.0122, test_acc: 0.7326, best: 0.7396, time: 0:02:53
 Epoch: 206, lr: 2.0e-03, train_loss: 0.4047, train_acc: 0.8580 test_loss: 1.0331, test_acc: 0.7340, best: 0.7396, time: 0:02:53
 Epoch: 207, lr: 2.0e-03, train_loss: 0.4161, train_acc: 0.8588 test_loss: 0.9750, test_acc: 0.7352, best: 0.7396, time: 0:02:53
 Epoch: 208, lr: 2.0e-03, train_loss: 0.4150, train_acc: 0.8554 test_loss: 1.0131, test_acc: 0.7349, best: 0.7396, time: 0:02:53
 Epoch: 209, lr: 2.0e-03, train_loss: 0.4170, train_acc: 0.8590 test_loss: 1.0115, test_acc: 0.7346, best: 0.7396, time: 0:02:53
 Epoch: 210, lr: 2.0e-03, train_loss: 0.4036, train_acc: 0.8560 test_loss: 0.9852, test_acc: 0.7351, best: 0.7396, time: 0:02:53
 Epoch: 211, lr: 2.0e-03, train_loss: 0.4091, train_acc: 0.8592 test_loss: 1.0055, test_acc: 0.7364, best: 0.7396, time: 0:02:53
 Epoch: 212, lr: 2.0e-03, train_loss: 0.3999, train_acc: 0.8608 test_loss: 1.0205, test_acc: 0.7359, best: 0.7396, time: 0:02:53
 Epoch: 213, lr: 2.0e-03, train_loss: 0.4183, train_acc: 0.8584 test_loss: 1.0001, test_acc: 0.7351, best: 0.7396, time: 0:02:53
 Epoch: 214, lr: 2.0e-03, train_loss: 0.4043, train_acc: 0.8600 test_loss: 1.0256, test_acc: 0.7321, best: 0.7396, time: 0:02:53
 Epoch: 215, lr: 2.0e-03, train_loss: 0.4266, train_acc: 0.8504 test_loss: 1.0066, test_acc: 0.7359, best: 0.7396, time: 0:02:53
 Epoch: 216, lr: 2.0e-03, train_loss: 0.4037, train_acc: 0.8622 test_loss: 1.0143, test_acc: 0.7335, best: 0.7396, time: 0:02:53
 Epoch: 217, lr: 2.0e-03, train_loss: 0.4084, train_acc: 0.8636 test_loss: 1.0140, test_acc: 0.7354, best: 0.7396, time: 0:02:53
 Epoch: 218, lr: 2.0e-03, train_loss: 0.4093, train_acc: 0.8568 test_loss: 1.0131, test_acc: 0.7355, best: 0.7396, time: 0:02:53
 Epoch: 219, lr: 2.0e-03, train_loss: 0.4007, train_acc: 0.8574 test_loss: 1.0344, test_acc: 0.7342, best: 0.7396, time: 0:02:53
 Epoch: 220, lr: 2.0e-03, train_loss: 0.4293, train_acc: 0.8526 test_loss: 1.0058, test_acc: 0.7350, best: 0.7396, time: 0:02:53
 Epoch: 221, lr: 2.0e-03, train_loss: 0.3963, train_acc: 0.8634 test_loss: 1.0270, test_acc: 0.7322, best: 0.7396, time: 0:02:53
 Epoch: 222, lr: 2.0e-03, train_loss: 0.4011, train_acc: 0.8636 test_loss: 1.0391, test_acc: 0.7320, best: 0.7396, time: 0:02:53
 Epoch: 223, lr: 2.0e-03, train_loss: 0.3892, train_acc: 0.8648 test_loss: 1.0565, test_acc: 0.7296, best: 0.7396, time: 0:02:53
 Epoch: 224, lr: 2.0e-03, train_loss: 0.4092, train_acc: 0.8634 test_loss: 1.0385, test_acc: 0.7348, best: 0.7396, time: 0:02:53
 Epoch: 225, lr: 2.0e-03, train_loss: 0.3996, train_acc: 0.8646 test_loss: 1.0376, test_acc: 0.7311, best: 0.7396, time: 0:02:53
 Epoch: 226, lr: 2.0e-03, train_loss: 0.4101, train_acc: 0.8642 test_loss: 1.0234, test_acc: 0.7319, best: 0.7396, time: 0:02:53
 Epoch: 227, lr: 2.0e-03, train_loss: 0.4018, train_acc: 0.8644 test_loss: 1.0168, test_acc: 0.7311, best: 0.7396, time: 0:02:53
 Epoch: 228, lr: 2.0e-03, train_loss: 0.4014, train_acc: 0.8578 test_loss: 1.0711, test_acc: 0.7299, best: 0.7396, time: 0:02:53
 Epoch: 229, lr: 2.0e-03, train_loss: 0.3877, train_acc: 0.8700 test_loss: 1.0937, test_acc: 0.7244, best: 0.7396, time: 0:02:53
 Epoch: 230, lr: 2.0e-03, train_loss: 0.3855, train_acc: 0.8704 test_loss: 0.9952, test_acc: 0.7361, best: 0.7396, time: 0:02:53
 Epoch: 231, lr: 2.0e-03, train_loss: 0.3900, train_acc: 0.8710 test_loss: 1.0265, test_acc: 0.7350, best: 0.7396, time: 0:02:53
 Epoch: 232, lr: 2.0e-03, train_loss: 0.3897, train_acc: 0.8672 test_loss: 1.0413, test_acc: 0.7379, best: 0.7396, time: 0:02:53
 Epoch: 233, lr: 2.0e-03, train_loss: 0.3854, train_acc: 0.8698 test_loss: 1.0798, test_acc: 0.7334, best: 0.7396, time: 0:02:53
 Epoch: 234, lr: 2.0e-03, train_loss: 0.3757, train_acc: 0.8700 test_loss: 1.0607, test_acc: 0.7299, best: 0.7396, time: 0:02:53
 Epoch: 235, lr: 2.0e-03, train_loss: 0.4162, train_acc: 0.8546 test_loss: 1.0426, test_acc: 0.7330, best: 0.7396, time: 0:02:53
 Epoch: 236, lr: 2.0e-03, train_loss: 0.3937, train_acc: 0.8656 test_loss: 1.0223, test_acc: 0.7336, best: 0.7396, time: 0:02:53
 Epoch: 237, lr: 2.0e-03, train_loss: 0.4093, train_acc: 0.8602 test_loss: 1.0060, test_acc: 0.7316, best: 0.7396, time: 0:02:53
 Epoch: 238, lr: 2.0e-03, train_loss: 0.3992, train_acc: 0.8634 test_loss: 1.0022, test_acc: 0.7346, best: 0.7396, time: 0:02:53
 Epoch: 239, lr: 2.0e-03, train_loss: 0.3852, train_acc: 0.8726 test_loss: 0.9993, test_acc: 0.7345, best: 0.7396, time: 0:02:53
 Epoch: 240, lr: 4.0e-04, train_loss: 0.3850, train_acc: 0.8752 test_loss: 1.0176, test_acc: 0.7342, best: 0.7396, time: 0:02:53
 Epoch: 241, lr: 4.0e-04, train_loss: 0.3696, train_acc: 0.8726 test_loss: 1.0166, test_acc: 0.7335, best: 0.7396, time: 0:02:53
 Epoch: 242, lr: 4.0e-04, train_loss: 0.3761, train_acc: 0.8704 test_loss: 1.0285, test_acc: 0.7371, best: 0.7396, time: 0:02:53
 Epoch: 243, lr: 4.0e-04, train_loss: 0.3751, train_acc: 0.8750 test_loss: 1.0162, test_acc: 0.7381, best: 0.7396, time: 0:02:53
 Epoch: 244, lr: 4.0e-04, train_loss: 0.3890, train_acc: 0.8676 test_loss: 1.0278, test_acc: 0.7371, best: 0.7396, time: 0:02:53
 Epoch: 245, lr: 4.0e-04, train_loss: 0.3613, train_acc: 0.8706 test_loss: 1.0198, test_acc: 0.7422, best: 0.7422, time: 0:02:53
 Epoch: 246, lr: 4.0e-04, train_loss: 0.3777, train_acc: 0.8720 test_loss: 1.0175, test_acc: 0.7392, best: 0.7422, time: 0:02:53
 Epoch: 247, lr: 4.0e-04, train_loss: 0.3624, train_acc: 0.8772 test_loss: 1.0221, test_acc: 0.7395, best: 0.7422, time: 0:02:53
 Epoch: 248, lr: 4.0e-04, train_loss: 0.3858, train_acc: 0.8682 test_loss: 1.0101, test_acc: 0.7418, best: 0.7422, time: 0:02:53
 Epoch: 249, lr: 4.0e-04, train_loss: 0.3581, train_acc: 0.8780 test_loss: 1.0102, test_acc: 0.7415, best: 0.7422, time: 0:02:53
 Epoch: 250, lr: 4.0e-04, train_loss: 0.3606, train_acc: 0.8742 test_loss: 1.0293, test_acc: 0.7380, best: 0.7422, time: 0:02:53
 Epoch: 251, lr: 4.0e-04, train_loss: 0.3884, train_acc: 0.8692 test_loss: 1.0371, test_acc: 0.7358, best: 0.7422, time: 0:02:53
 Epoch: 252, lr: 4.0e-04, train_loss: 0.3776, train_acc: 0.8754 test_loss: 1.0101, test_acc: 0.7416, best: 0.7422, time: 0:02:53
 Epoch: 253, lr: 4.0e-04, train_loss: 0.3713, train_acc: 0.8740 test_loss: 1.0191, test_acc: 0.7418, best: 0.7422, time: 0:02:53
 Epoch: 254, lr: 4.0e-04, train_loss: 0.3672, train_acc: 0.8776 test_loss: 1.0230, test_acc: 0.7356, best: 0.7422, time: 0:02:53
 Epoch: 255, lr: 4.0e-04, train_loss: 0.3763, train_acc: 0.8696 test_loss: 1.0437, test_acc: 0.7321, best: 0.7422, time: 0:02:53
 Epoch: 256, lr: 4.0e-04, train_loss: 0.3544, train_acc: 0.8836 test_loss: 1.0277, test_acc: 0.7378, best: 0.7422, time: 0:02:53
 Epoch: 257, lr: 4.0e-04, train_loss: 0.3603, train_acc: 0.8756 test_loss: 1.0199, test_acc: 0.7376, best: 0.7422, time: 0:02:53
 Epoch: 258, lr: 4.0e-04, train_loss: 0.3615, train_acc: 0.8762 test_loss: 1.0346, test_acc: 0.7368, best: 0.7422, time: 0:02:53
 Epoch: 259, lr: 4.0e-04, train_loss: 0.3863, train_acc: 0.8698 test_loss: 1.0190, test_acc: 0.7424, best: 0.7424, time: 0:02:53
 Epoch: 260, lr: 4.0e-04, train_loss: 0.3666, train_acc: 0.8778 test_loss: 1.0422, test_acc: 0.7399, best: 0.7424, time: 0:02:53
 Epoch: 261, lr: 4.0e-04, train_loss: 0.3531, train_acc: 0.8802 test_loss: 1.0516, test_acc: 0.7378, best: 0.7424, time: 0:02:53
 Epoch: 262, lr: 4.0e-04, train_loss: 0.3558, train_acc: 0.8800 test_loss: 1.0449, test_acc: 0.7414, best: 0.7424, time: 0:02:53
 Epoch: 263, lr: 4.0e-04, train_loss: 0.3773, train_acc: 0.8718 test_loss: 1.0037, test_acc: 0.7408, best: 0.7424, time: 0:02:53
 Epoch: 264, lr: 4.0e-04, train_loss: 0.3736, train_acc: 0.8744 test_loss: 1.0337, test_acc: 0.7366, best: 0.7424, time: 0:02:53
 Epoch: 265, lr: 4.0e-04, train_loss: 0.3637, train_acc: 0.8818 test_loss: 1.0383, test_acc: 0.7376, best: 0.7424, time: 0:02:53
 Epoch: 266, lr: 4.0e-04, train_loss: 0.3706, train_acc: 0.8746 test_loss: 1.0253, test_acc: 0.7419, best: 0.7424, time: 0:02:53
 Epoch: 267, lr: 4.0e-04, train_loss: 0.3547, train_acc: 0.8814 test_loss: 1.0495, test_acc: 0.7351, best: 0.7424, time: 0:02:53
 Epoch: 268, lr: 4.0e-04, train_loss: 0.3303, train_acc: 0.8848 test_loss: 1.0467, test_acc: 0.7338, best: 0.7424, time: 0:02:53
 Epoch: 269, lr: 4.0e-04, train_loss: 0.3769, train_acc: 0.8694 test_loss: 1.0423, test_acc: 0.7379, best: 0.7424, time: 0:02:53
 Epoch: 270, lr: 8.0e-05, train_loss: 0.3613, train_acc: 0.8736 test_loss: 1.0231, test_acc: 0.7412, best: 0.7424, time: 0:02:53
 Epoch: 271, lr: 8.0e-05, train_loss: 0.3599, train_acc: 0.8762 test_loss: 1.0343, test_acc: 0.7385, best: 0.7424, time: 0:02:53
 Epoch: 272, lr: 8.0e-05, train_loss: 0.3643, train_acc: 0.8752 test_loss: 1.0294, test_acc: 0.7396, best: 0.7424, time: 0:02:53
 Epoch: 273, lr: 8.0e-05, train_loss: 0.3555, train_acc: 0.8822 test_loss: 1.0242, test_acc: 0.7381, best: 0.7424, time: 0:02:53
 Epoch: 274, lr: 8.0e-05, train_loss: 0.3708, train_acc: 0.8710 test_loss: 1.0376, test_acc: 0.7371, best: 0.7424, time: 0:02:53
 Epoch: 275, lr: 8.0e-05, train_loss: 0.3431, train_acc: 0.8802 test_loss: 1.0264, test_acc: 0.7379, best: 0.7424, time: 0:02:53
 Epoch: 276, lr: 8.0e-05, train_loss: 0.3643, train_acc: 0.8742 test_loss: 1.0213, test_acc: 0.7416, best: 0.7424, time: 0:02:53
 Epoch: 277, lr: 8.0e-05, train_loss: 0.3659, train_acc: 0.8748 test_loss: 1.0222, test_acc: 0.7364, best: 0.7424, time: 0:02:53
 Epoch: 278, lr: 8.0e-05, train_loss: 0.3577, train_acc: 0.8764 test_loss: 1.0438, test_acc: 0.7362, best: 0.7424, time: 0:02:53
 Epoch: 279, lr: 8.0e-05, train_loss: 0.3556, train_acc: 0.8778 test_loss: 1.0489, test_acc: 0.7381, best: 0.7424, time: 0:02:53
 Epoch: 280, lr: 8.0e-05, train_loss: 0.3505, train_acc: 0.8808 test_loss: 1.0451, test_acc: 0.7364, best: 0.7424, time: 0:02:53
 Epoch: 281, lr: 8.0e-05, train_loss: 0.3527, train_acc: 0.8744 test_loss: 1.0187, test_acc: 0.7406, best: 0.7424, time: 0:02:53
 Epoch: 282, lr: 8.0e-05, train_loss: 0.3362, train_acc: 0.8818 test_loss: 1.0503, test_acc: 0.7330, best: 0.7424, time: 0:02:53
 Epoch: 283, lr: 8.0e-05, train_loss: 0.3594, train_acc: 0.8780 test_loss: 1.0182, test_acc: 0.7420, best: 0.7424, time: 0:02:53
 Epoch: 284, lr: 8.0e-05, train_loss: 0.3649, train_acc: 0.8794 test_loss: 1.0141, test_acc: 0.7405, best: 0.7424, time: 0:02:53
 Epoch: 285, lr: 8.0e-05, train_loss: 0.3768, train_acc: 0.8730 test_loss: 1.0188, test_acc: 0.7391, best: 0.7424, time: 0:02:53
 Epoch: 286, lr: 8.0e-05, train_loss: 0.3562, train_acc: 0.8776 test_loss: 1.0436, test_acc: 0.7385, best: 0.7424, time: 0:02:53
 Epoch: 287, lr: 8.0e-05, train_loss: 0.3561, train_acc: 0.8754 test_loss: 1.0485, test_acc: 0.7362, best: 0.7424, time: 0:02:53
 Epoch: 288, lr: 8.0e-05, train_loss: 0.3418, train_acc: 0.8832 test_loss: 1.0315, test_acc: 0.7400, best: 0.7424, time: 0:02:53
 Epoch: 289, lr: 8.0e-05, train_loss: 0.3646, train_acc: 0.8768 test_loss: 1.0478, test_acc: 0.7385, best: 0.7424, time: 0:02:53
 Epoch: 290, lr: 8.0e-05, train_loss: 0.3519, train_acc: 0.8774 test_loss: 1.0240, test_acc: 0.7378, best: 0.7424, time: 0:02:53
 Epoch: 291, lr: 8.0e-05, train_loss: 0.3435, train_acc: 0.8850 test_loss: 1.0332, test_acc: 0.7398, best: 0.7424, time: 0:02:53
 Epoch: 292, lr: 8.0e-05, train_loss: 0.3485, train_acc: 0.8764 test_loss: 1.0103, test_acc: 0.7390, best: 0.7424, time: 0:02:53
 Epoch: 293, lr: 8.0e-05, train_loss: 0.3728, train_acc: 0.8750 test_loss: 1.0257, test_acc: 0.7384, best: 0.7424, time: 0:02:53
 Epoch: 294, lr: 8.0e-05, train_loss: 0.3542, train_acc: 0.8758 test_loss: 1.0140, test_acc: 0.7395, best: 0.7424, time: 0:02:53
 Epoch: 295, lr: 8.0e-05, train_loss: 0.3784, train_acc: 0.8700 test_loss: 1.0211, test_acc: 0.7401, best: 0.7424, time: 0:02:53
 Epoch: 296, lr: 8.0e-05, train_loss: 0.3554, train_acc: 0.8814 test_loss: 1.0128, test_acc: 0.7415, best: 0.7424, time: 0:02:53
 Epoch: 297, lr: 8.0e-05, train_loss: 0.3616, train_acc: 0.8764 test_loss: 1.0163, test_acc: 0.7390, best: 0.7424, time: 0:02:53
 Epoch: 298, lr: 8.0e-05, train_loss: 0.3587, train_acc: 0.8814 test_loss: 1.0373, test_acc: 0.7379, best: 0.7424, time: 0:02:53
 Epoch: 299, lr: 8.0e-05, train_loss: 0.3650, train_acc: 0.8750 test_loss: 1.0463, test_acc: 0.7385, best: 0.7424, time: 0:02:53
 Highest accuracy: 0.7424