
 Run on time: 2022-07-01 02:37:18.752011

 Architecture: prepool-resnet18-nlp_headfix2-4

 Pool Config: {
    "arch": "resnet18",
    "conv1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "pool": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlp",
            "_stride": 4,
            "_psize": 2,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": true
        }
    },
    "layer1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer2": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer3": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer4": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    }
}

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : PREPOOL-RESNET18-NLP_HEADFIX2-4
	 im_size              : None
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): Network(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): Pool2d(
        (logit): Sequential(
          (pool_weight): NLP_BASE(
            (downsample): Sequential(
              (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (restore): Sequential(
              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Sigmoid()
            )
            (pos_embed): PositionEmbeddingLearned(
              (row_embed): Embedding(256, 32)
              (col_embed): Embedding(256, 32)
            )
          )
        )
        (pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
      )
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.4335, train_acc: 0.1840 test_loss: 1.9085, test_acc: 0.2670, best: 0.2670, time: 0:01:12
 Epoch: 2, lr: 1.0e-02, train_loss: 1.9824, train_acc: 0.2468 test_loss: 1.7793, test_acc: 0.3094, best: 0.3094, time: 0:01:11
 Epoch: 3, lr: 1.0e-02, train_loss: 1.8875, train_acc: 0.2796 test_loss: 1.6136, test_acc: 0.3779, best: 0.3779, time: 0:01:12
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8299, train_acc: 0.3072 test_loss: 1.6420, test_acc: 0.3615, best: 0.3779, time: 0:01:12
 Epoch: 5, lr: 1.0e-02, train_loss: 1.7917, train_acc: 0.3256 test_loss: 1.5569, test_acc: 0.4040, best: 0.4040, time: 0:01:12
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7390, train_acc: 0.3392 test_loss: 1.5402, test_acc: 0.4145, best: 0.4145, time: 0:01:11
 Epoch: 7, lr: 1.0e-02, train_loss: 1.7002, train_acc: 0.3624 test_loss: 1.4959, test_acc: 0.4318, best: 0.4318, time: 0:01:07
 Epoch: 8, lr: 1.0e-02, train_loss: 1.6756, train_acc: 0.3808 test_loss: 1.5841, test_acc: 0.4321, best: 0.4321, time: 0:01:12
 Epoch: 9, lr: 1.0e-02, train_loss: 1.6594, train_acc: 0.3850 test_loss: 1.4242, test_acc: 0.4713, best: 0.4713, time: 0:01:09
 Epoch: 10, lr: 1.0e-02, train_loss: 1.6058, train_acc: 0.4034 test_loss: 1.4294, test_acc: 0.4659, best: 0.4713, time: 0:01:11
 Epoch: 11, lr: 1.0e-02, train_loss: 1.5621, train_acc: 0.4182 test_loss: 1.3407, test_acc: 0.5001, best: 0.5001, time: 0:01:07
 Epoch: 12, lr: 1.0e-02, train_loss: 1.5339, train_acc: 0.4302 test_loss: 1.3959, test_acc: 0.4769, best: 0.5001, time: 0:01:10
 Epoch: 13, lr: 1.0e-02, train_loss: 1.5100, train_acc: 0.4458 test_loss: 1.4081, test_acc: 0.4795, best: 0.5001, time: 0:01:10
 Epoch: 14, lr: 1.0e-02, train_loss: 1.4631, train_acc: 0.4578 test_loss: 1.2897, test_acc: 0.5265, best: 0.5265, time: 0:01:11
 Epoch: 15, lr: 1.0e-02, train_loss: 1.4419, train_acc: 0.4686 test_loss: 1.3334, test_acc: 0.5156, best: 0.5265, time: 0:01:10
 Epoch: 16, lr: 1.0e-02, train_loss: 1.4120, train_acc: 0.4826 test_loss: 1.2756, test_acc: 0.5228, best: 0.5265, time: 0:01:11
 Epoch: 17, lr: 1.0e-02, train_loss: 1.4006, train_acc: 0.4798 test_loss: 1.2974, test_acc: 0.5220, best: 0.5265, time: 0:01:10
 Epoch: 18, lr: 1.0e-02, train_loss: 1.3745, train_acc: 0.4952 test_loss: 1.2415, test_acc: 0.5343, best: 0.5343, time: 0:01:12
 Epoch: 19, lr: 1.0e-02, train_loss: 1.3485, train_acc: 0.5120 test_loss: 1.2578, test_acc: 0.5457, best: 0.5457, time: 0:01:11
 Epoch: 20, lr: 1.0e-02, train_loss: 1.3123, train_acc: 0.5166 test_loss: 1.1575, test_acc: 0.5803, best: 0.5803, time: 0:01:10
 Epoch: 21, lr: 1.0e-02, train_loss: 1.3072, train_acc: 0.5112 test_loss: 1.2142, test_acc: 0.5524, best: 0.5803, time: 0:01:10
 Epoch: 22, lr: 1.0e-02, train_loss: 1.2833, train_acc: 0.5360 test_loss: 1.1082, test_acc: 0.5984, best: 0.5984, time: 0:01:12
 Epoch: 23, lr: 1.0e-02, train_loss: 1.2743, train_acc: 0.5344 test_loss: 1.1243, test_acc: 0.5897, best: 0.5984, time: 0:01:12
 Epoch: 24, lr: 1.0e-02, train_loss: 1.2599, train_acc: 0.5374 test_loss: 1.0793, test_acc: 0.6054, best: 0.6054, time: 0:01:12
 Epoch: 25, lr: 1.0e-02, train_loss: 1.2403, train_acc: 0.5502 test_loss: 1.1620, test_acc: 0.5800, best: 0.6054, time: 0:01:08
 Epoch: 26, lr: 1.0e-02, train_loss: 1.2193, train_acc: 0.5572 test_loss: 1.1954, test_acc: 0.5640, best: 0.6054, time: 0:01:11
 Epoch: 27, lr: 1.0e-02, train_loss: 1.2134, train_acc: 0.5596 test_loss: 1.0943, test_acc: 0.6024, best: 0.6054, time: 0:01:10
 Epoch: 28, lr: 1.0e-02, train_loss: 1.1953, train_acc: 0.5664 test_loss: 1.2333, test_acc: 0.5646, best: 0.6054, time: 0:01:05
 Epoch: 29, lr: 1.0e-02, train_loss: 1.1617, train_acc: 0.5838 test_loss: 1.1256, test_acc: 0.6049, best: 0.6054, time: 0:01:10
 Epoch: 30, lr: 1.0e-02, train_loss: 1.1698, train_acc: 0.5752 test_loss: 1.1312, test_acc: 0.5961, best: 0.6054, time: 0:01:04
 Epoch: 31, lr: 1.0e-02, train_loss: 1.1559, train_acc: 0.5842 test_loss: 1.1186, test_acc: 0.6035, best: 0.6054, time: 0:01:10
 Epoch: 32, lr: 1.0e-02, train_loss: 1.1386, train_acc: 0.5910 test_loss: 1.0146, test_acc: 0.6345, best: 0.6345, time: 0:01:10
 Epoch: 33, lr: 1.0e-02, train_loss: 1.1190, train_acc: 0.5884 test_loss: 1.0857, test_acc: 0.6128, best: 0.6345, time: 0:01:00
 Epoch: 34, lr: 1.0e-02, train_loss: 1.1154, train_acc: 0.6010 test_loss: 1.0843, test_acc: 0.6169, best: 0.6345, time: 0:01:10
 Epoch: 35, lr: 1.0e-02, train_loss: 1.0773, train_acc: 0.6130 test_loss: 1.0132, test_acc: 0.6434, best: 0.6434, time: 0:01:07
 Epoch: 36, lr: 1.0e-02, train_loss: 1.0926, train_acc: 0.6106 test_loss: 1.0073, test_acc: 0.6330, best: 0.6434, time: 0:01:06
 Epoch: 37, lr: 1.0e-02, train_loss: 1.0665, train_acc: 0.6174 test_loss: 1.0205, test_acc: 0.6358, best: 0.6434, time: 0:01:10
 Epoch: 38, lr: 1.0e-02, train_loss: 1.0688, train_acc: 0.6072 test_loss: 1.0430, test_acc: 0.6330, best: 0.6434, time: 0:01:02
 Epoch: 39, lr: 1.0e-02, train_loss: 1.0576, train_acc: 0.6156 test_loss: 1.0712, test_acc: 0.6248, best: 0.6434, time: 0:01:10
 Epoch: 40, lr: 1.0e-02, train_loss: 1.0391, train_acc: 0.6252 test_loss: 1.0862, test_acc: 0.6182, best: 0.6434, time: 0:01:11
 Epoch: 41, lr: 1.0e-02, train_loss: 1.0281, train_acc: 0.6184 test_loss: 0.9921, test_acc: 0.6548, best: 0.6548, time: 0:01:11
 Epoch: 42, lr: 1.0e-02, train_loss: 1.0260, train_acc: 0.6396 test_loss: 1.0822, test_acc: 0.6319, best: 0.6548, time: 0:01:11
 Epoch: 43, lr: 1.0e-02, train_loss: 1.0102, train_acc: 0.6356 test_loss: 0.9958, test_acc: 0.6458, best: 0.6548, time: 0:01:10
 Epoch: 44, lr: 1.0e-02, train_loss: 0.9960, train_acc: 0.6434 test_loss: 1.0312, test_acc: 0.6456, best: 0.6548, time: 0:01:11
 Epoch: 45, lr: 1.0e-02, train_loss: 0.9791, train_acc: 0.6524 test_loss: 0.9348, test_acc: 0.6709, best: 0.6709, time: 0:01:10
 Epoch: 46, lr: 1.0e-02, train_loss: 0.9869, train_acc: 0.6480 test_loss: 1.1066, test_acc: 0.6234, best: 0.6709, time: 0:01:09
 Epoch: 47, lr: 1.0e-02, train_loss: 0.9593, train_acc: 0.6476 test_loss: 1.0171, test_acc: 0.6524, best: 0.6709, time: 0:01:12
 Epoch: 48, lr: 1.0e-02, train_loss: 0.9730, train_acc: 0.6550 test_loss: 0.9846, test_acc: 0.6565, best: 0.6709, time: 0:01:09
 Epoch: 49, lr: 1.0e-02, train_loss: 0.9409, train_acc: 0.6584 test_loss: 0.9511, test_acc: 0.6689, best: 0.6709, time: 0:01:10
 Epoch: 50, lr: 1.0e-02, train_loss: 0.9231, train_acc: 0.6690 test_loss: 0.9817, test_acc: 0.6559, best: 0.6709, time: 0:01:09
 Epoch: 51, lr: 1.0e-02, train_loss: 0.9385, train_acc: 0.6656 test_loss: 0.9236, test_acc: 0.6747, best: 0.6747, time: 0:01:10
 Epoch: 52, lr: 1.0e-02, train_loss: 0.9059, train_acc: 0.6772 test_loss: 1.0752, test_acc: 0.6435, best: 0.6747, time: 0:01:08
 Epoch: 53, lr: 1.0e-02, train_loss: 0.9201, train_acc: 0.6698 test_loss: 0.9473, test_acc: 0.6666, best: 0.6747, time: 0:01:10
 Epoch: 54, lr: 1.0e-02, train_loss: 0.9163, train_acc: 0.6770 test_loss: 0.9181, test_acc: 0.6836, best: 0.6836, time: 0:01:10
 Epoch: 55, lr: 1.0e-02, train_loss: 0.9274, train_acc: 0.6700 test_loss: 0.9415, test_acc: 0.6770, best: 0.6836, time: 0:01:08
 Epoch: 56, lr: 1.0e-02, train_loss: 0.9007, train_acc: 0.6812 test_loss: 0.9491, test_acc: 0.6726, best: 0.6836, time: 0:01:09
 Epoch: 57, lr: 1.0e-02, train_loss: 0.8692, train_acc: 0.6900 test_loss: 0.8602, test_acc: 0.6999, best: 0.6999, time: 0:01:07
 Epoch: 58, lr: 1.0e-02, train_loss: 0.8694, train_acc: 0.6904 test_loss: 0.9097, test_acc: 0.6867, best: 0.6999, time: 0:01:07
 Epoch: 59, lr: 1.0e-02, train_loss: 0.8586, train_acc: 0.6964 test_loss: 0.8919, test_acc: 0.6879, best: 0.6999, time: 0:01:11
 Epoch: 60, lr: 1.0e-02, train_loss: 0.8281, train_acc: 0.7008 test_loss: 0.9917, test_acc: 0.6711, best: 0.6999, time: 0:01:11
 Epoch: 61, lr: 1.0e-02, train_loss: 0.8391, train_acc: 0.7028 test_loss: 0.9573, test_acc: 0.6715, best: 0.6999, time: 0:01:10
 Epoch: 62, lr: 1.0e-02, train_loss: 0.8319, train_acc: 0.6980 test_loss: 0.9821, test_acc: 0.6706, best: 0.6999, time: 0:01:06
 Epoch: 63, lr: 1.0e-02, train_loss: 0.8434, train_acc: 0.7042 test_loss: 1.0050, test_acc: 0.6741, best: 0.6999, time: 0:01:10
 Epoch: 64, lr: 1.0e-02, train_loss: 0.8118, train_acc: 0.7136 test_loss: 0.9145, test_acc: 0.6884, best: 0.6999, time: 0:01:10
 Epoch: 65, lr: 1.0e-02, train_loss: 0.8000, train_acc: 0.7134 test_loss: 0.9431, test_acc: 0.6925, best: 0.6999, time: 0:01:09
 Epoch: 66, lr: 1.0e-02, train_loss: 0.8013, train_acc: 0.7118 test_loss: 0.9342, test_acc: 0.6831, best: 0.6999, time: 0:01:10
 Epoch: 67, lr: 1.0e-02, train_loss: 0.7767, train_acc: 0.7210 test_loss: 0.9082, test_acc: 0.6896, best: 0.6999, time: 0:01:10
 Epoch: 68, lr: 1.0e-02, train_loss: 0.7888, train_acc: 0.7238 test_loss: 1.0080, test_acc: 0.6794, best: 0.6999, time: 0:01:12
 Epoch: 69, lr: 1.0e-02, train_loss: 0.7738, train_acc: 0.7258 test_loss: 0.8942, test_acc: 0.7067, best: 0.7067, time: 0:01:12
 Epoch: 70, lr: 1.0e-02, train_loss: 0.7866, train_acc: 0.7226 test_loss: 0.9579, test_acc: 0.6876, best: 0.7067, time: 0:01:11
 Epoch: 71, lr: 1.0e-02, train_loss: 0.7758, train_acc: 0.7250 test_loss: 0.8347, test_acc: 0.7054, best: 0.7067, time: 0:01:09
 Epoch: 72, lr: 1.0e-02, train_loss: 0.7377, train_acc: 0.7422 test_loss: 0.8717, test_acc: 0.7086, best: 0.7086, time: 0:01:09
 Epoch: 73, lr: 1.0e-02, train_loss: 0.7634, train_acc: 0.7278 test_loss: 0.9291, test_acc: 0.6997, best: 0.7086, time: 0:01:10
 Epoch: 74, lr: 1.0e-02, train_loss: 0.7595, train_acc: 0.7216 test_loss: 0.9045, test_acc: 0.6961, best: 0.7086, time: 0:01:08
 Epoch: 75, lr: 1.0e-02, train_loss: 0.7506, train_acc: 0.7314 test_loss: 0.9604, test_acc: 0.6946, best: 0.7086, time: 0:01:10
 Epoch: 76, lr: 1.0e-02, train_loss: 0.7388, train_acc: 0.7422 test_loss: 0.9009, test_acc: 0.7109, best: 0.7109, time: 0:01:11
 Epoch: 77, lr: 1.0e-02, train_loss: 0.7248, train_acc: 0.7404 test_loss: 0.9501, test_acc: 0.6913, best: 0.7109, time: 0:01:10
 Epoch: 78, lr: 1.0e-02, train_loss: 0.7324, train_acc: 0.7384 test_loss: 0.9248, test_acc: 0.6985, best: 0.7109, time: 0:01:08
 Epoch: 79, lr: 1.0e-02, train_loss: 0.7250, train_acc: 0.7532 test_loss: 0.8806, test_acc: 0.7129, best: 0.7129, time: 0:01:08
 Epoch: 80, lr: 1.0e-02, train_loss: 0.7041, train_acc: 0.7578 test_loss: 0.8956, test_acc: 0.7031, best: 0.7129, time: 0:01:08
 Epoch: 81, lr: 1.0e-02, train_loss: 0.7174, train_acc: 0.7522 test_loss: 0.9095, test_acc: 0.7053, best: 0.7129, time: 0:01:09
 Epoch: 82, lr: 1.0e-02, train_loss: 0.7001, train_acc: 0.7524 test_loss: 0.8687, test_acc: 0.7170, best: 0.7170, time: 0:01:11
 Epoch: 83, lr: 1.0e-02, train_loss: 0.7089, train_acc: 0.7526 test_loss: 0.8661, test_acc: 0.7147, best: 0.7170, time: 0:01:07
 Epoch: 84, lr: 1.0e-02, train_loss: 0.7031, train_acc: 0.7544 test_loss: 0.9522, test_acc: 0.7040, best: 0.7170, time: 0:01:09
 Epoch: 85, lr: 1.0e-02, train_loss: 0.6826, train_acc: 0.7594 test_loss: 0.9254, test_acc: 0.7040, best: 0.7170, time: 0:01:11
 Epoch: 86, lr: 1.0e-02, train_loss: 0.6850, train_acc: 0.7554 test_loss: 0.9062, test_acc: 0.7070, best: 0.7170, time: 0:01:11
 Epoch: 87, lr: 1.0e-02, train_loss: 0.6656, train_acc: 0.7596 test_loss: 1.1356, test_acc: 0.6727, best: 0.7170, time: 0:01:11
 Epoch: 88, lr: 1.0e-02, train_loss: 0.6845, train_acc: 0.7604 test_loss: 0.9519, test_acc: 0.7011, best: 0.7170, time: 0:01:10
 Epoch: 89, lr: 1.0e-02, train_loss: 0.6712, train_acc: 0.7660 test_loss: 0.9909, test_acc: 0.7007, best: 0.7170, time: 0:01:11
 Epoch: 90, lr: 1.0e-02, train_loss: 0.6514, train_acc: 0.7692 test_loss: 1.0824, test_acc: 0.6917, best: 0.7170, time: 0:01:11
 Epoch: 91, lr: 1.0e-02, train_loss: 0.6944, train_acc: 0.7526 test_loss: 0.8650, test_acc: 0.7235, best: 0.7235, time: 0:01:12
 Epoch: 92, lr: 1.0e-02, train_loss: 0.6558, train_acc: 0.7690 test_loss: 1.0010, test_acc: 0.6965, best: 0.7235, time: 0:01:11
 Epoch: 93, lr: 1.0e-02, train_loss: 0.6487, train_acc: 0.7720 test_loss: 0.9319, test_acc: 0.7105, best: 0.7235, time: 0:01:11
 Epoch: 94, lr: 1.0e-02, train_loss: 0.6321, train_acc: 0.7746 test_loss: 0.9528, test_acc: 0.7065, best: 0.7235, time: 0:01:11
 Epoch: 95, lr: 1.0e-02, train_loss: 0.6340, train_acc: 0.7784 test_loss: 0.8386, test_acc: 0.7281, best: 0.7281, time: 0:01:11
 Epoch: 96, lr: 1.0e-02, train_loss: 0.6310, train_acc: 0.7780 test_loss: 0.9048, test_acc: 0.7126, best: 0.7281, time: 0:01:11
 Epoch: 97, lr: 1.0e-02, train_loss: 0.6209, train_acc: 0.7872 test_loss: 0.9241, test_acc: 0.7174, best: 0.7281, time: 0:01:11
 Epoch: 98, lr: 1.0e-02, train_loss: 0.6308, train_acc: 0.7742 test_loss: 0.8452, test_acc: 0.7166, best: 0.7281, time: 0:01:11
 Epoch: 99, lr: 1.0e-02, train_loss: 0.6065, train_acc: 0.7830 test_loss: 0.8992, test_acc: 0.7250, best: 0.7281, time: 0:01:12
 Epoch: 100, lr: 1.0e-02, train_loss: 0.6443, train_acc: 0.7722 test_loss: 0.8615, test_acc: 0.7302, best: 0.7302, time: 0:01:11
 Epoch: 101, lr: 1.0e-02, train_loss: 0.6072, train_acc: 0.7886 test_loss: 0.9929, test_acc: 0.7071, best: 0.7302, time: 0:01:12
 Epoch: 102, lr: 1.0e-02, train_loss: 0.6046, train_acc: 0.7906 test_loss: 0.9815, test_acc: 0.7120, best: 0.7302, time: 0:01:11
 Epoch: 103, lr: 1.0e-02, train_loss: 0.6027, train_acc: 0.7858 test_loss: 0.8951, test_acc: 0.7230, best: 0.7302, time: 0:01:11
 Epoch: 104, lr: 1.0e-02, train_loss: 0.5906, train_acc: 0.7872 test_loss: 0.9164, test_acc: 0.7238, best: 0.7302, time: 0:01:11
 Epoch: 105, lr: 1.0e-02, train_loss: 0.5852, train_acc: 0.7946 test_loss: 0.9690, test_acc: 0.7251, best: 0.7302, time: 0:01:11
 Epoch: 106, lr: 1.0e-02, train_loss: 0.5735, train_acc: 0.7952 test_loss: 0.9714, test_acc: 0.7137, best: 0.7302, time: 0:01:12
 Epoch: 107, lr: 1.0e-02, train_loss: 0.5773, train_acc: 0.7950 test_loss: 0.8846, test_acc: 0.7306, best: 0.7306, time: 0:01:12
 Epoch: 108, lr: 1.0e-02, train_loss: 0.5880, train_acc: 0.7942 test_loss: 0.9252, test_acc: 0.7255, best: 0.7306, time: 0:01:12
 Epoch: 109, lr: 1.0e-02, train_loss: 0.5568, train_acc: 0.8034 test_loss: 0.9128, test_acc: 0.7334, best: 0.7334, time: 0:01:11
 Epoch: 110, lr: 1.0e-02, train_loss: 0.5489, train_acc: 0.8068 test_loss: 0.9026, test_acc: 0.7290, best: 0.7334, time: 0:01:11
 Epoch: 111, lr: 1.0e-02, train_loss: 0.5715, train_acc: 0.7974 test_loss: 0.8996, test_acc: 0.7260, best: 0.7334, time: 0:01:11
 Epoch: 112, lr: 1.0e-02, train_loss: 0.5988, train_acc: 0.7918 test_loss: 0.8813, test_acc: 0.7280, best: 0.7334, time: 0:01:10
 Epoch: 113, lr: 1.0e-02, train_loss: 0.5526, train_acc: 0.8012 test_loss: 0.9036, test_acc: 0.7332, best: 0.7334, time: 0:01:11
 Epoch: 114, lr: 1.0e-02, train_loss: 0.5395, train_acc: 0.8030 test_loss: 0.8758, test_acc: 0.7436, best: 0.7436, time: 0:01:12
 Epoch: 115, lr: 1.0e-02, train_loss: 0.5551, train_acc: 0.8072 test_loss: 0.9848, test_acc: 0.7289, best: 0.7436, time: 0:01:11
 Epoch: 116, lr: 1.0e-02, train_loss: 0.5367, train_acc: 0.8152 test_loss: 0.8784, test_acc: 0.7410, best: 0.7436, time: 0:01:12
 Epoch: 117, lr: 1.0e-02, train_loss: 0.5431, train_acc: 0.8062 test_loss: 0.9308, test_acc: 0.7250, best: 0.7436, time: 0:01:11
 Epoch: 118, lr: 1.0e-02, train_loss: 0.5314, train_acc: 0.8160 test_loss: 0.9666, test_acc: 0.7331, best: 0.7436, time: 0:01:12
 Epoch: 119, lr: 1.0e-02, train_loss: 0.5351, train_acc: 0.8180 test_loss: 0.9329, test_acc: 0.7276, best: 0.7436, time: 0:01:12
 Epoch: 120, lr: 1.0e-02, train_loss: 0.5459, train_acc: 0.8082 test_loss: 0.8585, test_acc: 0.7426, best: 0.7436, time: 0:01:10
 Epoch: 121, lr: 1.0e-02, train_loss: 0.5332, train_acc: 0.8144 test_loss: 0.9459, test_acc: 0.7312, best: 0.7436, time: 0:01:12
 Epoch: 122, lr: 1.0e-02, train_loss: 0.5333, train_acc: 0.8208 test_loss: 0.9377, test_acc: 0.7324, best: 0.7436, time: 0:01:11
 Epoch: 123, lr: 1.0e-02, train_loss: 0.5293, train_acc: 0.8156 test_loss: 0.9562, test_acc: 0.7209, best: 0.7436, time: 0:01:10
 Epoch: 124, lr: 1.0e-02, train_loss: 0.5237, train_acc: 0.8158 test_loss: 1.0125, test_acc: 0.7224, best: 0.7436, time: 0:01:11
 Epoch: 125, lr: 1.0e-02, train_loss: 0.5118, train_acc: 0.8202 test_loss: 0.9066, test_acc: 0.7340, best: 0.7436, time: 0:01:12
 Epoch: 126, lr: 1.0e-02, train_loss: 0.5261, train_acc: 0.8192 test_loss: 0.9070, test_acc: 0.7369, best: 0.7436, time: 0:01:11
 Epoch: 127, lr: 1.0e-02, train_loss: 0.5196, train_acc: 0.8182 test_loss: 0.9494, test_acc: 0.7316, best: 0.7436, time: 0:01:11
 Epoch: 128, lr: 1.0e-02, train_loss: 0.5166, train_acc: 0.8152 test_loss: 1.0357, test_acc: 0.7081, best: 0.7436, time: 0:01:11
 Epoch: 129, lr: 1.0e-02, train_loss: 0.5016, train_acc: 0.8318 test_loss: 1.0040, test_acc: 0.7264, best: 0.7436, time: 0:01:10
 Epoch: 130, lr: 1.0e-02, train_loss: 0.4952, train_acc: 0.8230 test_loss: 0.9033, test_acc: 0.7415, best: 0.7436, time: 0:01:11
 Epoch: 131, lr: 1.0e-02, train_loss: 0.5208, train_acc: 0.8184 test_loss: 0.9237, test_acc: 0.7362, best: 0.7436, time: 0:01:11
 Epoch: 132, lr: 1.0e-02, train_loss: 0.4931, train_acc: 0.8328 test_loss: 1.0794, test_acc: 0.7079, best: 0.7436, time: 0:01:10
 Epoch: 133, lr: 1.0e-02, train_loss: 0.4866, train_acc: 0.8290 test_loss: 0.9249, test_acc: 0.7272, best: 0.7436, time: 0:01:12
 Epoch: 134, lr: 1.0e-02, train_loss: 0.4844, train_acc: 0.8352 test_loss: 0.9290, test_acc: 0.7450, best: 0.7450, time: 0:01:11
 Epoch: 135, lr: 1.0e-02, train_loss: 0.4949, train_acc: 0.8322 test_loss: 0.8907, test_acc: 0.7499, best: 0.7499, time: 0:01:12
 Epoch: 136, lr: 1.0e-02, train_loss: 0.4885, train_acc: 0.8284 test_loss: 0.9112, test_acc: 0.7344, best: 0.7499, time: 0:01:11
 Epoch: 137, lr: 1.0e-02, train_loss: 0.4920, train_acc: 0.8238 test_loss: 0.9038, test_acc: 0.7488, best: 0.7499, time: 0:01:11
 Epoch: 138, lr: 1.0e-02, train_loss: 0.4881, train_acc: 0.8304 test_loss: 0.9095, test_acc: 0.7379, best: 0.7499, time: 0:01:12
 Epoch: 139, lr: 1.0e-02, train_loss: 0.5072, train_acc: 0.8242 test_loss: 0.9326, test_acc: 0.7326, best: 0.7499, time: 0:01:10
 Epoch: 140, lr: 1.0e-02, train_loss: 0.4891, train_acc: 0.8274 test_loss: 0.8890, test_acc: 0.7472, best: 0.7499, time: 0:01:12
 Epoch: 141, lr: 1.0e-02, train_loss: 0.4844, train_acc: 0.8322 test_loss: 0.9208, test_acc: 0.7445, best: 0.7499, time: 0:01:10
 Epoch: 142, lr: 1.0e-02, train_loss: 0.4740, train_acc: 0.8346 test_loss: 0.8816, test_acc: 0.7392, best: 0.7499, time: 0:01:12
 Epoch: 143, lr: 1.0e-02, train_loss: 0.4601, train_acc: 0.8402 test_loss: 0.9544, test_acc: 0.7275, best: 0.7499, time: 0:01:11
 Epoch: 144, lr: 1.0e-02, train_loss: 0.4493, train_acc: 0.8482 test_loss: 0.9859, test_acc: 0.7299, best: 0.7499, time: 0:01:11
 Epoch: 145, lr: 1.0e-02, train_loss: 0.4611, train_acc: 0.8400 test_loss: 0.8976, test_acc: 0.7485, best: 0.7499, time: 0:01:11
 Epoch: 146, lr: 1.0e-02, train_loss: 0.4726, train_acc: 0.8346 test_loss: 0.8977, test_acc: 0.7402, best: 0.7499, time: 0:01:11
 Epoch: 147, lr: 1.0e-02, train_loss: 0.4589, train_acc: 0.8440 test_loss: 0.9100, test_acc: 0.7491, best: 0.7499, time: 0:01:08
 Epoch: 148, lr: 1.0e-02, train_loss: 0.4409, train_acc: 0.8448 test_loss: 0.9537, test_acc: 0.7428, best: 0.7499, time: 0:01:07
 Epoch: 149, lr: 1.0e-02, train_loss: 0.4546, train_acc: 0.8370 test_loss: 1.0312, test_acc: 0.7339, best: 0.7499, time: 0:01:11
 Epoch: 150, lr: 1.0e-02, train_loss: 0.4559, train_acc: 0.8470 test_loss: 0.9090, test_acc: 0.7506, best: 0.7506, time: 0:01:11
 Epoch: 151, lr: 1.0e-02, train_loss: 0.4513, train_acc: 0.8416 test_loss: 0.9149, test_acc: 0.7462, best: 0.7506, time: 0:01:09
 Epoch: 152, lr: 1.0e-02, train_loss: 0.4551, train_acc: 0.8424 test_loss: 0.9442, test_acc: 0.7431, best: 0.7506, time: 0:01:10
 Epoch: 153, lr: 1.0e-02, train_loss: 0.4523, train_acc: 0.8474 test_loss: 1.0117, test_acc: 0.7344, best: 0.7506, time: 0:01:10
 Epoch: 154, lr: 1.0e-02, train_loss: 0.4344, train_acc: 0.8524 test_loss: 0.9317, test_acc: 0.7470, best: 0.7506, time: 0:01:11
 Epoch: 155, lr: 1.0e-02, train_loss: 0.4447, train_acc: 0.8480 test_loss: 0.8952, test_acc: 0.7604, best: 0.7604, time: 0:01:11
 Epoch: 156, lr: 1.0e-02, train_loss: 0.4198, train_acc: 0.8548 test_loss: 0.9321, test_acc: 0.7438, best: 0.7604, time: 0:01:10
 Epoch: 157, lr: 1.0e-02, train_loss: 0.4317, train_acc: 0.8468 test_loss: 0.9261, test_acc: 0.7414, best: 0.7604, time: 0:01:12
 Epoch: 158, lr: 1.0e-02, train_loss: 0.4258, train_acc: 0.8558 test_loss: 0.9781, test_acc: 0.7404, best: 0.7604, time: 0:01:11
 Epoch: 159, lr: 1.0e-02, train_loss: 0.4185, train_acc: 0.8518 test_loss: 1.0215, test_acc: 0.7310, best: 0.7604, time: 0:01:11
 Epoch: 160, lr: 1.0e-02, train_loss: 0.4055, train_acc: 0.8642 test_loss: 0.9852, test_acc: 0.7420, best: 0.7604, time: 0:01:10
 Epoch: 161, lr: 1.0e-02, train_loss: 0.4419, train_acc: 0.8448 test_loss: 1.0092, test_acc: 0.7305, best: 0.7604, time: 0:01:08
 Epoch: 162, lr: 1.0e-02, train_loss: 0.4060, train_acc: 0.8608 test_loss: 1.0219, test_acc: 0.7350, best: 0.7604, time: 0:01:10
 Epoch: 163, lr: 1.0e-02, train_loss: 0.4171, train_acc: 0.8518 test_loss: 0.9530, test_acc: 0.7460, best: 0.7604, time: 0:01:11
 Epoch: 164, lr: 1.0e-02, train_loss: 0.4139, train_acc: 0.8558 test_loss: 1.0024, test_acc: 0.7344, best: 0.7604, time: 0:01:09
 Epoch: 165, lr: 1.0e-02, train_loss: 0.3901, train_acc: 0.8634 test_loss: 1.0298, test_acc: 0.7458, best: 0.7604, time: 0:01:11
 Epoch: 166, lr: 1.0e-02, train_loss: 0.4135, train_acc: 0.8572 test_loss: 0.9550, test_acc: 0.7496, best: 0.7604, time: 0:01:11
 Epoch: 167, lr: 1.0e-02, train_loss: 0.4287, train_acc: 0.8542 test_loss: 0.9649, test_acc: 0.7459, best: 0.7604, time: 0:01:11
 Epoch: 168, lr: 1.0e-02, train_loss: 0.4010, train_acc: 0.8640 test_loss: 1.0397, test_acc: 0.7452, best: 0.7604, time: 0:01:11
 Epoch: 169, lr: 1.0e-02, train_loss: 0.4010, train_acc: 0.8590 test_loss: 1.0516, test_acc: 0.7324, best: 0.7604, time: 0:01:11
 Epoch: 170, lr: 1.0e-02, train_loss: 0.3974, train_acc: 0.8634 test_loss: 0.9575, test_acc: 0.7452, best: 0.7604, time: 0:01:08
 Epoch: 171, lr: 1.0e-02, train_loss: 0.4119, train_acc: 0.8566 test_loss: 0.9874, test_acc: 0.7454, best: 0.7604, time: 0:01:11
 Epoch: 172, lr: 1.0e-02, train_loss: 0.4079, train_acc: 0.8624 test_loss: 1.0193, test_acc: 0.7311, best: 0.7604, time: 0:01:09
 Epoch: 173, lr: 1.0e-02, train_loss: 0.3973, train_acc: 0.8662 test_loss: 0.9969, test_acc: 0.7418, best: 0.7604, time: 0:01:11
 Epoch: 174, lr: 1.0e-02, train_loss: 0.3917, train_acc: 0.8646 test_loss: 0.9964, test_acc: 0.7438, best: 0.7604, time: 0:01:10
 Epoch: 175, lr: 1.0e-02, train_loss: 0.3778, train_acc: 0.8676 test_loss: 1.0267, test_acc: 0.7395, best: 0.7604, time: 0:01:10
 Epoch: 176, lr: 1.0e-02, train_loss: 0.3919, train_acc: 0.8652 test_loss: 0.9621, test_acc: 0.7369, best: 0.7604, time: 0:01:10
 Epoch: 177, lr: 1.0e-02, train_loss: 0.4068, train_acc: 0.8616 test_loss: 0.9151, test_acc: 0.7474, best: 0.7604, time: 0:01:10
 Epoch: 178, lr: 1.0e-02, train_loss: 0.3975, train_acc: 0.8634 test_loss: 0.9997, test_acc: 0.7509, best: 0.7604, time: 0:01:09
 Epoch: 179, lr: 1.0e-02, train_loss: 0.4039, train_acc: 0.8622 test_loss: 1.0051, test_acc: 0.7465, best: 0.7604, time: 0:01:10
 Epoch: 180, lr: 2.0e-03, train_loss: 0.3515, train_acc: 0.8780 test_loss: 0.9338, test_acc: 0.7614, best: 0.7614, time: 0:01:08
 Epoch: 181, lr: 2.0e-03, train_loss: 0.3020, train_acc: 0.8968 test_loss: 0.9275, test_acc: 0.7679, best: 0.7679, time: 0:01:10
 Epoch: 182, lr: 2.0e-03, train_loss: 0.3224, train_acc: 0.8862 test_loss: 0.9070, test_acc: 0.7636, best: 0.7679, time: 0:01:11
 Epoch: 183, lr: 2.0e-03, train_loss: 0.3093, train_acc: 0.8948 test_loss: 0.9325, test_acc: 0.7638, best: 0.7679, time: 0:01:10
 Epoch: 184, lr: 2.0e-03, train_loss: 0.3203, train_acc: 0.8900 test_loss: 0.8899, test_acc: 0.7628, best: 0.7679, time: 0:01:05
 Epoch: 185, lr: 2.0e-03, train_loss: 0.3131, train_acc: 0.8912 test_loss: 0.9353, test_acc: 0.7694, best: 0.7694, time: 0:01:11
 Epoch: 186, lr: 2.0e-03, train_loss: 0.2979, train_acc: 0.8986 test_loss: 0.9227, test_acc: 0.7701, best: 0.7701, time: 0:01:05
 Epoch: 187, lr: 2.0e-03, train_loss: 0.2797, train_acc: 0.9058 test_loss: 0.9352, test_acc: 0.7671, best: 0.7701, time: 0:01:10
 Epoch: 188, lr: 2.0e-03, train_loss: 0.2954, train_acc: 0.8978 test_loss: 0.9025, test_acc: 0.7722, best: 0.7722, time: 0:01:05
 Epoch: 189, lr: 2.0e-03, train_loss: 0.2956, train_acc: 0.8966 test_loss: 0.9306, test_acc: 0.7691, best: 0.7722, time: 0:01:09
 Epoch: 190, lr: 2.0e-03, train_loss: 0.2717, train_acc: 0.9098 test_loss: 0.9199, test_acc: 0.7652, best: 0.7722, time: 0:01:09
 Epoch: 191, lr: 2.0e-03, train_loss: 0.3022, train_acc: 0.8944 test_loss: 0.9304, test_acc: 0.7655, best: 0.7722, time: 0:01:09
 Epoch: 192, lr: 2.0e-03, train_loss: 0.2779, train_acc: 0.9062 test_loss: 0.9371, test_acc: 0.7646, best: 0.7722, time: 0:01:11
 Epoch: 193, lr: 2.0e-03, train_loss: 0.2858, train_acc: 0.9018 test_loss: 0.9013, test_acc: 0.7691, best: 0.7722, time: 0:01:11
 Epoch: 194, lr: 2.0e-03, train_loss: 0.2930, train_acc: 0.8986 test_loss: 0.9117, test_acc: 0.7721, best: 0.7722, time: 0:01:09
 Epoch: 195, lr: 2.0e-03, train_loss: 0.2784, train_acc: 0.9074 test_loss: 0.9303, test_acc: 0.7624, best: 0.7722, time: 0:01:12
 Epoch: 196, lr: 2.0e-03, train_loss: 0.2791, train_acc: 0.9068 test_loss: 0.9190, test_acc: 0.7681, best: 0.7722, time: 0:01:12
 Epoch: 197, lr: 2.0e-03, train_loss: 0.2850, train_acc: 0.9024 test_loss: 0.9169, test_acc: 0.7691, best: 0.7722, time: 0:01:12
 Epoch: 198, lr: 2.0e-03, train_loss: 0.2641, train_acc: 0.9116 test_loss: 0.9720, test_acc: 0.7652, best: 0.7722, time: 0:01:08
 Epoch: 199, lr: 2.0e-03, train_loss: 0.2564, train_acc: 0.9134 test_loss: 0.9239, test_acc: 0.7664, best: 0.7722, time: 0:01:05
 Epoch: 200, lr: 2.0e-03, train_loss: 0.2683, train_acc: 0.9076 test_loss: 0.9276, test_acc: 0.7685, best: 0.7722, time: 0:01:08
 Epoch: 201, lr: 2.0e-03, train_loss: 0.2808, train_acc: 0.9026 test_loss: 0.9158, test_acc: 0.7714, best: 0.7722, time: 0:01:10
 Epoch: 202, lr: 2.0e-03, train_loss: 0.2835, train_acc: 0.9026 test_loss: 0.9335, test_acc: 0.7665, best: 0.7722, time: 0:01:09
 Epoch: 203, lr: 2.0e-03, train_loss: 0.2664, train_acc: 0.9106 test_loss: 0.8973, test_acc: 0.7681, best: 0.7722, time: 0:01:09
 Epoch: 204, lr: 2.0e-03, train_loss: 0.2618, train_acc: 0.9104 test_loss: 0.9124, test_acc: 0.7704, best: 0.7722, time: 0:01:11
 Epoch: 205, lr: 2.0e-03, train_loss: 0.2642, train_acc: 0.9062 test_loss: 0.9588, test_acc: 0.7661, best: 0.7722, time: 0:01:10
 Epoch: 206, lr: 2.0e-03, train_loss: 0.2581, train_acc: 0.9100 test_loss: 0.9674, test_acc: 0.7666, best: 0.7722, time: 0:01:06
 Epoch: 207, lr: 2.0e-03, train_loss: 0.2589, train_acc: 0.9128 test_loss: 0.9700, test_acc: 0.7686, best: 0.7722, time: 0:01:08
 Epoch: 208, lr: 2.0e-03, train_loss: 0.2764, train_acc: 0.9036 test_loss: 0.9363, test_acc: 0.7688, best: 0.7722, time: 0:01:09
 Epoch: 209, lr: 2.0e-03, train_loss: 0.2549, train_acc: 0.9128 test_loss: 0.9303, test_acc: 0.7659, best: 0.7722, time: 0:01:08
 Epoch: 210, lr: 2.0e-03, train_loss: 0.2482, train_acc: 0.9128 test_loss: 0.9310, test_acc: 0.7719, best: 0.7722, time: 0:01:07
 Epoch: 211, lr: 2.0e-03, train_loss: 0.2696, train_acc: 0.9096 test_loss: 0.9401, test_acc: 0.7696, best: 0.7722, time: 0:01:10
 Epoch: 212, lr: 2.0e-03, train_loss: 0.2601, train_acc: 0.9128 test_loss: 0.9449, test_acc: 0.7706, best: 0.7722, time: 0:01:06
 Epoch: 213, lr: 2.0e-03, train_loss: 0.2584, train_acc: 0.9136 test_loss: 0.9211, test_acc: 0.7694, best: 0.7722, time: 0:01:10
 Epoch: 214, lr: 2.0e-03, train_loss: 0.2498, train_acc: 0.9158 test_loss: 0.9285, test_acc: 0.7708, best: 0.7722, time: 0:01:09
 Epoch: 215, lr: 2.0e-03, train_loss: 0.2843, train_acc: 0.9032 test_loss: 0.9506, test_acc: 0.7680, best: 0.7722, time: 0:01:10
 Epoch: 216, lr: 2.0e-03, train_loss: 0.2545, train_acc: 0.9170 test_loss: 0.9564, test_acc: 0.7672, best: 0.7722, time: 0:01:11
 Epoch: 217, lr: 2.0e-03, train_loss: 0.2598, train_acc: 0.9100 test_loss: 0.9357, test_acc: 0.7715, best: 0.7722, time: 0:01:09
 Epoch: 218, lr: 2.0e-03, train_loss: 0.2520, train_acc: 0.9178 test_loss: 0.9158, test_acc: 0.7724, best: 0.7724, time: 0:01:11
 Epoch: 219, lr: 2.0e-03, train_loss: 0.2593, train_acc: 0.9096 test_loss: 0.9406, test_acc: 0.7708, best: 0.7724, time: 0:01:11
 Epoch: 220, lr: 2.0e-03, train_loss: 0.2770, train_acc: 0.9032 test_loss: 0.9403, test_acc: 0.7731, best: 0.7731, time: 0:01:11
 Epoch: 221, lr: 2.0e-03, train_loss: 0.2473, train_acc: 0.9150 test_loss: 0.9537, test_acc: 0.7709, best: 0.7731, time: 0:01:10
 Epoch: 222, lr: 2.0e-03, train_loss: 0.2507, train_acc: 0.9160 test_loss: 0.9371, test_acc: 0.7705, best: 0.7731, time: 0:01:08
 Epoch: 223, lr: 2.0e-03, train_loss: 0.2482, train_acc: 0.9168 test_loss: 0.9514, test_acc: 0.7706, best: 0.7731, time: 0:01:10
 Epoch: 224, lr: 2.0e-03, train_loss: 0.2539, train_acc: 0.9128 test_loss: 0.9603, test_acc: 0.7699, best: 0.7731, time: 0:01:07
 Epoch: 225, lr: 2.0e-03, train_loss: 0.2525, train_acc: 0.9146 test_loss: 0.9752, test_acc: 0.7699, best: 0.7731, time: 0:01:11
 Epoch: 226, lr: 2.0e-03, train_loss: 0.2477, train_acc: 0.9166 test_loss: 0.9695, test_acc: 0.7701, best: 0.7731, time: 0:01:07
 Epoch: 227, lr: 2.0e-03, train_loss: 0.2583, train_acc: 0.9132 test_loss: 0.9540, test_acc: 0.7724, best: 0.7731, time: 0:01:11
 Epoch: 228, lr: 2.0e-03, train_loss: 0.2510, train_acc: 0.9164 test_loss: 0.9613, test_acc: 0.7688, best: 0.7731, time: 0:01:12
 Epoch: 229, lr: 2.0e-03, train_loss: 0.2423, train_acc: 0.9190 test_loss: 0.9533, test_acc: 0.7700, best: 0.7731, time: 0:01:11
 Epoch: 230, lr: 2.0e-03, train_loss: 0.2445, train_acc: 0.9208 test_loss: 0.9352, test_acc: 0.7708, best: 0.7731, time: 0:01:10
 Epoch: 231, lr: 2.0e-03, train_loss: 0.2434, train_acc: 0.9186 test_loss: 0.9540, test_acc: 0.7681, best: 0.7731, time: 0:01:12
 Epoch: 232, lr: 2.0e-03, train_loss: 0.2510, train_acc: 0.9176 test_loss: 0.9499, test_acc: 0.7699, best: 0.7731, time: 0:01:12
 Epoch: 233, lr: 2.0e-03, train_loss: 0.2510, train_acc: 0.9118 test_loss: 0.9876, test_acc: 0.7669, best: 0.7731, time: 0:01:09
 Epoch: 234, lr: 2.0e-03, train_loss: 0.2297, train_acc: 0.9210 test_loss: 0.9796, test_acc: 0.7688, best: 0.7731, time: 0:01:07
 Epoch: 235, lr: 2.0e-03, train_loss: 0.2577, train_acc: 0.9128 test_loss: 1.0053, test_acc: 0.7638, best: 0.7731, time: 0:01:06
 Epoch: 236, lr: 2.0e-03, train_loss: 0.2365, train_acc: 0.9180 test_loss: 0.9708, test_acc: 0.7631, best: 0.7731, time: 0:01:09
 Epoch: 237, lr: 2.0e-03, train_loss: 0.2454, train_acc: 0.9140 test_loss: 0.9573, test_acc: 0.7724, best: 0.7731, time: 0:01:10
 Epoch: 238, lr: 2.0e-03, train_loss: 0.2411, train_acc: 0.9148 test_loss: 0.9329, test_acc: 0.7724, best: 0.7731, time: 0:01:10
 Epoch: 239, lr: 2.0e-03, train_loss: 0.2380, train_acc: 0.9178 test_loss: 0.9378, test_acc: 0.7722, best: 0.7731, time: 0:01:08
 Epoch: 240, lr: 4.0e-04, train_loss: 0.2252, train_acc: 0.9254 test_loss: 0.9563, test_acc: 0.7674, best: 0.7731, time: 0:01:09
 Epoch: 241, lr: 4.0e-04, train_loss: 0.2360, train_acc: 0.9220 test_loss: 0.9529, test_acc: 0.7650, best: 0.7731, time: 0:01:10
 Epoch: 242, lr: 4.0e-04, train_loss: 0.2409, train_acc: 0.9208 test_loss: 0.9692, test_acc: 0.7651, best: 0.7731, time: 0:01:09
 Epoch: 243, lr: 4.0e-04, train_loss: 0.2362, train_acc: 0.9200 test_loss: 0.9622, test_acc: 0.7690, best: 0.7731, time: 0:01:05
 Epoch: 244, lr: 4.0e-04, train_loss: 0.2431, train_acc: 0.9164 test_loss: 0.9730, test_acc: 0.7661, best: 0.7731, time: 0:01:10
 Epoch: 245, lr: 4.0e-04, train_loss: 0.2274, train_acc: 0.9220 test_loss: 0.9732, test_acc: 0.7702, best: 0.7731, time: 0:01:11
 Epoch: 246, lr: 4.0e-04, train_loss: 0.2343, train_acc: 0.9208 test_loss: 0.9555, test_acc: 0.7692, best: 0.7731, time: 0:01:12
 Epoch: 247, lr: 4.0e-04, train_loss: 0.2320, train_acc: 0.9230 test_loss: 0.9622, test_acc: 0.7684, best: 0.7731, time: 0:01:10
 Epoch: 248, lr: 4.0e-04, train_loss: 0.2380, train_acc: 0.9176 test_loss: 0.9512, test_acc: 0.7699, best: 0.7731, time: 0:01:09
 Epoch: 249, lr: 4.0e-04, train_loss: 0.2174, train_acc: 0.9246 test_loss: 0.9440, test_acc: 0.7714, best: 0.7731, time: 0:01:10
 Epoch: 250, lr: 4.0e-04, train_loss: 0.2264, train_acc: 0.9256 test_loss: 0.9568, test_acc: 0.7712, best: 0.7731, time: 0:01:10
 Epoch: 251, lr: 4.0e-04, train_loss: 0.2442, train_acc: 0.9176 test_loss: 0.9649, test_acc: 0.7681, best: 0.7731, time: 0:01:08
 Epoch: 252, lr: 4.0e-04, train_loss: 0.2403, train_acc: 0.9204 test_loss: 0.9573, test_acc: 0.7678, best: 0.7731, time: 0:01:10
 Epoch: 253, lr: 4.0e-04, train_loss: 0.2236, train_acc: 0.9252 test_loss: 0.9375, test_acc: 0.7726, best: 0.7731, time: 0:01:10
 Epoch: 254, lr: 4.0e-04, train_loss: 0.2324, train_acc: 0.9236 test_loss: 0.9561, test_acc: 0.7724, best: 0.7731, time: 0:01:11
 Epoch: 255, lr: 4.0e-04, train_loss: 0.2287, train_acc: 0.9264 test_loss: 0.9754, test_acc: 0.7678, best: 0.7731, time: 0:01:10
 Epoch: 256, lr: 4.0e-04, train_loss: 0.2269, train_acc: 0.9268 test_loss: 0.9672, test_acc: 0.7681, best: 0.7731, time: 0:01:10
 Epoch: 257, lr: 4.0e-04, train_loss: 0.2171, train_acc: 0.9236 test_loss: 0.9614, test_acc: 0.7676, best: 0.7731, time: 0:01:11
 Epoch: 258, lr: 4.0e-04, train_loss: 0.2291, train_acc: 0.9232 test_loss: 0.9840, test_acc: 0.7669, best: 0.7731, time: 0:01:09
 Epoch: 259, lr: 4.0e-04, train_loss: 0.2341, train_acc: 0.9214 test_loss: 0.9470, test_acc: 0.7701, best: 0.7731, time: 0:01:09
 Epoch: 260, lr: 4.0e-04, train_loss: 0.2292, train_acc: 0.9222 test_loss: 0.9567, test_acc: 0.7712, best: 0.7731, time: 0:01:09
 Epoch: 261, lr: 4.0e-04, train_loss: 0.2172, train_acc: 0.9254 test_loss: 0.9524, test_acc: 0.7720, best: 0.7731, time: 0:01:09
 Epoch: 262, lr: 4.0e-04, train_loss: 0.2227, train_acc: 0.9246 test_loss: 0.9744, test_acc: 0.7704, best: 0.7731, time: 0:01:10
 Epoch: 263, lr: 4.0e-04, train_loss: 0.2351, train_acc: 0.9208 test_loss: 0.9447, test_acc: 0.7709, best: 0.7731, time: 0:01:12
 Epoch: 264, lr: 4.0e-04, train_loss: 0.2250, train_acc: 0.9244 test_loss: 0.9624, test_acc: 0.7684, best: 0.7731, time: 0:01:10
 Epoch: 265, lr: 4.0e-04, train_loss: 0.2209, train_acc: 0.9268 test_loss: 0.9694, test_acc: 0.7699, best: 0.7731, time: 0:01:11
 Epoch: 266, lr: 4.0e-04, train_loss: 0.2429, train_acc: 0.9202 test_loss: 0.9558, test_acc: 0.7696, best: 0.7731, time: 0:01:11
 Epoch: 267, lr: 4.0e-04, train_loss: 0.2122, train_acc: 0.9274 test_loss: 0.9726, test_acc: 0.7678, best: 0.7731, time: 0:01:10
 Epoch: 268, lr: 4.0e-04, train_loss: 0.2087, train_acc: 0.9272 test_loss: 0.9515, test_acc: 0.7700, best: 0.7731, time: 0:01:12
 Epoch: 269, lr: 4.0e-04, train_loss: 0.2258, train_acc: 0.9224 test_loss: 0.9785, test_acc: 0.7711, best: 0.7731, time: 0:01:10
 Epoch: 270, lr: 8.0e-05, train_loss: 0.2134, train_acc: 0.9270 test_loss: 0.9404, test_acc: 0.7739, best: 0.7739, time: 0:01:11
 Epoch: 271, lr: 8.0e-05, train_loss: 0.2175, train_acc: 0.9258 test_loss: 0.9669, test_acc: 0.7684, best: 0.7739, time: 0:01:08
 Epoch: 272, lr: 8.0e-05, train_loss: 0.2232, train_acc: 0.9272 test_loss: 0.9610, test_acc: 0.7720, best: 0.7739, time: 0:01:11
 Epoch: 273, lr: 8.0e-05, train_loss: 0.2279, train_acc: 0.9268 test_loss: 0.9538, test_acc: 0.7705, best: 0.7739, time: 0:01:11
 Epoch: 274, lr: 8.0e-05, train_loss: 0.2315, train_acc: 0.9186 test_loss: 0.9490, test_acc: 0.7749, best: 0.7749, time: 0:01:11
 Epoch: 275, lr: 8.0e-05, train_loss: 0.2277, train_acc: 0.9252 test_loss: 0.9633, test_acc: 0.7701, best: 0.7749, time: 0:01:11
 Epoch: 276, lr: 8.0e-05, train_loss: 0.2354, train_acc: 0.9244 test_loss: 0.9616, test_acc: 0.7709, best: 0.7749, time: 0:01:11
 Epoch: 277, lr: 8.0e-05, train_loss: 0.2282, train_acc: 0.9218 test_loss: 0.9597, test_acc: 0.7721, best: 0.7749, time: 0:01:10
 Epoch: 278, lr: 8.0e-05, train_loss: 0.2124, train_acc: 0.9258 test_loss: 0.9740, test_acc: 0.7704, best: 0.7749, time: 0:01:12
 Epoch: 279, lr: 8.0e-05, train_loss: 0.2188, train_acc: 0.9236 test_loss: 0.9740, test_acc: 0.7699, best: 0.7749, time: 0:01:10
 Epoch: 280, lr: 8.0e-05, train_loss: 0.2211, train_acc: 0.9270 test_loss: 0.9757, test_acc: 0.7715, best: 0.7749, time: 0:01:10
 Epoch: 281, lr: 8.0e-05, train_loss: 0.2123, train_acc: 0.9278 test_loss: 0.9460, test_acc: 0.7702, best: 0.7749, time: 0:01:10
 Epoch: 282, lr: 8.0e-05, train_loss: 0.2123, train_acc: 0.9292 test_loss: 0.9805, test_acc: 0.7688, best: 0.7749, time: 0:01:11
 Epoch: 283, lr: 8.0e-05, train_loss: 0.2223, train_acc: 0.9256 test_loss: 0.9455, test_acc: 0.7730, best: 0.7749, time: 0:01:10
 Epoch: 284, lr: 8.0e-05, train_loss: 0.2166, train_acc: 0.9220 test_loss: 0.9586, test_acc: 0.7726, best: 0.7749, time: 0:01:11
 Epoch: 285, lr: 8.0e-05, train_loss: 0.2287, train_acc: 0.9240 test_loss: 0.9637, test_acc: 0.7725, best: 0.7749, time: 0:01:09
 Epoch: 286, lr: 8.0e-05, train_loss: 0.2239, train_acc: 0.9234 test_loss: 0.9695, test_acc: 0.7691, best: 0.7749, time: 0:01:10
 Epoch: 287, lr: 8.0e-05, train_loss: 0.2379, train_acc: 0.9208 test_loss: 1.0019, test_acc: 0.7678, best: 0.7749, time: 0:01:10
 Epoch: 288, lr: 8.0e-05, train_loss: 0.2224, train_acc: 0.9252 test_loss: 0.9740, test_acc: 0.7728, best: 0.7749, time: 0:01:11
 Epoch: 289, lr: 8.0e-05, train_loss: 0.2227, train_acc: 0.9222 test_loss: 0.9774, test_acc: 0.7701, best: 0.7749, time: 0:01:10
 Epoch: 290, lr: 8.0e-05, train_loss: 0.2150, train_acc: 0.9284 test_loss: 0.9525, test_acc: 0.7728, best: 0.7749, time: 0:01:12
 Epoch: 291, lr: 8.0e-05, train_loss: 0.2233, train_acc: 0.9212 test_loss: 0.9670, test_acc: 0.7715, best: 0.7749, time: 0:01:11
 Epoch: 292, lr: 8.0e-05, train_loss: 0.2127, train_acc: 0.9242 test_loss: 0.9546, test_acc: 0.7711, best: 0.7749, time: 0:01:09
 Epoch: 293, lr: 8.0e-05, train_loss: 0.2175, train_acc: 0.9246 test_loss: 0.9651, test_acc: 0.7718, best: 0.7749, time: 0:01:12
 Epoch: 294, lr: 8.0e-05, train_loss: 0.2145, train_acc: 0.9256 test_loss: 0.9403, test_acc: 0.7716, best: 0.7749, time: 0:01:12
 Epoch: 295, lr: 8.0e-05, train_loss: 0.2365, train_acc: 0.9184 test_loss: 0.9573, test_acc: 0.7734, best: 0.7749, time: 0:01:11
 Epoch: 296, lr: 8.0e-05, train_loss: 0.2098, train_acc: 0.9302 test_loss: 0.9495, test_acc: 0.7719, best: 0.7749, time: 0:01:12
 Epoch: 297, lr: 8.0e-05, train_loss: 0.2202, train_acc: 0.9244 test_loss: 0.9254, test_acc: 0.7755, best: 0.7755, time: 0:01:13
 Epoch: 298, lr: 8.0e-05, train_loss: 0.2192, train_acc: 0.9236 test_loss: 0.9647, test_acc: 0.7684, best: 0.7755, time: 0:01:11
 Epoch: 299, lr: 8.0e-05, train_loss: 0.2259, train_acc: 0.9198 test_loss: 0.9699, test_acc: 0.7739, best: 0.7755, time: 0:01:12
 Highest accuracy: 0.7755