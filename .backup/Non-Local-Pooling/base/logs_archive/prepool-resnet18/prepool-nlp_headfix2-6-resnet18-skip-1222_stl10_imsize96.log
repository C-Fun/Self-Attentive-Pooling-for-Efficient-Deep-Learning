
 Run on time: 2022-07-01 02:38:53.175462

 Architecture: prepool-resnet18-nlp_headfix2-6

 Pool Config: {
    "arch": "resnet18",
    "conv1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "pool": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlp",
            "_stride": 6,
            "_psize": 2,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": true
        }
    },
    "layer1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer2": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer3": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer4": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    }
}

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : PREPOOL-RESNET18-NLP_HEADFIX2-6
	 im_size              : None
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): Network(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): Pool2d(
        (logit): Sequential(
          (pool_weight): NLP_BASE(
            (downsample): Sequential(
              (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (restore): Sequential(
              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Sigmoid()
            )
            (pos_embed): PositionEmbeddingLearned(
              (row_embed): Embedding(256, 32)
              (col_embed): Embedding(256, 32)
            )
          )
        )
        (pool): AvgPool2d(kernel_size=6, stride=6, padding=0)
      )
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.4415, train_acc: 0.1702 test_loss: 2.4525, test_acc: 0.2136, best: 0.2136, time: 0:01:24
 Epoch: 2, lr: 1.0e-02, train_loss: 2.0217, train_acc: 0.2290 test_loss: 1.9167, test_acc: 0.2662, best: 0.2662, time: 0:01:22
 Epoch: 3, lr: 1.0e-02, train_loss: 1.9283, train_acc: 0.2644 test_loss: 1.6395, test_acc: 0.3673, best: 0.3673, time: 0:01:22
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8594, train_acc: 0.2852 test_loss: 1.6969, test_acc: 0.3725, best: 0.3725, time: 0:01:22
 Epoch: 5, lr: 1.0e-02, train_loss: 1.8374, train_acc: 0.3122 test_loss: 1.6339, test_acc: 0.3921, best: 0.3921, time: 0:01:22
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7988, train_acc: 0.3200 test_loss: 1.5626, test_acc: 0.4104, best: 0.4104, time: 0:01:23
 Epoch: 7, lr: 1.0e-02, train_loss: 1.7630, train_acc: 0.3394 test_loss: 1.6031, test_acc: 0.3939, best: 0.4104, time: 0:01:23
 Epoch: 8, lr: 1.0e-02, train_loss: 1.7399, train_acc: 0.3530 test_loss: 1.5070, test_acc: 0.4370, best: 0.4370, time: 0:01:23
 Epoch: 9, lr: 1.0e-02, train_loss: 1.7201, train_acc: 0.3536 test_loss: 1.4776, test_acc: 0.4496, best: 0.4496, time: 0:01:23
 Epoch: 10, lr: 1.0e-02, train_loss: 1.6610, train_acc: 0.3814 test_loss: 1.5224, test_acc: 0.4404, best: 0.4496, time: 0:01:23
 Epoch: 11, lr: 1.0e-02, train_loss: 1.6302, train_acc: 0.3940 test_loss: 1.3944, test_acc: 0.4894, best: 0.4894, time: 0:01:23
 Epoch: 12, lr: 1.0e-02, train_loss: 1.6149, train_acc: 0.4066 test_loss: 1.3921, test_acc: 0.4789, best: 0.4894, time: 0:01:23
 Epoch: 13, lr: 1.0e-02, train_loss: 1.5688, train_acc: 0.4132 test_loss: 1.3779, test_acc: 0.4899, best: 0.4899, time: 0:01:23
 Epoch: 14, lr: 1.0e-02, train_loss: 1.5357, train_acc: 0.4384 test_loss: 1.4420, test_acc: 0.4908, best: 0.4908, time: 0:01:23
 Epoch: 15, lr: 1.0e-02, train_loss: 1.5304, train_acc: 0.4438 test_loss: 1.3193, test_acc: 0.5161, best: 0.5161, time: 0:01:23
 Epoch: 16, lr: 1.0e-02, train_loss: 1.4989, train_acc: 0.4504 test_loss: 1.3921, test_acc: 0.4895, best: 0.5161, time: 0:01:23
 Epoch: 17, lr: 1.0e-02, train_loss: 1.4827, train_acc: 0.4586 test_loss: 1.3187, test_acc: 0.5260, best: 0.5260, time: 0:01:23
 Epoch: 18, lr: 1.0e-02, train_loss: 1.4460, train_acc: 0.4598 test_loss: 1.2469, test_acc: 0.5409, best: 0.5409, time: 0:01:23
 Epoch: 19, lr: 1.0e-02, train_loss: 1.4274, train_acc: 0.4788 test_loss: 1.2559, test_acc: 0.5325, best: 0.5409, time: 0:01:23
 Epoch: 20, lr: 1.0e-02, train_loss: 1.3986, train_acc: 0.4824 test_loss: 1.1956, test_acc: 0.5556, best: 0.5556, time: 0:01:23
 Epoch: 21, lr: 1.0e-02, train_loss: 1.3811, train_acc: 0.4866 test_loss: 1.2039, test_acc: 0.5541, best: 0.5556, time: 0:01:23
 Epoch: 22, lr: 1.0e-02, train_loss: 1.3593, train_acc: 0.5110 test_loss: 1.2323, test_acc: 0.5519, best: 0.5556, time: 0:01:23
 Epoch: 23, lr: 1.0e-02, train_loss: 1.3245, train_acc: 0.5114 test_loss: 1.1972, test_acc: 0.5649, best: 0.5649, time: 0:01:23
 Epoch: 24, lr: 1.0e-02, train_loss: 1.3399, train_acc: 0.5044 test_loss: 1.1704, test_acc: 0.5770, best: 0.5770, time: 0:01:23
 Epoch: 25, lr: 1.0e-02, train_loss: 1.3219, train_acc: 0.5198 test_loss: 1.2868, test_acc: 0.5591, best: 0.5770, time: 0:01:23
 Epoch: 26, lr: 1.0e-02, train_loss: 1.3031, train_acc: 0.5244 test_loss: 1.3214, test_acc: 0.5331, best: 0.5770, time: 0:01:23
 Epoch: 27, lr: 1.0e-02, train_loss: 1.2930, train_acc: 0.5302 test_loss: 1.1096, test_acc: 0.5991, best: 0.5991, time: 0:01:23
 Epoch: 28, lr: 1.0e-02, train_loss: 1.2720, train_acc: 0.5414 test_loss: 1.2653, test_acc: 0.5534, best: 0.5991, time: 0:01:23
 Epoch: 29, lr: 1.0e-02, train_loss: 1.2546, train_acc: 0.5422 test_loss: 1.2367, test_acc: 0.5736, best: 0.5991, time: 0:01:23
 Epoch: 30, lr: 1.0e-02, train_loss: 1.2506, train_acc: 0.5460 test_loss: 1.1772, test_acc: 0.5657, best: 0.5991, time: 0:01:23
 Epoch: 31, lr: 1.0e-02, train_loss: 1.2364, train_acc: 0.5484 test_loss: 1.1586, test_acc: 0.5853, best: 0.5991, time: 0:01:23
 Epoch: 32, lr: 1.0e-02, train_loss: 1.2021, train_acc: 0.5602 test_loss: 1.0259, test_acc: 0.6365, best: 0.6365, time: 0:01:23
 Epoch: 33, lr: 1.0e-02, train_loss: 1.2118, train_acc: 0.5564 test_loss: 1.1142, test_acc: 0.6098, best: 0.6365, time: 0:01:23
 Epoch: 34, lr: 1.0e-02, train_loss: 1.1775, train_acc: 0.5758 test_loss: 1.1129, test_acc: 0.6048, best: 0.6365, time: 0:01:23
 Epoch: 35, lr: 1.0e-02, train_loss: 1.1651, train_acc: 0.5860 test_loss: 1.0267, test_acc: 0.6379, best: 0.6379, time: 0:01:23
 Epoch: 36, lr: 1.0e-02, train_loss: 1.1771, train_acc: 0.5742 test_loss: 1.1323, test_acc: 0.5883, best: 0.6379, time: 0:01:23
 Epoch: 37, lr: 1.0e-02, train_loss: 1.1503, train_acc: 0.5832 test_loss: 1.0766, test_acc: 0.6176, best: 0.6379, time: 0:01:23
 Epoch: 38, lr: 1.0e-02, train_loss: 1.1516, train_acc: 0.5896 test_loss: 1.0557, test_acc: 0.6195, best: 0.6379, time: 0:01:23
 Epoch: 39, lr: 1.0e-02, train_loss: 1.1261, train_acc: 0.5858 test_loss: 1.1678, test_acc: 0.5969, best: 0.6379, time: 0:01:23
 Epoch: 40, lr: 1.0e-02, train_loss: 1.1269, train_acc: 0.5964 test_loss: 1.1317, test_acc: 0.6054, best: 0.6379, time: 0:01:23
 Epoch: 41, lr: 1.0e-02, train_loss: 1.1201, train_acc: 0.5976 test_loss: 1.0301, test_acc: 0.6406, best: 0.6406, time: 0:01:23
 Epoch: 42, lr: 1.0e-02, train_loss: 1.1047, train_acc: 0.6010 test_loss: 1.1254, test_acc: 0.6174, best: 0.6406, time: 0:01:23
 Epoch: 43, lr: 1.0e-02, train_loss: 1.1009, train_acc: 0.5976 test_loss: 1.0033, test_acc: 0.6452, best: 0.6452, time: 0:01:23
 Epoch: 44, lr: 1.0e-02, train_loss: 1.0950, train_acc: 0.6038 test_loss: 1.0482, test_acc: 0.6281, best: 0.6452, time: 0:01:23
 Epoch: 45, lr: 1.0e-02, train_loss: 1.0697, train_acc: 0.6104 test_loss: 1.0077, test_acc: 0.6418, best: 0.6452, time: 0:01:23
 Epoch: 46, lr: 1.0e-02, train_loss: 1.0824, train_acc: 0.6102 test_loss: 1.2035, test_acc: 0.6002, best: 0.6452, time: 0:01:23
 Epoch: 47, lr: 1.0e-02, train_loss: 1.0612, train_acc: 0.6134 test_loss: 1.0090, test_acc: 0.6461, best: 0.6461, time: 0:01:23
 Epoch: 48, lr: 1.0e-02, train_loss: 1.0649, train_acc: 0.6148 test_loss: 1.1351, test_acc: 0.6038, best: 0.6461, time: 0:01:23
 Epoch: 49, lr: 1.0e-02, train_loss: 1.0387, train_acc: 0.6258 test_loss: 0.9422, test_acc: 0.6693, best: 0.6693, time: 0:01:23
 Epoch: 50, lr: 1.0e-02, train_loss: 0.9966, train_acc: 0.6408 test_loss: 1.0315, test_acc: 0.6416, best: 0.6693, time: 0:01:23
 Epoch: 51, lr: 1.0e-02, train_loss: 1.0259, train_acc: 0.6274 test_loss: 0.9579, test_acc: 0.6645, best: 0.6693, time: 0:01:23
 Epoch: 52, lr: 1.0e-02, train_loss: 0.9972, train_acc: 0.6410 test_loss: 1.1873, test_acc: 0.6086, best: 0.6693, time: 0:01:23
 Epoch: 53, lr: 1.0e-02, train_loss: 1.0249, train_acc: 0.6406 test_loss: 1.0602, test_acc: 0.6372, best: 0.6693, time: 0:01:23
 Epoch: 54, lr: 1.0e-02, train_loss: 0.9995, train_acc: 0.6396 test_loss: 1.0386, test_acc: 0.6464, best: 0.6693, time: 0:01:23
 Epoch: 55, lr: 1.0e-02, train_loss: 1.0095, train_acc: 0.6382 test_loss: 0.9959, test_acc: 0.6514, best: 0.6693, time: 0:01:23
 Epoch: 56, lr: 1.0e-02, train_loss: 0.9973, train_acc: 0.6364 test_loss: 1.0076, test_acc: 0.6489, best: 0.6693, time: 0:01:23
 Epoch: 57, lr: 1.0e-02, train_loss: 0.9696, train_acc: 0.6472 test_loss: 0.9271, test_acc: 0.6759, best: 0.6759, time: 0:01:23
 Epoch: 58, lr: 1.0e-02, train_loss: 0.9654, train_acc: 0.6566 test_loss: 1.0176, test_acc: 0.6583, best: 0.6759, time: 0:01:23
 Epoch: 59, lr: 1.0e-02, train_loss: 0.9565, train_acc: 0.6602 test_loss: 0.9387, test_acc: 0.6736, best: 0.6759, time: 0:01:23
 Epoch: 60, lr: 1.0e-02, train_loss: 0.9429, train_acc: 0.6586 test_loss: 1.1117, test_acc: 0.6345, best: 0.6759, time: 0:01:23
 Epoch: 61, lr: 1.0e-02, train_loss: 0.9513, train_acc: 0.6566 test_loss: 0.9758, test_acc: 0.6681, best: 0.6759, time: 0:01:23
 Epoch: 62, lr: 1.0e-02, train_loss: 0.9447, train_acc: 0.6580 test_loss: 0.9779, test_acc: 0.6609, best: 0.6759, time: 0:01:23
 Epoch: 63, lr: 1.0e-02, train_loss: 0.9434, train_acc: 0.6708 test_loss: 1.0952, test_acc: 0.6564, best: 0.6759, time: 0:01:23
 Epoch: 64, lr: 1.0e-02, train_loss: 0.9073, train_acc: 0.6772 test_loss: 1.0146, test_acc: 0.6634, best: 0.6759, time: 0:01:23
 Epoch: 65, lr: 1.0e-02, train_loss: 0.8969, train_acc: 0.6824 test_loss: 0.9674, test_acc: 0.6761, best: 0.6761, time: 0:01:23
 Epoch: 66, lr: 1.0e-02, train_loss: 0.9076, train_acc: 0.6704 test_loss: 0.9812, test_acc: 0.6669, best: 0.6761, time: 0:01:23
 Epoch: 67, lr: 1.0e-02, train_loss: 0.8792, train_acc: 0.6878 test_loss: 0.8866, test_acc: 0.6955, best: 0.6955, time: 0:01:23
 Epoch: 68, lr: 1.0e-02, train_loss: 0.8842, train_acc: 0.6848 test_loss: 1.0254, test_acc: 0.6605, best: 0.6955, time: 0:01:23
 Epoch: 69, lr: 1.0e-02, train_loss: 0.8849, train_acc: 0.6902 test_loss: 0.9378, test_acc: 0.6846, best: 0.6955, time: 0:01:23
 Epoch: 70, lr: 1.0e-02, train_loss: 0.8832, train_acc: 0.6882 test_loss: 0.9827, test_acc: 0.6754, best: 0.6955, time: 0:01:23
 Epoch: 71, lr: 1.0e-02, train_loss: 0.8866, train_acc: 0.6852 test_loss: 0.9698, test_acc: 0.6689, best: 0.6955, time: 0:01:23
 Epoch: 72, lr: 1.0e-02, train_loss: 0.8515, train_acc: 0.6978 test_loss: 0.9590, test_acc: 0.6875, best: 0.6955, time: 0:01:23
 Epoch: 73, lr: 1.0e-02, train_loss: 0.8698, train_acc: 0.6856 test_loss: 0.9424, test_acc: 0.6861, best: 0.6955, time: 0:01:23
 Epoch: 74, lr: 1.0e-02, train_loss: 0.8723, train_acc: 0.6942 test_loss: 0.9355, test_acc: 0.6851, best: 0.6955, time: 0:01:23
 Epoch: 75, lr: 1.0e-02, train_loss: 0.8460, train_acc: 0.6984 test_loss: 1.0468, test_acc: 0.6610, best: 0.6955, time: 0:01:23
 Epoch: 76, lr: 1.0e-02, train_loss: 0.8594, train_acc: 0.7002 test_loss: 0.9863, test_acc: 0.6789, best: 0.6955, time: 0:01:23
 Epoch: 77, lr: 1.0e-02, train_loss: 0.8315, train_acc: 0.7032 test_loss: 1.0440, test_acc: 0.6700, best: 0.6955, time: 0:01:23
 Epoch: 78, lr: 1.0e-02, train_loss: 0.8399, train_acc: 0.6986 test_loss: 1.0032, test_acc: 0.6841, best: 0.6955, time: 0:01:23
 Epoch: 79, lr: 1.0e-02, train_loss: 0.8312, train_acc: 0.7060 test_loss: 0.9480, test_acc: 0.6955, best: 0.6955, time: 0:01:23
 Epoch: 80, lr: 1.0e-02, train_loss: 0.8108, train_acc: 0.7098 test_loss: 0.9333, test_acc: 0.6876, best: 0.6955, time: 0:01:23
 Epoch: 81, lr: 1.0e-02, train_loss: 0.8320, train_acc: 0.7102 test_loss: 1.0197, test_acc: 0.6701, best: 0.6955, time: 0:01:23
 Epoch: 82, lr: 1.0e-02, train_loss: 0.8044, train_acc: 0.7124 test_loss: 0.9558, test_acc: 0.6844, best: 0.6955, time: 0:01:23
 Epoch: 83, lr: 1.0e-02, train_loss: 0.8257, train_acc: 0.7036 test_loss: 1.0208, test_acc: 0.6665, best: 0.6955, time: 0:01:23
 Epoch: 84, lr: 1.0e-02, train_loss: 0.8000, train_acc: 0.7208 test_loss: 0.9653, test_acc: 0.6811, best: 0.6955, time: 0:01:23
 Epoch: 85, lr: 1.0e-02, train_loss: 0.7971, train_acc: 0.7170 test_loss: 0.9431, test_acc: 0.6956, best: 0.6956, time: 0:01:23
 Epoch: 86, lr: 1.0e-02, train_loss: 0.7917, train_acc: 0.7162 test_loss: 1.0449, test_acc: 0.6649, best: 0.6956, time: 0:01:23
 Epoch: 87, lr: 1.0e-02, train_loss: 0.7842, train_acc: 0.7246 test_loss: 1.0146, test_acc: 0.6806, best: 0.6956, time: 0:01:23
 Epoch: 88, lr: 1.0e-02, train_loss: 0.7945, train_acc: 0.7178 test_loss: 0.9382, test_acc: 0.6954, best: 0.6956, time: 0:01:23
 Epoch: 89, lr: 1.0e-02, train_loss: 0.7989, train_acc: 0.7182 test_loss: 0.9575, test_acc: 0.6961, best: 0.6961, time: 0:01:23
 Epoch: 90, lr: 1.0e-02, train_loss: 0.7526, train_acc: 0.7332 test_loss: 0.9908, test_acc: 0.6990, best: 0.6990, time: 0:01:23
 Epoch: 91, lr: 1.0e-02, train_loss: 0.7709, train_acc: 0.7228 test_loss: 0.9857, test_acc: 0.6843, best: 0.6990, time: 0:01:23
 Epoch: 92, lr: 1.0e-02, train_loss: 0.7646, train_acc: 0.7318 test_loss: 1.0516, test_acc: 0.6813, best: 0.6990, time: 0:01:23
 Epoch: 93, lr: 1.0e-02, train_loss: 0.7672, train_acc: 0.7274 test_loss: 0.9906, test_acc: 0.6845, best: 0.6990, time: 0:01:23
 Epoch: 94, lr: 1.0e-02, train_loss: 0.7481, train_acc: 0.7394 test_loss: 0.9707, test_acc: 0.6980, best: 0.6990, time: 0:01:23
 Epoch: 95, lr: 1.0e-02, train_loss: 0.7334, train_acc: 0.7432 test_loss: 0.8866, test_acc: 0.7097, best: 0.7097, time: 0:01:23
 Epoch: 96, lr: 1.0e-02, train_loss: 0.7336, train_acc: 0.7400 test_loss: 0.9637, test_acc: 0.7025, best: 0.7097, time: 0:01:23
 Epoch: 97, lr: 1.0e-02, train_loss: 0.7429, train_acc: 0.7424 test_loss: 0.9551, test_acc: 0.7039, best: 0.7097, time: 0:01:23
 Epoch: 98, lr: 1.0e-02, train_loss: 0.7330, train_acc: 0.7448 test_loss: 0.9491, test_acc: 0.6953, best: 0.7097, time: 0:01:23
 Epoch: 99, lr: 1.0e-02, train_loss: 0.7245, train_acc: 0.7412 test_loss: 0.9758, test_acc: 0.6985, best: 0.7097, time: 0:01:23
 Epoch: 100, lr: 1.0e-02, train_loss: 0.7532, train_acc: 0.7324 test_loss: 0.9333, test_acc: 0.7031, best: 0.7097, time: 0:01:23
 Epoch: 101, lr: 1.0e-02, train_loss: 0.7200, train_acc: 0.7504 test_loss: 0.9467, test_acc: 0.7051, best: 0.7097, time: 0:01:23
 Epoch: 102, lr: 1.0e-02, train_loss: 0.7235, train_acc: 0.7492 test_loss: 1.0292, test_acc: 0.6933, best: 0.7097, time: 0:01:23
 Epoch: 103, lr: 1.0e-02, train_loss: 0.7200, train_acc: 0.7498 test_loss: 0.9300, test_acc: 0.7004, best: 0.7097, time: 0:01:23
 Epoch: 104, lr: 1.0e-02, train_loss: 0.6912, train_acc: 0.7628 test_loss: 0.9813, test_acc: 0.6943, best: 0.7097, time: 0:01:23
 Epoch: 105, lr: 1.0e-02, train_loss: 0.7148, train_acc: 0.7544 test_loss: 0.9659, test_acc: 0.7024, best: 0.7097, time: 0:01:23
 Epoch: 106, lr: 1.0e-02, train_loss: 0.6999, train_acc: 0.7532 test_loss: 0.9581, test_acc: 0.6983, best: 0.7097, time: 0:01:23
 Epoch: 107, lr: 1.0e-02, train_loss: 0.6910, train_acc: 0.7540 test_loss: 0.9613, test_acc: 0.7017, best: 0.7097, time: 0:01:23
 Epoch: 108, lr: 1.0e-02, train_loss: 0.7037, train_acc: 0.7500 test_loss: 1.0094, test_acc: 0.7023, best: 0.7097, time: 0:01:23
 Epoch: 109, lr: 1.0e-02, train_loss: 0.6730, train_acc: 0.7606 test_loss: 1.0398, test_acc: 0.6987, best: 0.7097, time: 0:01:23
 Epoch: 110, lr: 1.0e-02, train_loss: 0.6650, train_acc: 0.7602 test_loss: 0.9948, test_acc: 0.7035, best: 0.7097, time: 0:01:23
 Epoch: 111, lr: 1.0e-02, train_loss: 0.6942, train_acc: 0.7622 test_loss: 0.9781, test_acc: 0.7003, best: 0.7097, time: 0:01:23
 Epoch: 112, lr: 1.0e-02, train_loss: 0.7001, train_acc: 0.7532 test_loss: 0.8827, test_acc: 0.7176, best: 0.7176, time: 0:01:23
 Epoch: 113, lr: 1.0e-02, train_loss: 0.6654, train_acc: 0.7666 test_loss: 0.9619, test_acc: 0.7064, best: 0.7176, time: 0:01:23
 Epoch: 114, lr: 1.0e-02, train_loss: 0.6612, train_acc: 0.7668 test_loss: 0.9620, test_acc: 0.7085, best: 0.7176, time: 0:01:23
 Epoch: 115, lr: 1.0e-02, train_loss: 0.6778, train_acc: 0.7552 test_loss: 0.9948, test_acc: 0.7049, best: 0.7176, time: 0:01:23
 Epoch: 116, lr: 1.0e-02, train_loss: 0.6565, train_acc: 0.7718 test_loss: 0.9815, test_acc: 0.7034, best: 0.7176, time: 0:01:23
 Epoch: 117, lr: 1.0e-02, train_loss: 0.6463, train_acc: 0.7806 test_loss: 0.9739, test_acc: 0.7033, best: 0.7176, time: 0:01:23
 Epoch: 118, lr: 1.0e-02, train_loss: 0.6430, train_acc: 0.7744 test_loss: 0.9830, test_acc: 0.7127, best: 0.7176, time: 0:01:23
 Epoch: 119, lr: 1.0e-02, train_loss: 0.6421, train_acc: 0.7778 test_loss: 0.9989, test_acc: 0.7003, best: 0.7176, time: 0:01:23
 Epoch: 120, lr: 1.0e-02, train_loss: 0.6448, train_acc: 0.7706 test_loss: 0.9657, test_acc: 0.7066, best: 0.7176, time: 0:01:23
 Epoch: 121, lr: 1.0e-02, train_loss: 0.6372, train_acc: 0.7758 test_loss: 0.9939, test_acc: 0.7034, best: 0.7176, time: 0:01:23
 Epoch: 122, lr: 1.0e-02, train_loss: 0.6519, train_acc: 0.7714 test_loss: 0.9256, test_acc: 0.7146, best: 0.7176, time: 0:01:23
 Epoch: 123, lr: 1.0e-02, train_loss: 0.6495, train_acc: 0.7748 test_loss: 0.9915, test_acc: 0.6969, best: 0.7176, time: 0:01:23
 Epoch: 124, lr: 1.0e-02, train_loss: 0.6296, train_acc: 0.7814 test_loss: 1.0454, test_acc: 0.6967, best: 0.7176, time: 0:01:23
 Epoch: 125, lr: 1.0e-02, train_loss: 0.6316, train_acc: 0.7762 test_loss: 0.9154, test_acc: 0.7235, best: 0.7235, time: 0:01:23
 Epoch: 126, lr: 1.0e-02, train_loss: 0.6290, train_acc: 0.7792 test_loss: 0.9704, test_acc: 0.7096, best: 0.7235, time: 0:01:23
 Epoch: 127, lr: 1.0e-02, train_loss: 0.6317, train_acc: 0.7794 test_loss: 0.9114, test_acc: 0.7218, best: 0.7235, time: 0:01:23
 Epoch: 128, lr: 1.0e-02, train_loss: 0.6276, train_acc: 0.7782 test_loss: 1.0464, test_acc: 0.6933, best: 0.7235, time: 0:01:23
 Epoch: 129, lr: 1.0e-02, train_loss: 0.6158, train_acc: 0.7876 test_loss: 1.0210, test_acc: 0.7021, best: 0.7235, time: 0:01:23
 Epoch: 130, lr: 1.0e-02, train_loss: 0.6039, train_acc: 0.7896 test_loss: 0.9878, test_acc: 0.7129, best: 0.7235, time: 0:01:23
 Epoch: 131, lr: 1.0e-02, train_loss: 0.6310, train_acc: 0.7840 test_loss: 0.9138, test_acc: 0.7269, best: 0.7269, time: 0:01:23
 Epoch: 132, lr: 1.0e-02, train_loss: 0.6108, train_acc: 0.7952 test_loss: 1.0855, test_acc: 0.7010, best: 0.7269, time: 0:01:23
 Epoch: 133, lr: 1.0e-02, train_loss: 0.6103, train_acc: 0.7874 test_loss: 1.0640, test_acc: 0.6967, best: 0.7269, time: 0:01:23
 Epoch: 134, lr: 1.0e-02, train_loss: 0.5953, train_acc: 0.7896 test_loss: 0.9438, test_acc: 0.7230, best: 0.7269, time: 0:01:23
 Epoch: 135, lr: 1.0e-02, train_loss: 0.5855, train_acc: 0.7954 test_loss: 0.9424, test_acc: 0.7322, best: 0.7322, time: 0:01:23
 Epoch: 136, lr: 1.0e-02, train_loss: 0.6000, train_acc: 0.7922 test_loss: 1.0083, test_acc: 0.7116, best: 0.7322, time: 0:01:23
 Epoch: 137, lr: 1.0e-02, train_loss: 0.5841, train_acc: 0.7954 test_loss: 1.0105, test_acc: 0.7113, best: 0.7322, time: 0:01:23
 Epoch: 138, lr: 1.0e-02, train_loss: 0.5945, train_acc: 0.7924 test_loss: 0.9640, test_acc: 0.7109, best: 0.7322, time: 0:01:23
 Epoch: 139, lr: 1.0e-02, train_loss: 0.6074, train_acc: 0.7908 test_loss: 0.9904, test_acc: 0.7226, best: 0.7322, time: 0:01:23
 Epoch: 140, lr: 1.0e-02, train_loss: 0.5913, train_acc: 0.7922 test_loss: 0.9904, test_acc: 0.7154, best: 0.7322, time: 0:01:23
 Epoch: 141, lr: 1.0e-02, train_loss: 0.5981, train_acc: 0.7970 test_loss: 1.0104, test_acc: 0.7204, best: 0.7322, time: 0:01:23
 Epoch: 142, lr: 1.0e-02, train_loss: 0.5858, train_acc: 0.7966 test_loss: 0.9553, test_acc: 0.7205, best: 0.7322, time: 0:01:23
 Epoch: 143, lr: 1.0e-02, train_loss: 0.5696, train_acc: 0.8070 test_loss: 0.9836, test_acc: 0.7147, best: 0.7322, time: 0:01:23
 Epoch: 144, lr: 1.0e-02, train_loss: 0.5578, train_acc: 0.8020 test_loss: 0.9449, test_acc: 0.7266, best: 0.7322, time: 0:01:23
 Epoch: 145, lr: 1.0e-02, train_loss: 0.5773, train_acc: 0.8076 test_loss: 0.9661, test_acc: 0.7288, best: 0.7322, time: 0:01:23
 Epoch: 146, lr: 1.0e-02, train_loss: 0.5698, train_acc: 0.8016 test_loss: 0.9700, test_acc: 0.7184, best: 0.7322, time: 0:01:23
 Epoch: 147, lr: 1.0e-02, train_loss: 0.5497, train_acc: 0.8142 test_loss: 1.0463, test_acc: 0.7086, best: 0.7322, time: 0:01:23
 Epoch: 148, lr: 1.0e-02, train_loss: 0.5794, train_acc: 0.7966 test_loss: 1.0636, test_acc: 0.7080, best: 0.7322, time: 0:01:23
 Epoch: 149, lr: 1.0e-02, train_loss: 0.5681, train_acc: 0.8034 test_loss: 1.0756, test_acc: 0.7064, best: 0.7322, time: 0:01:23
 Epoch: 150, lr: 1.0e-02, train_loss: 0.5595, train_acc: 0.8086 test_loss: 0.9752, test_acc: 0.7181, best: 0.7322, time: 0:01:23
 Epoch: 151, lr: 1.0e-02, train_loss: 0.5694, train_acc: 0.8024 test_loss: 0.9428, test_acc: 0.7235, best: 0.7322, time: 0:01:23
 Epoch: 152, lr: 1.0e-02, train_loss: 0.5590, train_acc: 0.8012 test_loss: 1.0816, test_acc: 0.6906, best: 0.7322, time: 0:01:23
 Epoch: 153, lr: 1.0e-02, train_loss: 0.5510, train_acc: 0.8112 test_loss: 1.0621, test_acc: 0.7015, best: 0.7322, time: 0:01:23
 Epoch: 154, lr: 1.0e-02, train_loss: 0.5471, train_acc: 0.8132 test_loss: 0.9697, test_acc: 0.7190, best: 0.7322, time: 0:01:23
 Epoch: 155, lr: 1.0e-02, train_loss: 0.5533, train_acc: 0.8064 test_loss: 0.9735, test_acc: 0.7328, best: 0.7328, time: 0:01:23
 Epoch: 156, lr: 1.0e-02, train_loss: 0.5469, train_acc: 0.8098 test_loss: 0.9381, test_acc: 0.7180, best: 0.7328, time: 0:01:23
 Epoch: 157, lr: 1.0e-02, train_loss: 0.5534, train_acc: 0.8092 test_loss: 0.9779, test_acc: 0.7204, best: 0.7328, time: 0:01:23
 Epoch: 158, lr: 1.0e-02, train_loss: 0.5373, train_acc: 0.8150 test_loss: 0.9824, test_acc: 0.7269, best: 0.7328, time: 0:01:23
 Epoch: 159, lr: 1.0e-02, train_loss: 0.5361, train_acc: 0.8148 test_loss: 0.9879, test_acc: 0.7285, best: 0.7328, time: 0:01:23
 Epoch: 160, lr: 1.0e-02, train_loss: 0.5355, train_acc: 0.8164 test_loss: 0.9925, test_acc: 0.7211, best: 0.7328, time: 0:01:23
 Epoch: 161, lr: 1.0e-02, train_loss: 0.5280, train_acc: 0.8184 test_loss: 1.0088, test_acc: 0.7167, best: 0.7328, time: 0:01:23
 Epoch: 162, lr: 1.0e-02, train_loss: 0.5300, train_acc: 0.8154 test_loss: 0.9893, test_acc: 0.7181, best: 0.7328, time: 0:01:23
 Epoch: 163, lr: 1.0e-02, train_loss: 0.5273, train_acc: 0.8164 test_loss: 1.0112, test_acc: 0.7198, best: 0.7328, time: 0:01:23
 Epoch: 164, lr: 1.0e-02, train_loss: 0.5138, train_acc: 0.8228 test_loss: 1.0897, test_acc: 0.7171, best: 0.7328, time: 0:01:23
 Epoch: 165, lr: 1.0e-02, train_loss: 0.5103, train_acc: 0.8216 test_loss: 1.0099, test_acc: 0.7284, best: 0.7328, time: 0:01:23
 Epoch: 166, lr: 1.0e-02, train_loss: 0.5216, train_acc: 0.8140 test_loss: 1.0333, test_acc: 0.7232, best: 0.7328, time: 0:01:23
 Epoch: 167, lr: 1.0e-02, train_loss: 0.5363, train_acc: 0.8134 test_loss: 0.9835, test_acc: 0.7180, best: 0.7328, time: 0:01:23
 Epoch: 168, lr: 1.0e-02, train_loss: 0.5354, train_acc: 0.8158 test_loss: 1.0489, test_acc: 0.7184, best: 0.7328, time: 0:01:23
 Epoch: 169, lr: 1.0e-02, train_loss: 0.4971, train_acc: 0.8308 test_loss: 1.0278, test_acc: 0.7232, best: 0.7328, time: 0:01:23
 Epoch: 170, lr: 1.0e-02, train_loss: 0.5245, train_acc: 0.8172 test_loss: 0.9992, test_acc: 0.7222, best: 0.7328, time: 0:01:23
 Epoch: 171, lr: 1.0e-02, train_loss: 0.5102, train_acc: 0.8200 test_loss: 1.0116, test_acc: 0.7190, best: 0.7328, time: 0:01:23
 Epoch: 172, lr: 1.0e-02, train_loss: 0.5179, train_acc: 0.8164 test_loss: 1.0212, test_acc: 0.7211, best: 0.7328, time: 0:01:23
 Epoch: 173, lr: 1.0e-02, train_loss: 0.5078, train_acc: 0.8270 test_loss: 1.0681, test_acc: 0.7188, best: 0.7328, time: 0:01:23
 Epoch: 174, lr: 1.0e-02, train_loss: 0.5006, train_acc: 0.8270 test_loss: 1.1035, test_acc: 0.7044, best: 0.7328, time: 0:01:23
 Epoch: 175, lr: 1.0e-02, train_loss: 0.4886, train_acc: 0.8320 test_loss: 1.0605, test_acc: 0.7238, best: 0.7328, time: 0:01:23
 Epoch: 176, lr: 1.0e-02, train_loss: 0.5084, train_acc: 0.8278 test_loss: 1.0341, test_acc: 0.7186, best: 0.7328, time: 0:01:23
 Epoch: 177, lr: 1.0e-02, train_loss: 0.5310, train_acc: 0.8202 test_loss: 0.9943, test_acc: 0.7258, best: 0.7328, time: 0:01:23
 Epoch: 178, lr: 1.0e-02, train_loss: 0.5041, train_acc: 0.8262 test_loss: 1.1227, test_acc: 0.7134, best: 0.7328, time: 0:01:23
 Epoch: 179, lr: 1.0e-02, train_loss: 0.5256, train_acc: 0.8150 test_loss: 1.0544, test_acc: 0.7179, best: 0.7328, time: 0:01:23
 Epoch: 180, lr: 2.0e-03, train_loss: 0.4560, train_acc: 0.8414 test_loss: 0.9764, test_acc: 0.7335, best: 0.7335, time: 0:01:23
 Epoch: 181, lr: 2.0e-03, train_loss: 0.4095, train_acc: 0.8610 test_loss: 0.9631, test_acc: 0.7380, best: 0.7380, time: 0:01:23
 Epoch: 182, lr: 2.0e-03, train_loss: 0.4198, train_acc: 0.8546 test_loss: 0.9381, test_acc: 0.7476, best: 0.7476, time: 0:01:23
 Epoch: 183, lr: 2.0e-03, train_loss: 0.4071, train_acc: 0.8566 test_loss: 0.9621, test_acc: 0.7409, best: 0.7476, time: 0:01:23
 Epoch: 184, lr: 2.0e-03, train_loss: 0.4187, train_acc: 0.8592 test_loss: 0.9418, test_acc: 0.7472, best: 0.7476, time: 0:01:23
 Epoch: 185, lr: 2.0e-03, train_loss: 0.4023, train_acc: 0.8590 test_loss: 0.9833, test_acc: 0.7408, best: 0.7476, time: 0:01:23
 Epoch: 186, lr: 2.0e-03, train_loss: 0.3982, train_acc: 0.8636 test_loss: 0.9651, test_acc: 0.7459, best: 0.7476, time: 0:01:23
 Epoch: 187, lr: 2.0e-03, train_loss: 0.3697, train_acc: 0.8740 test_loss: 0.9670, test_acc: 0.7481, best: 0.7481, time: 0:01:23
 Epoch: 188, lr: 2.0e-03, train_loss: 0.3822, train_acc: 0.8656 test_loss: 0.9576, test_acc: 0.7480, best: 0.7481, time: 0:01:23
 Epoch: 189, lr: 2.0e-03, train_loss: 0.3999, train_acc: 0.8664 test_loss: 0.9598, test_acc: 0.7424, best: 0.7481, time: 0:01:23
 Epoch: 190, lr: 2.0e-03, train_loss: 0.3576, train_acc: 0.8794 test_loss: 0.9612, test_acc: 0.7491, best: 0.7491, time: 0:01:23
 Epoch: 191, lr: 2.0e-03, train_loss: 0.3872, train_acc: 0.8698 test_loss: 1.0035, test_acc: 0.7421, best: 0.7491, time: 0:01:23
 Epoch: 192, lr: 2.0e-03, train_loss: 0.3740, train_acc: 0.8734 test_loss: 0.9909, test_acc: 0.7432, best: 0.7491, time: 0:01:23
 Epoch: 193, lr: 2.0e-03, train_loss: 0.3790, train_acc: 0.8696 test_loss: 0.9679, test_acc: 0.7454, best: 0.7491, time: 0:01:23
 Epoch: 194, lr: 2.0e-03, train_loss: 0.3845, train_acc: 0.8676 test_loss: 0.9933, test_acc: 0.7434, best: 0.7491, time: 0:01:23
 Epoch: 195, lr: 2.0e-03, train_loss: 0.3587, train_acc: 0.8790 test_loss: 0.9804, test_acc: 0.7455, best: 0.7491, time: 0:01:23
 Epoch: 196, lr: 2.0e-03, train_loss: 0.3693, train_acc: 0.8724 test_loss: 0.9973, test_acc: 0.7466, best: 0.7491, time: 0:01:23
 Epoch: 197, lr: 2.0e-03, train_loss: 0.3853, train_acc: 0.8666 test_loss: 0.9536, test_acc: 0.7512, best: 0.7512, time: 0:01:23
 Epoch: 198, lr: 2.0e-03, train_loss: 0.3643, train_acc: 0.8714 test_loss: 1.0102, test_acc: 0.7462, best: 0.7512, time: 0:01:23
 Epoch: 199, lr: 2.0e-03, train_loss: 0.3446, train_acc: 0.8778 test_loss: 1.0005, test_acc: 0.7424, best: 0.7512, time: 0:01:23
 Epoch: 200, lr: 2.0e-03, train_loss: 0.3426, train_acc: 0.8844 test_loss: 0.9811, test_acc: 0.7449, best: 0.7512, time: 0:01:23
 Epoch: 201, lr: 2.0e-03, train_loss: 0.3738, train_acc: 0.8788 test_loss: 1.0015, test_acc: 0.7415, best: 0.7512, time: 0:01:23
 Epoch: 202, lr: 2.0e-03, train_loss: 0.3631, train_acc: 0.8698 test_loss: 0.9959, test_acc: 0.7440, best: 0.7512, time: 0:01:23
 Epoch: 203, lr: 2.0e-03, train_loss: 0.3492, train_acc: 0.8822 test_loss: 0.9617, test_acc: 0.7466, best: 0.7512, time: 0:01:23
 Epoch: 204, lr: 2.0e-03, train_loss: 0.3619, train_acc: 0.8786 test_loss: 0.9704, test_acc: 0.7449, best: 0.7512, time: 0:01:23
 Epoch: 205, lr: 2.0e-03, train_loss: 0.3604, train_acc: 0.8804 test_loss: 1.0029, test_acc: 0.7446, best: 0.7512, time: 0:01:23
 Epoch: 206, lr: 2.0e-03, train_loss: 0.3391, train_acc: 0.8820 test_loss: 1.0156, test_acc: 0.7438, best: 0.7512, time: 0:01:23
 Epoch: 207, lr: 2.0e-03, train_loss: 0.3453, train_acc: 0.8830 test_loss: 0.9644, test_acc: 0.7508, best: 0.7512, time: 0:01:23
 Epoch: 208, lr: 2.0e-03, train_loss: 0.3578, train_acc: 0.8750 test_loss: 0.9890, test_acc: 0.7516, best: 0.7516, time: 0:01:23
 Epoch: 209, lr: 2.0e-03, train_loss: 0.3542, train_acc: 0.8806 test_loss: 0.9707, test_acc: 0.7499, best: 0.7516, time: 0:01:23
 Epoch: 210, lr: 2.0e-03, train_loss: 0.3395, train_acc: 0.8814 test_loss: 0.9725, test_acc: 0.7481, best: 0.7516, time: 0:01:23
 Epoch: 211, lr: 2.0e-03, train_loss: 0.3493, train_acc: 0.8820 test_loss: 0.9949, test_acc: 0.7476, best: 0.7516, time: 0:01:23
 Epoch: 212, lr: 2.0e-03, train_loss: 0.3485, train_acc: 0.8800 test_loss: 1.0269, test_acc: 0.7409, best: 0.7516, time: 0:01:23
 Epoch: 213, lr: 2.0e-03, train_loss: 0.3439, train_acc: 0.8826 test_loss: 0.9895, test_acc: 0.7490, best: 0.7516, time: 0:01:23
 Epoch: 214, lr: 2.0e-03, train_loss: 0.3445, train_acc: 0.8842 test_loss: 1.0034, test_acc: 0.7428, best: 0.7516, time: 0:01:23
 Epoch: 215, lr: 2.0e-03, train_loss: 0.3632, train_acc: 0.8772 test_loss: 1.0038, test_acc: 0.7478, best: 0.7516, time: 0:01:23
 Epoch: 216, lr: 2.0e-03, train_loss: 0.3480, train_acc: 0.8820 test_loss: 1.0007, test_acc: 0.7449, best: 0.7516, time: 0:01:23
 Epoch: 217, lr: 2.0e-03, train_loss: 0.3443, train_acc: 0.8864 test_loss: 1.0263, test_acc: 0.7394, best: 0.7516, time: 0:01:23
 Epoch: 218, lr: 2.0e-03, train_loss: 0.3407, train_acc: 0.8864 test_loss: 1.0152, test_acc: 0.7464, best: 0.7516, time: 0:01:23
 Epoch: 219, lr: 2.0e-03, train_loss: 0.3470, train_acc: 0.8812 test_loss: 1.0131, test_acc: 0.7458, best: 0.7516, time: 0:01:23
 Epoch: 220, lr: 2.0e-03, train_loss: 0.3553, train_acc: 0.8792 test_loss: 1.0032, test_acc: 0.7468, best: 0.7516, time: 0:01:23
 Epoch: 221, lr: 2.0e-03, train_loss: 0.3308, train_acc: 0.8860 test_loss: 1.0233, test_acc: 0.7430, best: 0.7516, time: 0:01:23
 Epoch: 222, lr: 2.0e-03, train_loss: 0.3406, train_acc: 0.8864 test_loss: 1.0040, test_acc: 0.7461, best: 0.7516, time: 0:01:23
 Epoch: 223, lr: 2.0e-03, train_loss: 0.3358, train_acc: 0.8826 test_loss: 1.0079, test_acc: 0.7465, best: 0.7516, time: 0:01:23
 Epoch: 224, lr: 2.0e-03, train_loss: 0.3511, train_acc: 0.8818 test_loss: 1.0111, test_acc: 0.7500, best: 0.7516, time: 0:01:23
 Epoch: 225, lr: 2.0e-03, train_loss: 0.3299, train_acc: 0.8858 test_loss: 1.0316, test_acc: 0.7424, best: 0.7516, time: 0:01:23
 Epoch: 226, lr: 2.0e-03, train_loss: 0.3328, train_acc: 0.8880 test_loss: 1.0042, test_acc: 0.7478, best: 0.7516, time: 0:01:23
 Epoch: 227, lr: 2.0e-03, train_loss: 0.3387, train_acc: 0.8842 test_loss: 1.0110, test_acc: 0.7475, best: 0.7516, time: 0:01:23
 Epoch: 228, lr: 2.0e-03, train_loss: 0.3344, train_acc: 0.8866 test_loss: 1.0523, test_acc: 0.7429, best: 0.7516, time: 0:01:23
 Epoch: 229, lr: 2.0e-03, train_loss: 0.3224, train_acc: 0.8898 test_loss: 1.0637, test_acc: 0.7474, best: 0.7516, time: 0:01:23
 Epoch: 230, lr: 2.0e-03, train_loss: 0.3339, train_acc: 0.8906 test_loss: 0.9940, test_acc: 0.7505, best: 0.7516, time: 0:01:23
 Epoch: 231, lr: 2.0e-03, train_loss: 0.3293, train_acc: 0.8904 test_loss: 1.0064, test_acc: 0.7458, best: 0.7516, time: 0:01:23
 Epoch: 232, lr: 2.0e-03, train_loss: 0.3349, train_acc: 0.8852 test_loss: 0.9991, test_acc: 0.7426, best: 0.7516, time: 0:01:23
 Epoch: 233, lr: 2.0e-03, train_loss: 0.3374, train_acc: 0.8866 test_loss: 1.0515, test_acc: 0.7429, best: 0.7516, time: 0:01:23
 Epoch: 234, lr: 2.0e-03, train_loss: 0.3113, train_acc: 0.8944 test_loss: 1.0559, test_acc: 0.7382, best: 0.7516, time: 0:01:23
 Epoch: 235, lr: 2.0e-03, train_loss: 0.3523, train_acc: 0.8784 test_loss: 1.0517, test_acc: 0.7389, best: 0.7516, time: 0:01:23
 Epoch: 236, lr: 2.0e-03, train_loss: 0.3296, train_acc: 0.8896 test_loss: 0.9990, test_acc: 0.7435, best: 0.7516, time: 0:01:23
 Epoch: 237, lr: 2.0e-03, train_loss: 0.3406, train_acc: 0.8816 test_loss: 1.0159, test_acc: 0.7395, best: 0.7516, time: 0:01:23
 Epoch: 238, lr: 2.0e-03, train_loss: 0.3159, train_acc: 0.8894 test_loss: 1.0035, test_acc: 0.7478, best: 0.7516, time: 0:01:23
 Epoch: 239, lr: 2.0e-03, train_loss: 0.3214, train_acc: 0.8906 test_loss: 1.0119, test_acc: 0.7424, best: 0.7516, time: 0:01:23
 Epoch: 240, lr: 4.0e-04, train_loss: 0.3145, train_acc: 0.8914 test_loss: 1.0544, test_acc: 0.7410, best: 0.7516, time: 0:01:23
 Epoch: 241, lr: 4.0e-04, train_loss: 0.3158, train_acc: 0.8944 test_loss: 1.0299, test_acc: 0.7431, best: 0.7516, time: 0:01:23
 Epoch: 242, lr: 4.0e-04, train_loss: 0.3211, train_acc: 0.8898 test_loss: 1.0507, test_acc: 0.7398, best: 0.7516, time: 0:01:23
 Epoch: 243, lr: 4.0e-04, train_loss: 0.3196, train_acc: 0.8912 test_loss: 1.0203, test_acc: 0.7468, best: 0.7516, time: 0:01:23
 Epoch: 244, lr: 4.0e-04, train_loss: 0.3124, train_acc: 0.8952 test_loss: 1.0347, test_acc: 0.7478, best: 0.7516, time: 0:01:23
 Epoch: 245, lr: 4.0e-04, train_loss: 0.2940, train_acc: 0.8988 test_loss: 1.0460, test_acc: 0.7464, best: 0.7516, time: 0:01:22
 Epoch: 246, lr: 4.0e-04, train_loss: 0.3092, train_acc: 0.8922 test_loss: 1.0475, test_acc: 0.7461, best: 0.7516, time: 0:01:22
 Epoch: 247, lr: 4.0e-04, train_loss: 0.2950, train_acc: 0.8986 test_loss: 1.0283, test_acc: 0.7455, best: 0.7516, time: 0:01:22
 Epoch: 248, lr: 4.0e-04, train_loss: 0.3098, train_acc: 0.8938 test_loss: 1.0122, test_acc: 0.7491, best: 0.7516, time: 0:01:22
 Epoch: 249, lr: 4.0e-04, train_loss: 0.3072, train_acc: 0.8892 test_loss: 1.0178, test_acc: 0.7485, best: 0.7516, time: 0:01:22
 Epoch: 250, lr: 4.0e-04, train_loss: 0.3035, train_acc: 0.8980 test_loss: 1.0128, test_acc: 0.7476, best: 0.7516, time: 0:01:22
 Epoch: 251, lr: 4.0e-04, train_loss: 0.3160, train_acc: 0.8946 test_loss: 1.0430, test_acc: 0.7481, best: 0.7516, time: 0:01:22
 Epoch: 252, lr: 4.0e-04, train_loss: 0.3111, train_acc: 0.8976 test_loss: 1.0246, test_acc: 0.7450, best: 0.7516, time: 0:01:22
 Epoch: 253, lr: 4.0e-04, train_loss: 0.3260, train_acc: 0.8896 test_loss: 1.0207, test_acc: 0.7490, best: 0.7516, time: 0:01:22
 Epoch: 254, lr: 4.0e-04, train_loss: 0.3124, train_acc: 0.8938 test_loss: 1.0268, test_acc: 0.7466, best: 0.7516, time: 0:01:22
 Epoch: 255, lr: 4.0e-04, train_loss: 0.3099, train_acc: 0.8952 test_loss: 1.0387, test_acc: 0.7444, best: 0.7516, time: 0:01:22
 Epoch: 256, lr: 4.0e-04, train_loss: 0.3033, train_acc: 0.8962 test_loss: 1.0272, test_acc: 0.7439, best: 0.7516, time: 0:01:22
 Epoch: 257, lr: 4.0e-04, train_loss: 0.2902, train_acc: 0.9000 test_loss: 1.0051, test_acc: 0.7500, best: 0.7516, time: 0:01:22
 Epoch: 258, lr: 4.0e-04, train_loss: 0.3013, train_acc: 0.8994 test_loss: 1.0505, test_acc: 0.7480, best: 0.7516, time: 0:01:22
 Epoch: 259, lr: 4.0e-04, train_loss: 0.3133, train_acc: 0.8890 test_loss: 1.0188, test_acc: 0.7496, best: 0.7516, time: 0:01:22
 Epoch: 260, lr: 4.0e-04, train_loss: 0.3121, train_acc: 0.8888 test_loss: 1.0427, test_acc: 0.7450, best: 0.7516, time: 0:01:22
 Epoch: 261, lr: 4.0e-04, train_loss: 0.2995, train_acc: 0.8984 test_loss: 1.0284, test_acc: 0.7518, best: 0.7518, time: 0:01:22
 Epoch: 262, lr: 4.0e-04, train_loss: 0.2886, train_acc: 0.9018 test_loss: 1.0475, test_acc: 0.7480, best: 0.7518, time: 0:01:22
 Epoch: 263, lr: 4.0e-04, train_loss: 0.3141, train_acc: 0.8978 test_loss: 1.0106, test_acc: 0.7504, best: 0.7518, time: 0:01:22
 Epoch: 264, lr: 4.0e-04, train_loss: 0.3099, train_acc: 0.8980 test_loss: 1.0310, test_acc: 0.7466, best: 0.7518, time: 0:01:22
 Epoch: 265, lr: 4.0e-04, train_loss: 0.2996, train_acc: 0.8966 test_loss: 1.0520, test_acc: 0.7438, best: 0.7518, time: 0:01:22
 Epoch: 266, lr: 4.0e-04, train_loss: 0.3135, train_acc: 0.8944 test_loss: 1.0158, test_acc: 0.7499, best: 0.7518, time: 0:01:22
 Epoch: 267, lr: 4.0e-04, train_loss: 0.2936, train_acc: 0.8982 test_loss: 1.0340, test_acc: 0.7458, best: 0.7518, time: 0:01:22
 Epoch: 268, lr: 4.0e-04, train_loss: 0.2896, train_acc: 0.9008 test_loss: 1.0295, test_acc: 0.7475, best: 0.7518, time: 0:01:22
 Epoch: 269, lr: 4.0e-04, train_loss: 0.3116, train_acc: 0.8964 test_loss: 1.0305, test_acc: 0.7470, best: 0.7518, time: 0:01:22
 Epoch: 270, lr: 8.0e-05, train_loss: 0.2997, train_acc: 0.8972 test_loss: 1.0246, test_acc: 0.7474, best: 0.7518, time: 0:01:22
 Epoch: 271, lr: 8.0e-05, train_loss: 0.3041, train_acc: 0.9026 test_loss: 1.0161, test_acc: 0.7494, best: 0.7518, time: 0:01:22
 Epoch: 272, lr: 8.0e-05, train_loss: 0.3132, train_acc: 0.8956 test_loss: 1.0102, test_acc: 0.7502, best: 0.7518, time: 0:01:22
 Epoch: 273, lr: 8.0e-05, train_loss: 0.3146, train_acc: 0.8966 test_loss: 1.0266, test_acc: 0.7484, best: 0.7518, time: 0:01:22
 Epoch: 274, lr: 8.0e-05, train_loss: 0.3093, train_acc: 0.8940 test_loss: 1.0360, test_acc: 0.7506, best: 0.7518, time: 0:01:22
 Epoch: 275, lr: 8.0e-05, train_loss: 0.2876, train_acc: 0.9048 test_loss: 1.0115, test_acc: 0.7491, best: 0.7518, time: 0:01:22
 Epoch: 276, lr: 8.0e-05, train_loss: 0.3000, train_acc: 0.8978 test_loss: 1.0114, test_acc: 0.7492, best: 0.7518, time: 0:01:22
 Epoch: 277, lr: 8.0e-05, train_loss: 0.3076, train_acc: 0.8944 test_loss: 1.0391, test_acc: 0.7498, best: 0.7518, time: 0:01:22
 Epoch: 278, lr: 8.0e-05, train_loss: 0.2982, train_acc: 0.9000 test_loss: 1.0303, test_acc: 0.7475, best: 0.7518, time: 0:01:22
 Epoch: 279, lr: 8.0e-05, train_loss: 0.3029, train_acc: 0.8972 test_loss: 1.0303, test_acc: 0.7491, best: 0.7518, time: 0:01:22
 Epoch: 280, lr: 8.0e-05, train_loss: 0.2861, train_acc: 0.9010 test_loss: 1.0399, test_acc: 0.7471, best: 0.7518, time: 0:01:22
 Epoch: 281, lr: 8.0e-05, train_loss: 0.2972, train_acc: 0.9008 test_loss: 1.0206, test_acc: 0.7462, best: 0.7518, time: 0:01:22
 Epoch: 282, lr: 8.0e-05, train_loss: 0.2843, train_acc: 0.9008 test_loss: 1.0437, test_acc: 0.7465, best: 0.7518, time: 0:01:22
 Epoch: 283, lr: 8.0e-05, train_loss: 0.2920, train_acc: 0.8976 test_loss: 1.0196, test_acc: 0.7485, best: 0.7518, time: 0:01:22
 Epoch: 284, lr: 8.0e-05, train_loss: 0.2945, train_acc: 0.9006 test_loss: 1.0051, test_acc: 0.7496, best: 0.7518, time: 0:01:22
 Epoch: 285, lr: 8.0e-05, train_loss: 0.3127, train_acc: 0.8908 test_loss: 1.0090, test_acc: 0.7486, best: 0.7518, time: 0:01:22
 Epoch: 286, lr: 8.0e-05, train_loss: 0.2969, train_acc: 0.8982 test_loss: 1.0327, test_acc: 0.7461, best: 0.7518, time: 0:01:22
 Epoch: 287, lr: 8.0e-05, train_loss: 0.2985, train_acc: 0.9002 test_loss: 1.0490, test_acc: 0.7458, best: 0.7518, time: 0:01:22
 Epoch: 288, lr: 8.0e-05, train_loss: 0.2920, train_acc: 0.9006 test_loss: 1.0175, test_acc: 0.7492, best: 0.7518, time: 0:01:22
 Epoch: 289, lr: 8.0e-05, train_loss: 0.3136, train_acc: 0.8894 test_loss: 1.0294, test_acc: 0.7519, best: 0.7519, time: 0:01:22
 Epoch: 290, lr: 8.0e-05, train_loss: 0.2921, train_acc: 0.9016 test_loss: 1.0124, test_acc: 0.7511, best: 0.7519, time: 0:01:22
 Epoch: 291, lr: 8.0e-05, train_loss: 0.2805, train_acc: 0.9058 test_loss: 1.0512, test_acc: 0.7484, best: 0.7519, time: 0:01:22
 Epoch: 292, lr: 8.0e-05, train_loss: 0.3008, train_acc: 0.8944 test_loss: 1.0210, test_acc: 0.7501, best: 0.7519, time: 0:01:22
 Epoch: 293, lr: 8.0e-05, train_loss: 0.3109, train_acc: 0.8932 test_loss: 1.0178, test_acc: 0.7485, best: 0.7519, time: 0:01:22
 Epoch: 294, lr: 8.0e-05, train_loss: 0.2954, train_acc: 0.8972 test_loss: 0.9936, test_acc: 0.7498, best: 0.7519, time: 0:01:22
 Epoch: 295, lr: 8.0e-05, train_loss: 0.3169, train_acc: 0.8932 test_loss: 1.0093, test_acc: 0.7485, best: 0.7519, time: 0:01:22
 Epoch: 296, lr: 8.0e-05, train_loss: 0.2957, train_acc: 0.9002 test_loss: 1.0041, test_acc: 0.7536, best: 0.7536, time: 0:01:22
 Epoch: 297, lr: 8.0e-05, train_loss: 0.3067, train_acc: 0.8998 test_loss: 1.0017, test_acc: 0.7512, best: 0.7536, time: 0:01:22
 Epoch: 298, lr: 8.0e-05, train_loss: 0.2936, train_acc: 0.8944 test_loss: 1.0123, test_acc: 0.7484, best: 0.7536, time: 0:01:22
 Epoch: 299, lr: 8.0e-05, train_loss: 0.3015, train_acc: 0.8982 test_loss: 1.0346, test_acc: 0.7488, best: 0.7536, time: 0:01:22
 Highest accuracy: 0.7536