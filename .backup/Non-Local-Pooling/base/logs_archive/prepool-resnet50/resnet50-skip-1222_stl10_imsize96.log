
 Run on time: 2022-07-01 13:47:22.606578

 Architecture: resnet50-skip-1222

 Pool Config: {
    "arch": "resnet50",
    "conv1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "pool": {
        "_conv2d": null,
        "pool_cfg": {
            "_ptype": "maxp",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 1,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer2": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer3": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer4": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    }
}

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : RESNET50-SKIP-1222
	 im_size              : None
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): Network(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=2048, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 3.4071, train_acc: 0.1512 test_loss: 2.4778, test_acc: 0.1804, best: 0.1804, time: 0:00:52
 Epoch: 2, lr: 1.0e-02, train_loss: 2.1977, train_acc: 0.1966 test_loss: 2.3350, test_acc: 0.2386, best: 0.2386, time: 0:00:52
 Epoch: 3, lr: 1.0e-02, train_loss: 2.0375, train_acc: 0.2366 test_loss: 3.7645, test_acc: 0.2954, best: 0.2954, time: 0:00:52
 Epoch: 4, lr: 1.0e-02, train_loss: 1.9491, train_acc: 0.2588 test_loss: 2.2928, test_acc: 0.3312, best: 0.3312, time: 0:00:52
 Epoch: 5, lr: 1.0e-02, train_loss: 1.9499, train_acc: 0.2644 test_loss: 2.1585, test_acc: 0.2994, best: 0.3312, time: 0:00:52
 Epoch: 6, lr: 1.0e-02, train_loss: 1.9216, train_acc: 0.2822 test_loss: 1.7126, test_acc: 0.3465, best: 0.3465, time: 0:00:52
 Epoch: 7, lr: 1.0e-02, train_loss: 1.8693, train_acc: 0.2890 test_loss: 1.7421, test_acc: 0.3406, best: 0.3465, time: 0:00:52
 Epoch: 8, lr: 1.0e-02, train_loss: 1.8236, train_acc: 0.3136 test_loss: 2.9822, test_acc: 0.3290, best: 0.3465, time: 0:00:52
 Epoch: 9, lr: 1.0e-02, train_loss: 1.8385, train_acc: 0.2986 test_loss: 2.0741, test_acc: 0.3609, best: 0.3609, time: 0:00:52
 Epoch: 10, lr: 1.0e-02, train_loss: 1.7724, train_acc: 0.3370 test_loss: 2.2989, test_acc: 0.3781, best: 0.3781, time: 0:00:52
 Epoch: 11, lr: 1.0e-02, train_loss: 1.7351, train_acc: 0.3378 test_loss: 4.7036, test_acc: 0.3719, best: 0.3781, time: 0:00:52
 Epoch: 12, lr: 1.0e-02, train_loss: 1.7063, train_acc: 0.3532 test_loss: 2.0669, test_acc: 0.3854, best: 0.3854, time: 0:00:52
 Epoch: 13, lr: 1.0e-02, train_loss: 1.6815, train_acc: 0.3652 test_loss: 1.7384, test_acc: 0.3931, best: 0.3931, time: 0:00:52
 Epoch: 14, lr: 1.0e-02, train_loss: 1.6600, train_acc: 0.3812 test_loss: 2.1136, test_acc: 0.4191, best: 0.4191, time: 0:00:52
 Epoch: 15, lr: 1.0e-02, train_loss: 1.6553, train_acc: 0.3866 test_loss: 2.4606, test_acc: 0.4492, best: 0.4492, time: 0:00:52
 Epoch: 16, lr: 1.0e-02, train_loss: 1.6247, train_acc: 0.3938 test_loss: 1.6096, test_acc: 0.4476, best: 0.4492, time: 0:00:52
 Epoch: 17, lr: 1.0e-02, train_loss: 1.6038, train_acc: 0.4008 test_loss: 2.2356, test_acc: 0.4330, best: 0.4492, time: 0:00:52
 Epoch: 18, lr: 1.0e-02, train_loss: 1.5779, train_acc: 0.4118 test_loss: 1.4133, test_acc: 0.4830, best: 0.4830, time: 0:00:52
 Epoch: 19, lr: 1.0e-02, train_loss: 1.5756, train_acc: 0.4110 test_loss: 1.4698, test_acc: 0.4828, best: 0.4830, time: 0:00:52
 Epoch: 20, lr: 1.0e-02, train_loss: 1.5303, train_acc: 0.4372 test_loss: 4.7620, test_acc: 0.4597, best: 0.4830, time: 0:00:52
 Epoch: 21, lr: 1.0e-02, train_loss: 1.5607, train_acc: 0.4270 test_loss: 2.7050, test_acc: 0.4616, best: 0.4830, time: 0:00:52
 Epoch: 22, lr: 1.0e-02, train_loss: 1.5034, train_acc: 0.4352 test_loss: 1.7336, test_acc: 0.4592, best: 0.4830, time: 0:00:52
 Epoch: 23, lr: 1.0e-02, train_loss: 1.4861, train_acc: 0.4494 test_loss: 1.6463, test_acc: 0.4589, best: 0.4830, time: 0:00:52
 Epoch: 24, lr: 1.0e-02, train_loss: 1.5057, train_acc: 0.4480 test_loss: 1.8094, test_acc: 0.4555, best: 0.4830, time: 0:00:52
 Epoch: 25, lr: 1.0e-02, train_loss: 1.5067, train_acc: 0.4432 test_loss: 1.5721, test_acc: 0.5076, best: 0.5076, time: 0:00:52
 Epoch: 26, lr: 1.0e-02, train_loss: 1.4621, train_acc: 0.4616 test_loss: 1.3716, test_acc: 0.5039, best: 0.5076, time: 0:00:52
 Epoch: 27, lr: 1.0e-02, train_loss: 1.4844, train_acc: 0.4508 test_loss: 1.3978, test_acc: 0.4816, best: 0.5076, time: 0:00:52
 Epoch: 28, lr: 1.0e-02, train_loss: 1.4711, train_acc: 0.4574 test_loss: 1.3720, test_acc: 0.5119, best: 0.5119, time: 0:00:52
 Epoch: 29, lr: 1.0e-02, train_loss: 1.4497, train_acc: 0.4662 test_loss: 1.7064, test_acc: 0.5028, best: 0.5119, time: 0:00:52
 Epoch: 30, lr: 1.0e-02, train_loss: 1.4372, train_acc: 0.4692 test_loss: 1.3841, test_acc: 0.5184, best: 0.5184, time: 0:00:52
 Epoch: 31, lr: 1.0e-02, train_loss: 1.4008, train_acc: 0.4856 test_loss: 1.7475, test_acc: 0.5155, best: 0.5184, time: 0:00:52
 Epoch: 32, lr: 1.0e-02, train_loss: 1.3656, train_acc: 0.4986 test_loss: 1.8811, test_acc: 0.5258, best: 0.5258, time: 0:00:52
 Epoch: 33, lr: 1.0e-02, train_loss: 1.3740, train_acc: 0.4944 test_loss: 4.1314, test_acc: 0.4973, best: 0.5258, time: 0:00:52
 Epoch: 34, lr: 1.0e-02, train_loss: 1.4044, train_acc: 0.4940 test_loss: 1.3117, test_acc: 0.5521, best: 0.5521, time: 0:00:52
 Epoch: 35, lr: 1.0e-02, train_loss: 1.3787, train_acc: 0.4936 test_loss: 1.3363, test_acc: 0.5561, best: 0.5561, time: 0:00:52
 Epoch: 36, lr: 1.0e-02, train_loss: 1.3569, train_acc: 0.5040 test_loss: 1.3496, test_acc: 0.5317, best: 0.5561, time: 0:00:52
 Epoch: 37, lr: 1.0e-02, train_loss: 1.3343, train_acc: 0.5078 test_loss: 1.5105, test_acc: 0.4994, best: 0.5561, time: 0:00:52
 Epoch: 38, lr: 1.0e-02, train_loss: 1.4463, train_acc: 0.4680 test_loss: 1.3889, test_acc: 0.5400, best: 0.5561, time: 0:00:52
 Epoch: 39, lr: 1.0e-02, train_loss: 1.3592, train_acc: 0.5026 test_loss: 1.3643, test_acc: 0.5351, best: 0.5561, time: 0:00:52
 Epoch: 40, lr: 1.0e-02, train_loss: 1.3158, train_acc: 0.5154 test_loss: 1.6687, test_acc: 0.5326, best: 0.5561, time: 0:00:52
 Epoch: 41, lr: 1.0e-02, train_loss: 1.3190, train_acc: 0.5132 test_loss: 2.7915, test_acc: 0.5179, best: 0.5561, time: 0:00:52
 Epoch: 42, lr: 1.0e-02, train_loss: 1.2897, train_acc: 0.5286 test_loss: 3.2306, test_acc: 0.5241, best: 0.5561, time: 0:00:52
 Epoch: 43, lr: 1.0e-02, train_loss: 1.2374, train_acc: 0.5538 test_loss: 1.5762, test_acc: 0.5695, best: 0.5695, time: 0:00:52
 Epoch: 44, lr: 1.0e-02, train_loss: 1.2442, train_acc: 0.5362 test_loss: 2.4708, test_acc: 0.5760, best: 0.5760, time: 0:00:52
 Epoch: 45, lr: 1.0e-02, train_loss: 1.2079, train_acc: 0.5550 test_loss: 1.8038, test_acc: 0.5781, best: 0.5781, time: 0:00:52
 Epoch: 46, lr: 1.0e-02, train_loss: 1.2024, train_acc: 0.5604 test_loss: 1.6181, test_acc: 0.5571, best: 0.5781, time: 0:00:52
 Epoch: 47, lr: 1.0e-02, train_loss: 1.1951, train_acc: 0.5658 test_loss: 1.3235, test_acc: 0.5829, best: 0.5829, time: 0:00:52
 Epoch: 48, lr: 1.0e-02, train_loss: 1.1886, train_acc: 0.5670 test_loss: 1.4568, test_acc: 0.5820, best: 0.5829, time: 0:00:52
 Epoch: 49, lr: 1.0e-02, train_loss: 1.1774, train_acc: 0.5764 test_loss: 1.5357, test_acc: 0.5911, best: 0.5911, time: 0:00:52
 Epoch: 50, lr: 1.0e-02, train_loss: 1.1648, train_acc: 0.5762 test_loss: 2.1693, test_acc: 0.5843, best: 0.5911, time: 0:00:52
 Epoch: 51, lr: 1.0e-02, train_loss: 1.1789, train_acc: 0.5666 test_loss: 4.5187, test_acc: 0.5340, best: 0.5911, time: 0:00:52
 Epoch: 52, lr: 1.0e-02, train_loss: 1.1881, train_acc: 0.5708 test_loss: 1.6027, test_acc: 0.5615, best: 0.5911, time: 0:00:52
 Epoch: 53, lr: 1.0e-02, train_loss: 1.1643, train_acc: 0.5802 test_loss: 2.9248, test_acc: 0.5376, best: 0.5911, time: 0:00:52
 Epoch: 54, lr: 1.0e-02, train_loss: 1.1588, train_acc: 0.5798 test_loss: 1.1200, test_acc: 0.6081, best: 0.6081, time: 0:00:52
 Epoch: 55, lr: 1.0e-02, train_loss: 1.1471, train_acc: 0.5782 test_loss: 2.3012, test_acc: 0.5104, best: 0.6081, time: 0:00:52
 Epoch: 56, lr: 1.0e-02, train_loss: 1.1181, train_acc: 0.5898 test_loss: 2.9507, test_acc: 0.4800, best: 0.6081, time: 0:00:52
 Epoch: 57, lr: 1.0e-02, train_loss: 1.1000, train_acc: 0.6018 test_loss: 1.8261, test_acc: 0.5811, best: 0.6081, time: 0:00:52
 Epoch: 58, lr: 1.0e-02, train_loss: 1.1044, train_acc: 0.5996 test_loss: 1.7543, test_acc: 0.5756, best: 0.6081, time: 0:00:52
 Epoch: 59, lr: 1.0e-02, train_loss: 1.0612, train_acc: 0.6138 test_loss: 1.4327, test_acc: 0.5777, best: 0.6081, time: 0:00:52
 Epoch: 60, lr: 1.0e-02, train_loss: 1.1244, train_acc: 0.5954 test_loss: 4.9626, test_acc: 0.5331, best: 0.6081, time: 0:00:51
 Epoch: 61, lr: 1.0e-02, train_loss: 1.0845, train_acc: 0.6032 test_loss: 1.9878, test_acc: 0.5804, best: 0.6081, time: 0:00:51
 Epoch: 62, lr: 1.0e-02, train_loss: 1.0953, train_acc: 0.6014 test_loss: 1.1035, test_acc: 0.6160, best: 0.6160, time: 0:00:52
 Epoch: 63, lr: 1.0e-02, train_loss: 1.0754, train_acc: 0.6076 test_loss: 1.0857, test_acc: 0.6380, best: 0.6380, time: 0:00:52
 Epoch: 64, lr: 1.0e-02, train_loss: 1.1027, train_acc: 0.5980 test_loss: 1.2087, test_acc: 0.5831, best: 0.6380, time: 0:00:51
 Epoch: 65, lr: 1.0e-02, train_loss: 1.1124, train_acc: 0.5936 test_loss: 2.5424, test_acc: 0.5379, best: 0.6380, time: 0:00:51
 Epoch: 66, lr: 1.0e-02, train_loss: 1.0776, train_acc: 0.6130 test_loss: 1.6536, test_acc: 0.5746, best: 0.6380, time: 0:00:51
 Epoch: 67, lr: 1.0e-02, train_loss: 1.0392, train_acc: 0.6272 test_loss: 1.8344, test_acc: 0.5339, best: 0.6380, time: 0:00:51
 Epoch: 68, lr: 1.0e-02, train_loss: 1.0536, train_acc: 0.6234 test_loss: 2.2687, test_acc: 0.5489, best: 0.6380, time: 0:00:51
 Epoch: 69, lr: 1.0e-02, train_loss: 1.0527, train_acc: 0.6224 test_loss: 5.2957, test_acc: 0.5784, best: 0.6380, time: 0:00:51
 Epoch: 70, lr: 1.0e-02, train_loss: 1.0269, train_acc: 0.6338 test_loss: 1.2639, test_acc: 0.6159, best: 0.6380, time: 0:00:51
 Epoch: 71, lr: 1.0e-02, train_loss: 1.0218, train_acc: 0.6312 test_loss: 1.3958, test_acc: 0.6112, best: 0.6380, time: 0:00:51
 Epoch: 72, lr: 1.0e-02, train_loss: 0.9910, train_acc: 0.6380 test_loss: 1.7489, test_acc: 0.5837, best: 0.6380, time: 0:00:51
 Epoch: 73, lr: 1.0e-02, train_loss: 1.0086, train_acc: 0.6366 test_loss: 4.7545, test_acc: 0.5434, best: 0.6380, time: 0:00:51
 Epoch: 74, lr: 1.0e-02, train_loss: 0.9937, train_acc: 0.6324 test_loss: 2.4385, test_acc: 0.6082, best: 0.6380, time: 0:00:51
 Epoch: 75, lr: 1.0e-02, train_loss: 0.9869, train_acc: 0.6474 test_loss: 1.5766, test_acc: 0.6060, best: 0.6380, time: 0:00:51
 Epoch: 76, lr: 1.0e-02, train_loss: 0.9592, train_acc: 0.6542 test_loss: 2.0655, test_acc: 0.6090, best: 0.6380, time: 0:00:51
 Epoch: 77, lr: 1.0e-02, train_loss: 0.9576, train_acc: 0.6512 test_loss: 1.3815, test_acc: 0.6365, best: 0.6380, time: 0:00:51
 Epoch: 78, lr: 1.0e-02, train_loss: 0.9598, train_acc: 0.6580 test_loss: 3.7769, test_acc: 0.5880, best: 0.6380, time: 0:00:51
 Epoch: 79, lr: 1.0e-02, train_loss: 0.9312, train_acc: 0.6600 test_loss: 2.1046, test_acc: 0.6159, best: 0.6380, time: 0:00:51
 Epoch: 80, lr: 1.0e-02, train_loss: 0.9204, train_acc: 0.6696 test_loss: 2.0171, test_acc: 0.6175, best: 0.6380, time: 0:00:51
 Epoch: 81, lr: 1.0e-02, train_loss: 0.9413, train_acc: 0.6712 test_loss: 3.1183, test_acc: 0.5690, best: 0.6380, time: 0:00:51
 Epoch: 82, lr: 1.0e-02, train_loss: 0.9139, train_acc: 0.6726 test_loss: 3.5225, test_acc: 0.5740, best: 0.6380, time: 0:00:51
 Epoch: 83, lr: 1.0e-02, train_loss: 0.9384, train_acc: 0.6624 test_loss: 2.9429, test_acc: 0.5959, best: 0.6380, time: 0:00:51
 Epoch: 84, lr: 1.0e-02, train_loss: 0.9273, train_acc: 0.6648 test_loss: 2.2411, test_acc: 0.6290, best: 0.6380, time: 0:00:51
 Epoch: 85, lr: 1.0e-02, train_loss: 0.9593, train_acc: 0.6544 test_loss: 1.1600, test_acc: 0.6426, best: 0.6426, time: 0:00:51
 Epoch: 86, lr: 1.0e-02, train_loss: 0.9357, train_acc: 0.6616 test_loss: 1.4183, test_acc: 0.6265, best: 0.6426, time: 0:00:51
 Epoch: 87, lr: 1.0e-02, train_loss: 0.9368, train_acc: 0.6656 test_loss: 1.0922, test_acc: 0.6586, best: 0.6586, time: 0:00:51
 Epoch: 88, lr: 1.0e-02, train_loss: 0.9130, train_acc: 0.6702 test_loss: 1.0995, test_acc: 0.6560, best: 0.6586, time: 0:00:51
 Epoch: 89, lr: 1.0e-02, train_loss: 0.9678, train_acc: 0.6464 test_loss: 1.0386, test_acc: 0.6306, best: 0.6586, time: 0:00:51
 Epoch: 90, lr: 1.0e-02, train_loss: 0.9187, train_acc: 0.6760 test_loss: 1.5427, test_acc: 0.6135, best: 0.6586, time: 0:00:51
 Epoch: 91, lr: 1.0e-02, train_loss: 0.9254, train_acc: 0.6670 test_loss: 1.0467, test_acc: 0.6656, best: 0.6656, time: 0:00:51
 Epoch: 92, lr: 1.0e-02, train_loss: 0.8971, train_acc: 0.6746 test_loss: 1.1257, test_acc: 0.6468, best: 0.6656, time: 0:00:51
 Epoch: 93, lr: 1.0e-02, train_loss: 0.8891, train_acc: 0.6750 test_loss: 1.1529, test_acc: 0.6379, best: 0.6656, time: 0:00:51
 Epoch: 94, lr: 1.0e-02, train_loss: 0.8826, train_acc: 0.6834 test_loss: 1.9973, test_acc: 0.6129, best: 0.6656, time: 0:00:51
 Epoch: 95, lr: 1.0e-02, train_loss: 0.8585, train_acc: 0.6922 test_loss: 2.6142, test_acc: 0.6008, best: 0.6656, time: 0:00:51
 Epoch: 96, lr: 1.0e-02, train_loss: 0.8248, train_acc: 0.7086 test_loss: 1.5075, test_acc: 0.6221, best: 0.6656, time: 0:00:51
 Epoch: 97, lr: 1.0e-02, train_loss: 0.8217, train_acc: 0.7062 test_loss: 1.9810, test_acc: 0.6180, best: 0.6656, time: 0:00:51
 Epoch: 98, lr: 1.0e-02, train_loss: 0.8360, train_acc: 0.7036 test_loss: 3.9416, test_acc: 0.5845, best: 0.6656, time: 0:00:51
 Epoch: 99, lr: 1.0e-02, train_loss: 0.8608, train_acc: 0.6882 test_loss: 2.4602, test_acc: 0.6076, best: 0.6656, time: 0:00:51
 Epoch: 100, lr: 1.0e-02, train_loss: 0.8812, train_acc: 0.6876 test_loss: 2.2760, test_acc: 0.5890, best: 0.6656, time: 0:00:51
 Epoch: 101, lr: 1.0e-02, train_loss: 0.8511, train_acc: 0.6926 test_loss: 2.5323, test_acc: 0.6194, best: 0.6656, time: 0:00:51
 Epoch: 102, lr: 1.0e-02, train_loss: 0.8134, train_acc: 0.7086 test_loss: 2.7008, test_acc: 0.6599, best: 0.6656, time: 0:00:51
 Epoch: 103, lr: 1.0e-02, train_loss: 0.8021, train_acc: 0.7076 test_loss: 4.3356, test_acc: 0.5885, best: 0.6656, time: 0:00:51
 Epoch: 104, lr: 1.0e-02, train_loss: 0.7999, train_acc: 0.7092 test_loss: 1.0738, test_acc: 0.6594, best: 0.6656, time: 0:00:51
 Epoch: 105, lr: 1.0e-02, train_loss: 0.8054, train_acc: 0.7074 test_loss: 2.6101, test_acc: 0.6066, best: 0.6656, time: 0:00:51
 Epoch: 106, lr: 1.0e-02, train_loss: 0.8280, train_acc: 0.6954 test_loss: 2.6503, test_acc: 0.6035, best: 0.6656, time: 0:00:51
 Epoch: 107, lr: 1.0e-02, train_loss: 0.7878, train_acc: 0.7178 test_loss: 3.1691, test_acc: 0.5970, best: 0.6656, time: 0:00:51
 Epoch: 108, lr: 1.0e-02, train_loss: 0.7741, train_acc: 0.7330 test_loss: 2.3012, test_acc: 0.5959, best: 0.6656, time: 0:00:51
 Epoch: 109, lr: 1.0e-02, train_loss: 0.8064, train_acc: 0.7134 test_loss: 5.7523, test_acc: 0.5806, best: 0.6656, time: 0:00:51
 Epoch: 110, lr: 1.0e-02, train_loss: 0.7609, train_acc: 0.7332 test_loss: 2.0988, test_acc: 0.5764, best: 0.6656, time: 0:00:51
 Epoch: 111, lr: 1.0e-02, train_loss: 0.7855, train_acc: 0.7208 test_loss: 1.3274, test_acc: 0.6426, best: 0.6656, time: 0:00:51
 Epoch: 112, lr: 1.0e-02, train_loss: 0.7771, train_acc: 0.7260 test_loss: 1.1609, test_acc: 0.6595, best: 0.6656, time: 0:00:51
 Epoch: 113, lr: 1.0e-02, train_loss: 0.7660, train_acc: 0.7282 test_loss: 4.8264, test_acc: 0.5866, best: 0.6656, time: 0:00:51
 Epoch: 114, lr: 1.0e-02, train_loss: 0.7522, train_acc: 0.7320 test_loss: 2.8975, test_acc: 0.6169, best: 0.6656, time: 0:00:51
 Epoch: 115, lr: 1.0e-02, train_loss: 0.7746, train_acc: 0.7168 test_loss: 2.8369, test_acc: 0.6204, best: 0.6656, time: 0:00:51
 Epoch: 116, lr: 1.0e-02, train_loss: 0.7445, train_acc: 0.7302 test_loss: 2.1256, test_acc: 0.6261, best: 0.6656, time: 0:00:51
 Epoch: 117, lr: 1.0e-02, train_loss: 0.7338, train_acc: 0.7410 test_loss: 1.8503, test_acc: 0.6094, best: 0.6656, time: 0:00:51
 Epoch: 118, lr: 1.0e-02, train_loss: 0.7385, train_acc: 0.7346 test_loss: 1.1464, test_acc: 0.6558, best: 0.6656, time: 0:00:51
 Epoch: 119, lr: 1.0e-02, train_loss: 0.7040, train_acc: 0.7520 test_loss: 1.1469, test_acc: 0.6522, best: 0.6656, time: 0:00:51
 Epoch: 120, lr: 1.0e-02, train_loss: 0.7098, train_acc: 0.7398 test_loss: 2.4149, test_acc: 0.6056, best: 0.6656, time: 0:00:51
 Epoch: 121, lr: 1.0e-02, train_loss: 0.7092, train_acc: 0.7542 test_loss: 3.7846, test_acc: 0.5933, best: 0.6656, time: 0:00:51
 Epoch: 122, lr: 1.0e-02, train_loss: 0.7366, train_acc: 0.7406 test_loss: 1.4258, test_acc: 0.6370, best: 0.6656, time: 0:00:51
 Epoch: 123, lr: 1.0e-02, train_loss: 0.7082, train_acc: 0.7496 test_loss: 1.5506, test_acc: 0.6306, best: 0.6656, time: 0:00:51
 Epoch: 124, lr: 1.0e-02, train_loss: 0.7164, train_acc: 0.7504 test_loss: 1.3188, test_acc: 0.6583, best: 0.6656, time: 0:00:51
 Epoch: 125, lr: 1.0e-02, train_loss: 0.6836, train_acc: 0.7554 test_loss: 1.3669, test_acc: 0.6414, best: 0.6656, time: 0:00:51
 Epoch: 126, lr: 1.0e-02, train_loss: 0.7019, train_acc: 0.7546 test_loss: 2.0269, test_acc: 0.6231, best: 0.6656, time: 0:00:51
 Epoch: 127, lr: 1.0e-02, train_loss: 0.6776, train_acc: 0.7614 test_loss: 2.6856, test_acc: 0.6235, best: 0.6656, time: 0:00:51
 Epoch: 128, lr: 1.0e-02, train_loss: 0.6918, train_acc: 0.7588 test_loss: 1.9457, test_acc: 0.5986, best: 0.6656, time: 0:00:51
 Epoch: 129, lr: 1.0e-02, train_loss: 0.6955, train_acc: 0.7530 test_loss: 2.5727, test_acc: 0.6162, best: 0.6656, time: 0:00:51
 Epoch: 130, lr: 1.0e-02, train_loss: 0.6816, train_acc: 0.7608 test_loss: 1.8800, test_acc: 0.6259, best: 0.6656, time: 0:00:51
 Epoch: 131, lr: 1.0e-02, train_loss: 0.6535, train_acc: 0.7710 test_loss: 3.8849, test_acc: 0.5979, best: 0.6656, time: 0:00:51
 Epoch: 132, lr: 1.0e-02, train_loss: 0.6785, train_acc: 0.7542 test_loss: 2.6208, test_acc: 0.6069, best: 0.6656, time: 0:00:51
 Epoch: 133, lr: 1.0e-02, train_loss: 0.6656, train_acc: 0.7664 test_loss: 2.4612, test_acc: 0.6010, best: 0.6656, time: 0:00:51
 Epoch: 134, lr: 1.0e-02, train_loss: 0.6632, train_acc: 0.7642 test_loss: 1.9256, test_acc: 0.6510, best: 0.6656, time: 0:00:51
 Epoch: 135, lr: 1.0e-02, train_loss: 0.6640, train_acc: 0.7672 test_loss: 1.2329, test_acc: 0.6665, best: 0.6665, time: 0:00:51
 Epoch: 136, lr: 1.0e-02, train_loss: 0.6531, train_acc: 0.7718 test_loss: 1.7247, test_acc: 0.6518, best: 0.6665, time: 0:00:51
 Epoch: 137, lr: 1.0e-02, train_loss: 0.6276, train_acc: 0.7786 test_loss: 3.0709, test_acc: 0.6068, best: 0.6665, time: 0:00:51
 Epoch: 138, lr: 1.0e-02, train_loss: 0.6254, train_acc: 0.7698 test_loss: 1.7415, test_acc: 0.6234, best: 0.6665, time: 0:00:51
 Epoch: 139, lr: 1.0e-02, train_loss: 0.6392, train_acc: 0.7718 test_loss: 1.2347, test_acc: 0.6695, best: 0.6695, time: 0:00:51
 Epoch: 140, lr: 1.0e-02, train_loss: 0.6366, train_acc: 0.7752 test_loss: 1.5352, test_acc: 0.6298, best: 0.6695, time: 0:00:51
 Epoch: 141, lr: 1.0e-02, train_loss: 0.6477, train_acc: 0.7712 test_loss: 6.1787, test_acc: 0.5755, best: 0.6695, time: 0:00:51
 Epoch: 142, lr: 1.0e-02, train_loss: 0.6381, train_acc: 0.7814 test_loss: 2.5919, test_acc: 0.6216, best: 0.6695, time: 0:00:51
 Epoch: 143, lr: 1.0e-02, train_loss: 0.6183, train_acc: 0.7818 test_loss: 2.5938, test_acc: 0.6302, best: 0.6695, time: 0:00:51
 Epoch: 144, lr: 1.0e-02, train_loss: 0.6409, train_acc: 0.7728 test_loss: 3.2037, test_acc: 0.5917, best: 0.6695, time: 0:00:51
 Epoch: 145, lr: 1.0e-02, train_loss: 0.6204, train_acc: 0.7834 test_loss: 1.2377, test_acc: 0.6783, best: 0.6783, time: 0:00:51
 Epoch: 146, lr: 1.0e-02, train_loss: 0.6333, train_acc: 0.7782 test_loss: 3.5843, test_acc: 0.6220, best: 0.6783, time: 0:00:51
 Epoch: 147, lr: 1.0e-02, train_loss: 0.6095, train_acc: 0.7850 test_loss: 2.2371, test_acc: 0.6600, best: 0.6783, time: 0:00:51
 Epoch: 148, lr: 1.0e-02, train_loss: 0.6012, train_acc: 0.7884 test_loss: 3.0923, test_acc: 0.6418, best: 0.6783, time: 0:00:51
 Epoch: 149, lr: 1.0e-02, train_loss: 0.5870, train_acc: 0.7922 test_loss: 2.4335, test_acc: 0.6341, best: 0.6783, time: 0:00:51
 Epoch: 150, lr: 1.0e-02, train_loss: 0.5956, train_acc: 0.7914 test_loss: 8.2115, test_acc: 0.5904, best: 0.6783, time: 0:00:51
 Epoch: 151, lr: 1.0e-02, train_loss: 0.5934, train_acc: 0.7928 test_loss: 2.5106, test_acc: 0.6310, best: 0.6783, time: 0:00:51
 Epoch: 152, lr: 1.0e-02, train_loss: 0.5776, train_acc: 0.7970 test_loss: 3.6340, test_acc: 0.6228, best: 0.6783, time: 0:00:51
 Epoch: 153, lr: 1.0e-02, train_loss: 0.5786, train_acc: 0.7954 test_loss: 2.5290, test_acc: 0.6344, best: 0.6783, time: 0:00:51
 Epoch: 154, lr: 1.0e-02, train_loss: 0.5882, train_acc: 0.7930 test_loss: 1.6842, test_acc: 0.6156, best: 0.6783, time: 0:00:51
 Epoch: 155, lr: 1.0e-02, train_loss: 0.5894, train_acc: 0.7926 test_loss: 1.5448, test_acc: 0.6511, best: 0.6783, time: 0:00:51
 Epoch: 156, lr: 1.0e-02, train_loss: 0.5887, train_acc: 0.7922 test_loss: 1.0887, test_acc: 0.6899, best: 0.6899, time: 0:00:51
 Epoch: 157, lr: 1.0e-02, train_loss: 0.6029, train_acc: 0.7862 test_loss: 1.4034, test_acc: 0.6827, best: 0.6899, time: 0:00:51
 Epoch: 158, lr: 1.0e-02, train_loss: 0.5739, train_acc: 0.7966 test_loss: 1.2914, test_acc: 0.6701, best: 0.6899, time: 0:00:51
 Epoch: 159, lr: 1.0e-02, train_loss: 0.5587, train_acc: 0.8048 test_loss: 1.4950, test_acc: 0.6384, best: 0.6899, time: 0:00:51
 Epoch: 160, lr: 1.0e-02, train_loss: 0.6009, train_acc: 0.7920 test_loss: 2.5799, test_acc: 0.6096, best: 0.6899, time: 0:00:51
 Epoch: 161, lr: 1.0e-02, train_loss: 0.5763, train_acc: 0.8026 test_loss: 1.2744, test_acc: 0.6690, best: 0.6899, time: 0:00:51
 Epoch: 162, lr: 1.0e-02, train_loss: 0.5584, train_acc: 0.8038 test_loss: 1.4069, test_acc: 0.6633, best: 0.6899, time: 0:00:51
 Epoch: 163, lr: 1.0e-02, train_loss: 0.5505, train_acc: 0.8070 test_loss: 4.9368, test_acc: 0.5948, best: 0.6899, time: 0:00:51
 Epoch: 164, lr: 1.0e-02, train_loss: 0.5526, train_acc: 0.8068 test_loss: 1.3639, test_acc: 0.6585, best: 0.6899, time: 0:00:51
 Epoch: 165, lr: 1.0e-02, train_loss: 0.5596, train_acc: 0.8012 test_loss: 2.2825, test_acc: 0.6376, best: 0.6899, time: 0:00:51
 Epoch: 166, lr: 1.0e-02, train_loss: 0.5408, train_acc: 0.8104 test_loss: 3.2359, test_acc: 0.5991, best: 0.6899, time: 0:00:51
 Epoch: 167, lr: 1.0e-02, train_loss: 0.5615, train_acc: 0.8036 test_loss: 1.8111, test_acc: 0.6541, best: 0.6899, time: 0:00:51
 Epoch: 168, lr: 1.0e-02, train_loss: 0.5401, train_acc: 0.8154 test_loss: 3.1319, test_acc: 0.6532, best: 0.6899, time: 0:00:51
 Epoch: 169, lr: 1.0e-02, train_loss: 0.5960, train_acc: 0.7930 test_loss: 1.8524, test_acc: 0.6611, best: 0.6899, time: 0:00:51
 Epoch: 170, lr: 1.0e-02, train_loss: 0.6047, train_acc: 0.7892 test_loss: 1.7027, test_acc: 0.6466, best: 0.6899, time: 0:00:51
 Epoch: 171, lr: 1.0e-02, train_loss: 0.5816, train_acc: 0.7950 test_loss: 2.3897, test_acc: 0.6575, best: 0.6899, time: 0:00:51
 Epoch: 172, lr: 1.0e-02, train_loss: 0.6006, train_acc: 0.7920 test_loss: 4.9031, test_acc: 0.6352, best: 0.6899, time: 0:00:51
 Epoch: 173, lr: 1.0e-02, train_loss: 0.5616, train_acc: 0.8026 test_loss: 5.6674, test_acc: 0.6298, best: 0.6899, time: 0:00:51
 Epoch: 174, lr: 1.0e-02, train_loss: 0.5624, train_acc: 0.8094 test_loss: 5.5905, test_acc: 0.6364, best: 0.6899, time: 0:00:51
 Epoch: 175, lr: 1.0e-02, train_loss: 0.5606, train_acc: 0.8052 test_loss: 1.6962, test_acc: 0.6697, best: 0.6899, time: 0:00:51
 Epoch: 176, lr: 1.0e-02, train_loss: 0.5491, train_acc: 0.8082 test_loss: 1.1420, test_acc: 0.6975, best: 0.6975, time: 0:00:51
 Epoch: 177, lr: 1.0e-02, train_loss: 0.5392, train_acc: 0.8124 test_loss: 2.3528, test_acc: 0.6199, best: 0.6975, time: 0:00:51
 Epoch: 178, lr: 1.0e-02, train_loss: 0.5305, train_acc: 0.8186 test_loss: 2.0383, test_acc: 0.6342, best: 0.6975, time: 0:00:51
 Epoch: 179, lr: 1.0e-02, train_loss: 0.5304, train_acc: 0.8166 test_loss: 3.3327, test_acc: 0.6274, best: 0.6975, time: 0:00:51
 Epoch: 180, lr: 2.0e-03, train_loss: 0.4623, train_acc: 0.8372 test_loss: 2.6500, test_acc: 0.6591, best: 0.6975, time: 0:00:51
 Epoch: 181, lr: 2.0e-03, train_loss: 0.4144, train_acc: 0.8488 test_loss: 1.9317, test_acc: 0.6790, best: 0.6975, time: 0:00:51
 Epoch: 182, lr: 2.0e-03, train_loss: 0.4023, train_acc: 0.8600 test_loss: 1.3813, test_acc: 0.6950, best: 0.6975, time: 0:00:51
 Epoch: 183, lr: 2.0e-03, train_loss: 0.4019, train_acc: 0.8664 test_loss: 1.7596, test_acc: 0.6884, best: 0.6975, time: 0:00:51
 Epoch: 184, lr: 2.0e-03, train_loss: 0.4266, train_acc: 0.8558 test_loss: 3.2521, test_acc: 0.6418, best: 0.6975, time: 0:00:51
 Epoch: 185, lr: 2.0e-03, train_loss: 0.3705, train_acc: 0.8756 test_loss: 2.5918, test_acc: 0.6606, best: 0.6975, time: 0:00:51
 Epoch: 186, lr: 2.0e-03, train_loss: 0.4004, train_acc: 0.8614 test_loss: 2.3053, test_acc: 0.6705, best: 0.6975, time: 0:00:51
 Epoch: 187, lr: 2.0e-03, train_loss: 0.3754, train_acc: 0.8770 test_loss: 4.7442, test_acc: 0.6292, best: 0.6975, time: 0:00:51
 Epoch: 188, lr: 2.0e-03, train_loss: 0.3655, train_acc: 0.8766 test_loss: 2.5057, test_acc: 0.6717, best: 0.6975, time: 0:00:51
 Epoch: 189, lr: 2.0e-03, train_loss: 0.3836, train_acc: 0.8646 test_loss: 1.5432, test_acc: 0.7063, best: 0.7063, time: 0:00:51
 Epoch: 190, lr: 2.0e-03, train_loss: 0.3940, train_acc: 0.8624 test_loss: 4.4542, test_acc: 0.6345, best: 0.7063, time: 0:00:51
 Epoch: 191, lr: 2.0e-03, train_loss: 0.3864, train_acc: 0.8642 test_loss: 2.1704, test_acc: 0.6873, best: 0.7063, time: 0:00:51
 Epoch: 192, lr: 2.0e-03, train_loss: 0.4028, train_acc: 0.8598 test_loss: 1.4750, test_acc: 0.7084, best: 0.7084, time: 0:00:51
 Epoch: 193, lr: 2.0e-03, train_loss: 0.3767, train_acc: 0.8730 test_loss: 1.7371, test_acc: 0.7084, best: 0.7084, time: 0:00:51
 Epoch: 194, lr: 2.0e-03, train_loss: 0.3913, train_acc: 0.8700 test_loss: 1.7377, test_acc: 0.6945, best: 0.7084, time: 0:00:51
 Epoch: 195, lr: 2.0e-03, train_loss: 0.3971, train_acc: 0.8678 test_loss: 1.5358, test_acc: 0.7130, best: 0.7130, time: 0:00:51
 Epoch: 196, lr: 2.0e-03, train_loss: 0.3751, train_acc: 0.8682 test_loss: 1.5088, test_acc: 0.7114, best: 0.7130, time: 0:00:51
 Epoch: 197, lr: 2.0e-03, train_loss: 0.3706, train_acc: 0.8708 test_loss: 1.7512, test_acc: 0.7061, best: 0.7130, time: 0:00:51
 Epoch: 198, lr: 2.0e-03, train_loss: 0.3652, train_acc: 0.8734 test_loss: 1.8351, test_acc: 0.6950, best: 0.7130, time: 0:00:51
 Epoch: 199, lr: 2.0e-03, train_loss: 0.3978, train_acc: 0.8612 test_loss: 1.5432, test_acc: 0.6866, best: 0.7130, time: 0:00:51
 Epoch: 200, lr: 2.0e-03, train_loss: 0.3916, train_acc: 0.8684 test_loss: 1.7118, test_acc: 0.6843, best: 0.7130, time: 0:00:51
 Epoch: 201, lr: 2.0e-03, train_loss: 0.3772, train_acc: 0.8690 test_loss: 1.6683, test_acc: 0.6861, best: 0.7130, time: 0:00:51
 Epoch: 202, lr: 2.0e-03, train_loss: 0.3560, train_acc: 0.8768 test_loss: 1.3205, test_acc: 0.7075, best: 0.7130, time: 0:00:51
 Epoch: 203, lr: 2.0e-03, train_loss: 0.3694, train_acc: 0.8752 test_loss: 2.9719, test_acc: 0.6566, best: 0.7130, time: 0:00:51
 Epoch: 204, lr: 2.0e-03, train_loss: 0.3802, train_acc: 0.8694 test_loss: 3.2934, test_acc: 0.6506, best: 0.7130, time: 0:00:51
 Epoch: 205, lr: 2.0e-03, train_loss: 0.3185, train_acc: 0.8892 test_loss: 2.7387, test_acc: 0.6630, best: 0.7130, time: 0:00:51
 Epoch: 206, lr: 2.0e-03, train_loss: 0.3542, train_acc: 0.8760 test_loss: 1.5731, test_acc: 0.6956, best: 0.7130, time: 0:00:51
 Epoch: 207, lr: 2.0e-03, train_loss: 0.3616, train_acc: 0.8752 test_loss: 1.3288, test_acc: 0.7120, best: 0.7130, time: 0:00:51
 Epoch: 208, lr: 2.0e-03, train_loss: 0.3415, train_acc: 0.8840 test_loss: 1.8386, test_acc: 0.6959, best: 0.7130, time: 0:00:51
 Epoch: 209, lr: 2.0e-03, train_loss: 0.3363, train_acc: 0.8852 test_loss: 2.0723, test_acc: 0.6769, best: 0.7130, time: 0:00:51
 Epoch: 210, lr: 2.0e-03, train_loss: 0.3332, train_acc: 0.8856 test_loss: 2.1663, test_acc: 0.6759, best: 0.7130, time: 0:00:51
 Epoch: 211, lr: 2.0e-03, train_loss: 0.3517, train_acc: 0.8832 test_loss: 1.5091, test_acc: 0.7020, best: 0.7130, time: 0:00:51
 Epoch: 212, lr: 2.0e-03, train_loss: 0.3379, train_acc: 0.8796 test_loss: 1.8093, test_acc: 0.6896, best: 0.7130, time: 0:00:51
 Epoch: 213, lr: 2.0e-03, train_loss: 0.3465, train_acc: 0.8840 test_loss: 1.3326, test_acc: 0.7004, best: 0.7130, time: 0:00:51
 Epoch: 214, lr: 2.0e-03, train_loss: 0.3446, train_acc: 0.8828 test_loss: 2.8629, test_acc: 0.6571, best: 0.7130, time: 0:00:51
 Epoch: 215, lr: 2.0e-03, train_loss: 0.3322, train_acc: 0.8840 test_loss: 2.0718, test_acc: 0.6781, best: 0.7130, time: 0:00:51
 Epoch: 216, lr: 2.0e-03, train_loss: 0.3434, train_acc: 0.8822 test_loss: 2.0752, test_acc: 0.6773, best: 0.7130, time: 0:00:51
 Epoch: 217, lr: 2.0e-03, train_loss: 0.3467, train_acc: 0.8798 test_loss: 1.4368, test_acc: 0.7027, best: 0.7130, time: 0:00:51
 Epoch: 218, lr: 2.0e-03, train_loss: 0.3238, train_acc: 0.8846 test_loss: 2.6797, test_acc: 0.6492, best: 0.7130, time: 0:00:51
 Epoch: 219, lr: 2.0e-03, train_loss: 0.3502, train_acc: 0.8812 test_loss: 1.2457, test_acc: 0.7093, best: 0.7130, time: 0:00:51
 Epoch: 220, lr: 2.0e-03, train_loss: 0.3441, train_acc: 0.8808 test_loss: 2.0132, test_acc: 0.6653, best: 0.7130, time: 0:00:51
 Epoch: 221, lr: 2.0e-03, train_loss: 0.3363, train_acc: 0.8842 test_loss: 1.3249, test_acc: 0.7015, best: 0.7130, time: 0:00:51
 Epoch: 222, lr: 2.0e-03, train_loss: 0.3335, train_acc: 0.8916 test_loss: 2.4074, test_acc: 0.6721, best: 0.7130, time: 0:00:51
 Epoch: 223, lr: 2.0e-03, train_loss: 0.3303, train_acc: 0.8858 test_loss: 3.2988, test_acc: 0.6505, best: 0.7130, time: 0:00:51
 Epoch: 224, lr: 2.0e-03, train_loss: 0.3304, train_acc: 0.8886 test_loss: 2.0701, test_acc: 0.6804, best: 0.7130, time: 0:00:51
 Epoch: 225, lr: 2.0e-03, train_loss: 0.3445, train_acc: 0.8774 test_loss: 1.3767, test_acc: 0.7081, best: 0.7130, time: 0:00:51
 Epoch: 226, lr: 2.0e-03, train_loss: 0.3280, train_acc: 0.8904 test_loss: 1.8909, test_acc: 0.6773, best: 0.7130, time: 0:00:51
 Epoch: 227, lr: 2.0e-03, train_loss: 0.3373, train_acc: 0.8860 test_loss: 1.2230, test_acc: 0.7096, best: 0.7130, time: 0:00:51
 Epoch: 228, lr: 2.0e-03, train_loss: 0.3238, train_acc: 0.8890 test_loss: 2.1032, test_acc: 0.6741, best: 0.7130, time: 0:00:51
 Epoch: 229, lr: 2.0e-03, train_loss: 0.3228, train_acc: 0.8900 test_loss: 1.2140, test_acc: 0.7190, best: 0.7190, time: 0:00:51
 Epoch: 230, lr: 2.0e-03, train_loss: 0.3167, train_acc: 0.8900 test_loss: 2.1559, test_acc: 0.6716, best: 0.7190, time: 0:00:51
 Epoch: 231, lr: 2.0e-03, train_loss: 0.3160, train_acc: 0.8934 test_loss: 1.2855, test_acc: 0.7094, best: 0.7190, time: 0:00:51
 Epoch: 232, lr: 2.0e-03, train_loss: 0.3164, train_acc: 0.8920 test_loss: 1.4716, test_acc: 0.6996, best: 0.7190, time: 0:00:51
 Epoch: 233, lr: 2.0e-03, train_loss: 0.3225, train_acc: 0.8892 test_loss: 1.2752, test_acc: 0.7123, best: 0.7190, time: 0:00:51
 Epoch: 234, lr: 2.0e-03, train_loss: 0.3326, train_acc: 0.8858 test_loss: 1.7310, test_acc: 0.6847, best: 0.7190, time: 0:00:51
 Epoch: 235, lr: 2.0e-03, train_loss: 0.3163, train_acc: 0.8910 test_loss: 1.6326, test_acc: 0.6913, best: 0.7190, time: 0:00:51
 Epoch: 236, lr: 2.0e-03, train_loss: 0.3086, train_acc: 0.8998 test_loss: 5.1069, test_acc: 0.6058, best: 0.7190, time: 0:00:51
 Epoch: 237, lr: 2.0e-03, train_loss: 0.3193, train_acc: 0.8926 test_loss: 2.3386, test_acc: 0.6551, best: 0.7190, time: 0:00:51
 Epoch: 238, lr: 2.0e-03, train_loss: 0.3137, train_acc: 0.8952 test_loss: 1.7967, test_acc: 0.6787, best: 0.7190, time: 0:00:51
 Epoch: 239, lr: 2.0e-03, train_loss: 0.3139, train_acc: 0.8936 test_loss: 3.7439, test_acc: 0.6294, best: 0.7190, time: 0:00:51
 Epoch: 240, lr: 4.0e-04, train_loss: 0.3319, train_acc: 0.8916 test_loss: 1.9010, test_acc: 0.6761, best: 0.7190, time: 0:00:51
 Epoch: 241, lr: 4.0e-04, train_loss: 0.3176, train_acc: 0.8924 test_loss: 1.6175, test_acc: 0.6935, best: 0.7190, time: 0:00:51
 Epoch: 242, lr: 4.0e-04, train_loss: 0.3224, train_acc: 0.8892 test_loss: 1.4161, test_acc: 0.7047, best: 0.7190, time: 0:00:51
 Epoch: 243, lr: 4.0e-04, train_loss: 0.3015, train_acc: 0.8972 test_loss: 2.0534, test_acc: 0.6787, best: 0.7190, time: 0:00:51
 Epoch: 244, lr: 4.0e-04, train_loss: 0.3047, train_acc: 0.8986 test_loss: 1.8654, test_acc: 0.6895, best: 0.7190, time: 0:00:51
 Epoch: 245, lr: 4.0e-04, train_loss: 0.2939, train_acc: 0.8998 test_loss: 1.6185, test_acc: 0.6961, best: 0.7190, time: 0:00:51
 Epoch: 246, lr: 4.0e-04, train_loss: 0.3108, train_acc: 0.8938 test_loss: 1.3550, test_acc: 0.7143, best: 0.7190, time: 0:00:51
 Epoch: 247, lr: 4.0e-04, train_loss: 0.3121, train_acc: 0.8966 test_loss: 1.3508, test_acc: 0.7144, best: 0.7190, time: 0:00:51
 Epoch: 248, lr: 4.0e-04, train_loss: 0.2966, train_acc: 0.9010 test_loss: 1.4766, test_acc: 0.7137, best: 0.7190, time: 0:00:51
 Epoch: 249, lr: 4.0e-04, train_loss: 0.3141, train_acc: 0.8964 test_loss: 1.3993, test_acc: 0.7079, best: 0.7190, time: 0:00:51
 Epoch: 250, lr: 4.0e-04, train_loss: 0.2838, train_acc: 0.9076 test_loss: 1.4700, test_acc: 0.7049, best: 0.7190, time: 0:00:51
 Epoch: 251, lr: 4.0e-04, train_loss: 0.2879, train_acc: 0.9018 test_loss: 1.4736, test_acc: 0.7074, best: 0.7190, time: 0:00:51
 Epoch: 252, lr: 4.0e-04, train_loss: 0.2950, train_acc: 0.9038 test_loss: 1.5058, test_acc: 0.7080, best: 0.7190, time: 0:00:51
 Epoch: 253, lr: 4.0e-04, train_loss: 0.2978, train_acc: 0.8984 test_loss: 1.3517, test_acc: 0.7153, best: 0.7190, time: 0:00:51
 Epoch: 254, lr: 4.0e-04, train_loss: 0.3038, train_acc: 0.8960 test_loss: 1.3281, test_acc: 0.7136, best: 0.7190, time: 0:00:51
 Epoch: 255, lr: 4.0e-04, train_loss: 0.2788, train_acc: 0.9058 test_loss: 1.4602, test_acc: 0.7095, best: 0.7190, time: 0:00:51
 Epoch: 256, lr: 4.0e-04, train_loss: 0.3064, train_acc: 0.8990 test_loss: 1.4107, test_acc: 0.7050, best: 0.7190, time: 0:00:51
 Epoch: 257, lr: 4.0e-04, train_loss: 0.2878, train_acc: 0.8998 test_loss: 1.4237, test_acc: 0.7093, best: 0.7190, time: 0:00:51
 Epoch: 258, lr: 4.0e-04, train_loss: 0.2816, train_acc: 0.9066 test_loss: 1.5208, test_acc: 0.7051, best: 0.7190, time: 0:00:51
 Epoch: 259, lr: 4.0e-04, train_loss: 0.3100, train_acc: 0.8918 test_loss: 1.8080, test_acc: 0.6885, best: 0.7190, time: 0:00:51
 Epoch: 260, lr: 4.0e-04, train_loss: 0.2993, train_acc: 0.8992 test_loss: 1.3317, test_acc: 0.7137, best: 0.7190, time: 0:00:51
 Epoch: 261, lr: 4.0e-04, train_loss: 0.2657, train_acc: 0.9114 test_loss: 1.3944, test_acc: 0.7096, best: 0.7190, time: 0:00:51
 Epoch: 262, lr: 4.0e-04, train_loss: 0.2776, train_acc: 0.9070 test_loss: 2.0736, test_acc: 0.6737, best: 0.7190, time: 0:00:51
 Epoch: 263, lr: 4.0e-04, train_loss: 0.2791, train_acc: 0.9038 test_loss: 1.6411, test_acc: 0.6940, best: 0.7190, time: 0:00:51
 Epoch: 264, lr: 4.0e-04, train_loss: 0.2850, train_acc: 0.9012 test_loss: 1.1817, test_acc: 0.7230, best: 0.7230, time: 0:00:51
 Epoch: 265, lr: 4.0e-04, train_loss: 0.2879, train_acc: 0.8992 test_loss: 1.4417, test_acc: 0.7057, best: 0.7230, time: 0:00:51
 Epoch: 266, lr: 4.0e-04, train_loss: 0.2777, train_acc: 0.9068 test_loss: 2.0618, test_acc: 0.6731, best: 0.7230, time: 0:00:51
 Epoch: 267, lr: 4.0e-04, train_loss: 0.2864, train_acc: 0.9012 test_loss: 3.5056, test_acc: 0.6365, best: 0.7230, time: 0:00:51
 Epoch: 268, lr: 4.0e-04, train_loss: 0.2983, train_acc: 0.8998 test_loss: 1.2990, test_acc: 0.7125, best: 0.7230, time: 0:00:51
 Epoch: 269, lr: 4.0e-04, train_loss: 0.2879, train_acc: 0.9004 test_loss: 1.9490, test_acc: 0.6780, best: 0.7230, time: 0:00:51
 Epoch: 270, lr: 8.0e-05, train_loss: 0.2991, train_acc: 0.9022 test_loss: 1.4921, test_acc: 0.6990, best: 0.7230, time: 0:00:51
 Epoch: 271, lr: 8.0e-05, train_loss: 0.2741, train_acc: 0.9076 test_loss: 2.4972, test_acc: 0.6524, best: 0.7230, time: 0:00:51
 Epoch: 272, lr: 8.0e-05, train_loss: 0.2815, train_acc: 0.9018 test_loss: 1.3917, test_acc: 0.7120, best: 0.7230, time: 0:00:51
 Epoch: 273, lr: 8.0e-05, train_loss: 0.2867, train_acc: 0.9048 test_loss: 1.5632, test_acc: 0.6913, best: 0.7230, time: 0:00:51
 Epoch: 274, lr: 8.0e-05, train_loss: 0.2749, train_acc: 0.9044 test_loss: 1.5979, test_acc: 0.7010, best: 0.7230, time: 0:00:51
 Epoch: 275, lr: 8.0e-05, train_loss: 0.2747, train_acc: 0.9062 test_loss: 1.4928, test_acc: 0.7010, best: 0.7230, time: 0:00:51
 Epoch: 276, lr: 8.0e-05, train_loss: 0.2766, train_acc: 0.9046 test_loss: 1.5608, test_acc: 0.6917, best: 0.7230, time: 0:00:51
 Epoch: 277, lr: 8.0e-05, train_loss: 0.2657, train_acc: 0.9042 test_loss: 1.4413, test_acc: 0.7014, best: 0.7230, time: 0:00:51
 Epoch: 278, lr: 8.0e-05, train_loss: 0.2859, train_acc: 0.9076 test_loss: 1.2552, test_acc: 0.7234, best: 0.7234, time: 0:00:51
 Epoch: 279, lr: 8.0e-05, train_loss: 0.2663, train_acc: 0.9090 test_loss: 1.4558, test_acc: 0.7101, best: 0.7234, time: 0:00:51
 Epoch: 280, lr: 8.0e-05, train_loss: 0.2704, train_acc: 0.9092 test_loss: 1.5906, test_acc: 0.7041, best: 0.7234, time: 0:00:51
 Epoch: 281, lr: 8.0e-05, train_loss: 0.2863, train_acc: 0.9030 test_loss: 1.2757, test_acc: 0.7171, best: 0.7234, time: 0:00:51
 Epoch: 282, lr: 8.0e-05, train_loss: 0.2799, train_acc: 0.9078 test_loss: 1.5207, test_acc: 0.7023, best: 0.7234, time: 0:00:51
 Epoch: 283, lr: 8.0e-05, train_loss: 0.2779, train_acc: 0.9072 test_loss: 1.7946, test_acc: 0.6860, best: 0.7234, time: 0:00:51
 Epoch: 284, lr: 8.0e-05, train_loss: 0.2803, train_acc: 0.9068 test_loss: 1.9477, test_acc: 0.6865, best: 0.7234, time: 0:00:51
 Epoch: 285, lr: 8.0e-05, train_loss: 0.2626, train_acc: 0.9066 test_loss: 1.3067, test_acc: 0.7229, best: 0.7234, time: 0:00:51
 Epoch: 286, lr: 8.0e-05, train_loss: 0.2889, train_acc: 0.9026 test_loss: 1.2899, test_acc: 0.7198, best: 0.7234, time: 0:00:51
 Epoch: 287, lr: 8.0e-05, train_loss: 0.3040, train_acc: 0.8964 test_loss: 1.4962, test_acc: 0.7023, best: 0.7234, time: 0:00:51
 Epoch: 288, lr: 8.0e-05, train_loss: 0.2685, train_acc: 0.9084 test_loss: 2.4056, test_acc: 0.6657, best: 0.7234, time: 0:00:51
 Epoch: 289, lr: 8.0e-05, train_loss: 0.3060, train_acc: 0.8984 test_loss: 1.5655, test_acc: 0.6997, best: 0.7234, time: 0:00:51
 Epoch: 290, lr: 8.0e-05, train_loss: 0.2684, train_acc: 0.9042 test_loss: 1.8358, test_acc: 0.6869, best: 0.7234, time: 0:00:51
 Epoch: 291, lr: 8.0e-05, train_loss: 0.3019, train_acc: 0.8990 test_loss: 1.2870, test_acc: 0.7209, best: 0.7234, time: 0:00:51
 Epoch: 292, lr: 8.0e-05, train_loss: 0.2744, train_acc: 0.9070 test_loss: 1.4214, test_acc: 0.7081, best: 0.7234, time: 0:00:51
 Epoch: 293, lr: 8.0e-05, train_loss: 0.2730, train_acc: 0.9042 test_loss: 1.3883, test_acc: 0.7177, best: 0.7234, time: 0:00:51
 Epoch: 294, lr: 8.0e-05, train_loss: 0.2717, train_acc: 0.9030 test_loss: 1.5066, test_acc: 0.7061, best: 0.7234, time: 0:00:51
 Epoch: 295, lr: 8.0e-05, train_loss: 0.2861, train_acc: 0.9030 test_loss: 1.2126, test_acc: 0.7249, best: 0.7249, time: 0:00:52
 Epoch: 296, lr: 8.0e-05, train_loss: 0.2667, train_acc: 0.9064 test_loss: 1.5153, test_acc: 0.7007, best: 0.7249, time: 0:00:51
 Epoch: 297, lr: 8.0e-05, train_loss: 0.2708, train_acc: 0.9122 test_loss: 1.4644, test_acc: 0.7014, best: 0.7249, time: 0:00:50
 Epoch: 298, lr: 8.0e-05, train_loss: 0.2906, train_acc: 0.8978 test_loss: 2.0837, test_acc: 0.6741, best: 0.7249, time: 0:00:50
 Epoch: 299, lr: 8.0e-05, train_loss: 0.2848, train_acc: 0.9036 test_loss: 1.4888, test_acc: 0.6991, best: 0.7249, time: 0:00:51
 Highest accuracy: 0.7249