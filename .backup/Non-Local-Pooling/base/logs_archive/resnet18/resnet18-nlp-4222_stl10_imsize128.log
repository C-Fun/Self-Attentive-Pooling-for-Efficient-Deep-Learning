
 Run on time: 2022-06-29 16:01:26.762377

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : RESNET18_NLP_4222
	 im_size              : 128
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): NetworkByName(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 32)
                (col_embed): Embedding(256, 32)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 64)
                (col_embed): Embedding(256, 64)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 128)
                (col_embed): Embedding(256, 128)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 256)
                (col_embed): Embedding(256, 256)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.3105, train_acc: 0.2000 test_loss: 1.8437, test_acc: 0.3011, best: 0.3011, time: 0:01:07
 Epoch: 2, lr: 1.0e-02, train_loss: 1.9876, train_acc: 0.2412 test_loss: 1.9309, test_acc: 0.2772, best: 0.3011, time: 0:01:05
 Epoch: 3, lr: 1.0e-02, train_loss: 1.8970, train_acc: 0.2818 test_loss: 1.5993, test_acc: 0.3769, best: 0.3769, time: 0:01:06
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8425, train_acc: 0.3100 test_loss: 1.6109, test_acc: 0.3704, best: 0.3769, time: 0:01:05
 Epoch: 5, lr: 1.0e-02, train_loss: 1.7937, train_acc: 0.3236 test_loss: 1.5797, test_acc: 0.4020, best: 0.4020, time: 0:01:05
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7747, train_acc: 0.3378 test_loss: 1.5458, test_acc: 0.4160, best: 0.4160, time: 0:01:05
 Epoch: 7, lr: 1.0e-02, train_loss: 1.7287, train_acc: 0.3530 test_loss: 1.8109, test_acc: 0.3746, best: 0.4160, time: 0:01:06
 Epoch: 8, lr: 1.0e-02, train_loss: 1.6692, train_acc: 0.3746 test_loss: 1.4331, test_acc: 0.4572, best: 0.4572, time: 0:01:05
 Epoch: 9, lr: 1.0e-02, train_loss: 1.6336, train_acc: 0.3954 test_loss: 1.5449, test_acc: 0.4405, best: 0.4572, time: 0:01:05
 Epoch: 10, lr: 1.0e-02, train_loss: 1.5994, train_acc: 0.4064 test_loss: 1.3590, test_acc: 0.4924, best: 0.4924, time: 0:01:06
 Epoch: 11, lr: 1.0e-02, train_loss: 1.5630, train_acc: 0.4158 test_loss: 1.2789, test_acc: 0.5282, best: 0.5282, time: 0:01:05
 Epoch: 12, lr: 1.0e-02, train_loss: 1.5110, train_acc: 0.4434 test_loss: 1.3192, test_acc: 0.5159, best: 0.5282, time: 0:01:06
 Epoch: 13, lr: 1.0e-02, train_loss: 1.4712, train_acc: 0.4602 test_loss: 1.2710, test_acc: 0.5279, best: 0.5282, time: 0:01:06
 Epoch: 14, lr: 1.0e-02, train_loss: 1.4381, train_acc: 0.4758 test_loss: 1.1969, test_acc: 0.5656, best: 0.5656, time: 0:01:05
 Epoch: 15, lr: 1.0e-02, train_loss: 1.4237, train_acc: 0.4848 test_loss: 1.2511, test_acc: 0.5465, best: 0.5656, time: 0:01:06
 Epoch: 16, lr: 1.0e-02, train_loss: 1.3884, train_acc: 0.5012 test_loss: 1.2381, test_acc: 0.5533, best: 0.5656, time: 0:01:05
 Epoch: 17, lr: 1.0e-02, train_loss: 1.3456, train_acc: 0.5084 test_loss: 1.2626, test_acc: 0.5619, best: 0.5656, time: 0:01:05
 Epoch: 18, lr: 1.0e-02, train_loss: 1.3248, train_acc: 0.5168 test_loss: 1.2727, test_acc: 0.5316, best: 0.5656, time: 0:01:05
 Epoch: 19, lr: 1.0e-02, train_loss: 1.3351, train_acc: 0.5080 test_loss: 1.2486, test_acc: 0.5534, best: 0.5656, time: 0:01:06
 Epoch: 20, lr: 1.0e-02, train_loss: 1.3001, train_acc: 0.5272 test_loss: 1.1660, test_acc: 0.5823, best: 0.5823, time: 0:01:06
 Epoch: 21, lr: 1.0e-02, train_loss: 1.2745, train_acc: 0.5332 test_loss: 1.1473, test_acc: 0.5824, best: 0.5824, time: 0:01:05
 Epoch: 22, lr: 1.0e-02, train_loss: 1.2431, train_acc: 0.5428 test_loss: 1.4284, test_acc: 0.5254, best: 0.5824, time: 0:01:05
 Epoch: 23, lr: 1.0e-02, train_loss: 1.2370, train_acc: 0.5498 test_loss: 1.1600, test_acc: 0.5741, best: 0.5824, time: 0:01:04
 Epoch: 24, lr: 1.0e-02, train_loss: 1.2172, train_acc: 0.5536 test_loss: 1.0497, test_acc: 0.6199, best: 0.6199, time: 0:01:05
 Epoch: 25, lr: 1.0e-02, train_loss: 1.1833, train_acc: 0.5698 test_loss: 1.0761, test_acc: 0.6260, best: 0.6260, time: 0:01:05
 Epoch: 26, lr: 1.0e-02, train_loss: 1.1861, train_acc: 0.5750 test_loss: 1.0731, test_acc: 0.6196, best: 0.6260, time: 0:01:05
 Epoch: 27, lr: 1.0e-02, train_loss: 1.1548, train_acc: 0.5808 test_loss: 1.0003, test_acc: 0.6430, best: 0.6430, time: 0:01:06
 Epoch: 28, lr: 1.0e-02, train_loss: 1.1396, train_acc: 0.5912 test_loss: 1.1213, test_acc: 0.6151, best: 0.6430, time: 0:01:05
 Epoch: 29, lr: 1.0e-02, train_loss: 1.1479, train_acc: 0.5818 test_loss: 0.9727, test_acc: 0.6519, best: 0.6519, time: 0:01:05
 Epoch: 30, lr: 1.0e-02, train_loss: 1.1088, train_acc: 0.6016 test_loss: 0.9811, test_acc: 0.6452, best: 0.6519, time: 0:01:05
 Epoch: 31, lr: 1.0e-02, train_loss: 1.1022, train_acc: 0.5986 test_loss: 0.9975, test_acc: 0.6456, best: 0.6519, time: 0:01:05
 Epoch: 32, lr: 1.0e-02, train_loss: 1.1034, train_acc: 0.6006 test_loss: 1.0636, test_acc: 0.6309, best: 0.6519, time: 0:01:05
 Epoch: 33, lr: 1.0e-02, train_loss: 1.0656, train_acc: 0.6088 test_loss: 1.0826, test_acc: 0.6346, best: 0.6519, time: 0:01:05
 Epoch: 34, lr: 1.0e-02, train_loss: 1.0699, train_acc: 0.6094 test_loss: 0.9541, test_acc: 0.6556, best: 0.6556, time: 0:01:05
 Epoch: 35, lr: 1.0e-02, train_loss: 1.0356, train_acc: 0.6274 test_loss: 1.0336, test_acc: 0.6510, best: 0.6556, time: 0:01:05
 Epoch: 36, lr: 1.0e-02, train_loss: 1.0444, train_acc: 0.6332 test_loss: 0.9997, test_acc: 0.6569, best: 0.6569, time: 0:01:05
 Epoch: 37, lr: 1.0e-02, train_loss: 1.0318, train_acc: 0.6290 test_loss: 0.9379, test_acc: 0.6605, best: 0.6605, time: 0:01:05
 Epoch: 38, lr: 1.0e-02, train_loss: 1.0080, train_acc: 0.6398 test_loss: 1.0936, test_acc: 0.6346, best: 0.6605, time: 0:01:05
 Epoch: 39, lr: 1.0e-02, train_loss: 1.0121, train_acc: 0.6294 test_loss: 0.9266, test_acc: 0.6703, best: 0.6703, time: 0:01:05
 Epoch: 40, lr: 1.0e-02, train_loss: 1.0052, train_acc: 0.6384 test_loss: 1.0853, test_acc: 0.6254, best: 0.6703, time: 0:01:05
 Epoch: 41, lr: 1.0e-02, train_loss: 0.9925, train_acc: 0.6374 test_loss: 1.0189, test_acc: 0.6545, best: 0.6703, time: 0:01:05
 Epoch: 42, lr: 1.0e-02, train_loss: 0.9497, train_acc: 0.6546 test_loss: 1.0677, test_acc: 0.6481, best: 0.6703, time: 0:01:05
 Epoch: 43, lr: 1.0e-02, train_loss: 0.9669, train_acc: 0.6548 test_loss: 0.9607, test_acc: 0.6625, best: 0.6703, time: 0:01:05
 Epoch: 44, lr: 1.0e-02, train_loss: 0.9316, train_acc: 0.6646 test_loss: 1.1246, test_acc: 0.6336, best: 0.6703, time: 0:01:06
 Epoch: 45, lr: 1.0e-02, train_loss: 0.9289, train_acc: 0.6660 test_loss: 0.8690, test_acc: 0.6977, best: 0.6977, time: 0:01:05
 Epoch: 46, lr: 1.0e-02, train_loss: 0.9243, train_acc: 0.6614 test_loss: 0.9558, test_acc: 0.6610, best: 0.6977, time: 0:01:05
 Epoch: 47, lr: 1.0e-02, train_loss: 0.9196, train_acc: 0.6650 test_loss: 0.8883, test_acc: 0.6903, best: 0.6977, time: 0:01:05
 Epoch: 48, lr: 1.0e-02, train_loss: 0.9230, train_acc: 0.6592 test_loss: 0.9633, test_acc: 0.6729, best: 0.6977, time: 0:01:05
 Epoch: 49, lr: 1.0e-02, train_loss: 0.9055, train_acc: 0.6696 test_loss: 0.8932, test_acc: 0.6943, best: 0.6977, time: 0:01:05
 Epoch: 50, lr: 1.0e-02, train_loss: 0.8936, train_acc: 0.6792 test_loss: 0.8976, test_acc: 0.6904, best: 0.6977, time: 0:01:05
 Epoch: 51, lr: 1.0e-02, train_loss: 0.8960, train_acc: 0.6764 test_loss: 1.0320, test_acc: 0.6745, best: 0.6977, time: 0:01:05
 Epoch: 52, lr: 1.0e-02, train_loss: 0.8808, train_acc: 0.6856 test_loss: 0.8808, test_acc: 0.7004, best: 0.7004, time: 0:01:05
 Epoch: 53, lr: 1.0e-02, train_loss: 0.8612, train_acc: 0.6968 test_loss: 0.9527, test_acc: 0.6871, best: 0.7004, time: 0:01:05
 Epoch: 54, lr: 1.0e-02, train_loss: 0.8475, train_acc: 0.6912 test_loss: 0.9164, test_acc: 0.6885, best: 0.7004, time: 0:01:05
 Epoch: 55, lr: 1.0e-02, train_loss: 0.8480, train_acc: 0.6916 test_loss: 0.8884, test_acc: 0.7053, best: 0.7053, time: 0:01:05
 Epoch: 56, lr: 1.0e-02, train_loss: 0.8233, train_acc: 0.7068 test_loss: 0.8561, test_acc: 0.7144, best: 0.7144, time: 0:01:39
 Epoch: 57, lr: 1.0e-02, train_loss: 0.8283, train_acc: 0.7006 test_loss: 0.9014, test_acc: 0.7029, best: 0.7144, time: 0:01:05
 Epoch: 58, lr: 1.0e-02, train_loss: 0.8348, train_acc: 0.7024 test_loss: 0.8647, test_acc: 0.7159, best: 0.7159, time: 0:01:04
 Epoch: 59, lr: 1.0e-02, train_loss: 0.8153, train_acc: 0.7060 test_loss: 0.9401, test_acc: 0.6954, best: 0.7159, time: 0:01:05
 Epoch: 60, lr: 1.0e-02, train_loss: 0.8148, train_acc: 0.7114 test_loss: 0.9558, test_acc: 0.6885, best: 0.7159, time: 0:01:04
 Epoch: 61, lr: 1.0e-02, train_loss: 0.8011, train_acc: 0.7116 test_loss: 0.9256, test_acc: 0.7045, best: 0.7159, time: 0:01:04
 Epoch: 62, lr: 1.0e-02, train_loss: 0.7858, train_acc: 0.7176 test_loss: 0.9746, test_acc: 0.6930, best: 0.7159, time: 0:01:04
 Epoch: 63, lr: 1.0e-02, train_loss: 0.7821, train_acc: 0.7256 test_loss: 0.8965, test_acc: 0.7029, best: 0.7159, time: 0:01:05
 Epoch: 64, lr: 1.0e-02, train_loss: 0.8012, train_acc: 0.7222 test_loss: 0.8696, test_acc: 0.7051, best: 0.7159, time: 0:01:05
 Epoch: 65, lr: 1.0e-02, train_loss: 0.7825, train_acc: 0.7160 test_loss: 0.8674, test_acc: 0.7150, best: 0.7159, time: 0:01:04
 Epoch: 66, lr: 1.0e-02, train_loss: 0.7642, train_acc: 0.7234 test_loss: 0.8148, test_acc: 0.7324, best: 0.7324, time: 0:01:05
 Epoch: 67, lr: 1.0e-02, train_loss: 0.7561, train_acc: 0.7322 test_loss: 0.8985, test_acc: 0.7104, best: 0.7324, time: 0:01:04
 Epoch: 68, lr: 1.0e-02, train_loss: 0.7736, train_acc: 0.7238 test_loss: 0.8161, test_acc: 0.7250, best: 0.7324, time: 0:01:04
 Epoch: 69, lr: 1.0e-02, train_loss: 0.7444, train_acc: 0.7362 test_loss: 0.9695, test_acc: 0.6897, best: 0.7324, time: 0:01:04
 Epoch: 70, lr: 1.0e-02, train_loss: 0.7258, train_acc: 0.7414 test_loss: 0.9357, test_acc: 0.7173, best: 0.7324, time: 0:01:04
 Epoch: 71, lr: 1.0e-02, train_loss: 0.7230, train_acc: 0.7432 test_loss: 0.9064, test_acc: 0.7095, best: 0.7324, time: 0:01:04
 Epoch: 72, lr: 1.0e-02, train_loss: 0.7212, train_acc: 0.7422 test_loss: 0.9519, test_acc: 0.7035, best: 0.7324, time: 0:01:04
 Epoch: 73, lr: 1.0e-02, train_loss: 0.7267, train_acc: 0.7414 test_loss: 0.8371, test_acc: 0.7279, best: 0.7324, time: 0:01:04
 Epoch: 74, lr: 1.0e-02, train_loss: 0.7045, train_acc: 0.7494 test_loss: 0.8777, test_acc: 0.7254, best: 0.7324, time: 0:01:04
 Epoch: 75, lr: 1.0e-02, train_loss: 0.6823, train_acc: 0.7538 test_loss: 0.8916, test_acc: 0.7115, best: 0.7324, time: 0:01:04
 Epoch: 76, lr: 1.0e-02, train_loss: 0.7005, train_acc: 0.7528 test_loss: 0.8903, test_acc: 0.7175, best: 0.7324, time: 0:01:04
 Epoch: 77, lr: 1.0e-02, train_loss: 0.6950, train_acc: 0.7512 test_loss: 0.8835, test_acc: 0.7288, best: 0.7324, time: 0:01:04
 Epoch: 78, lr: 1.0e-02, train_loss: 0.6900, train_acc: 0.7522 test_loss: 0.8669, test_acc: 0.7332, best: 0.7332, time: 0:01:05
 Epoch: 79, lr: 1.0e-02, train_loss: 0.6614, train_acc: 0.7666 test_loss: 0.9191, test_acc: 0.7220, best: 0.7332, time: 0:01:05
 Epoch: 80, lr: 1.0e-02, train_loss: 0.6843, train_acc: 0.7512 test_loss: 0.9418, test_acc: 0.7117, best: 0.7332, time: 0:01:04
 Epoch: 81, lr: 1.0e-02, train_loss: 0.6712, train_acc: 0.7564 test_loss: 0.9157, test_acc: 0.7211, best: 0.7332, time: 0:01:04
 Epoch: 82, lr: 1.0e-02, train_loss: 0.6803, train_acc: 0.7648 test_loss: 0.9831, test_acc: 0.7188, best: 0.7332, time: 0:01:04
 Epoch: 83, lr: 1.0e-02, train_loss: 0.6559, train_acc: 0.7626 test_loss: 0.8522, test_acc: 0.7360, best: 0.7360, time: 0:01:05
 Epoch: 84, lr: 1.0e-02, train_loss: 0.6442, train_acc: 0.7738 test_loss: 0.9880, test_acc: 0.7105, best: 0.7360, time: 0:01:04
 Epoch: 85, lr: 1.0e-02, train_loss: 0.6576, train_acc: 0.7676 test_loss: 0.9376, test_acc: 0.7274, best: 0.7360, time: 0:01:05
 Epoch: 86, lr: 1.0e-02, train_loss: 0.6361, train_acc: 0.7728 test_loss: 0.8437, test_acc: 0.7288, best: 0.7360, time: 0:01:05
 Epoch: 87, lr: 1.0e-02, train_loss: 0.6088, train_acc: 0.7798 test_loss: 0.9167, test_acc: 0.7236, best: 0.7360, time: 0:01:04
 Epoch: 88, lr: 1.0e-02, train_loss: 0.6551, train_acc: 0.7630 test_loss: 0.9175, test_acc: 0.7245, best: 0.7360, time: 0:01:05
 Epoch: 89, lr: 1.0e-02, train_loss: 0.6294, train_acc: 0.7804 test_loss: 0.8966, test_acc: 0.7326, best: 0.7360, time: 0:01:04
 Epoch: 90, lr: 1.0e-02, train_loss: 0.6144, train_acc: 0.7806 test_loss: 1.0267, test_acc: 0.7119, best: 0.7360, time: 0:01:04
 Epoch: 91, lr: 1.0e-02, train_loss: 0.6131, train_acc: 0.7830 test_loss: 0.8377, test_acc: 0.7428, best: 0.7428, time: 0:01:05
 Epoch: 92, lr: 1.0e-02, train_loss: 0.6118, train_acc: 0.7834 test_loss: 0.7934, test_acc: 0.7501, best: 0.7501, time: 0:01:05
 Epoch: 93, lr: 1.0e-02, train_loss: 0.6187, train_acc: 0.7750 test_loss: 0.8591, test_acc: 0.7389, best: 0.7501, time: 0:01:04
 Epoch: 94, lr: 1.0e-02, train_loss: 0.5945, train_acc: 0.7894 test_loss: 0.8514, test_acc: 0.7412, best: 0.7501, time: 0:01:05
 Epoch: 95, lr: 1.0e-02, train_loss: 0.5842, train_acc: 0.7940 test_loss: 0.8517, test_acc: 0.7392, best: 0.7501, time: 0:01:04
 Epoch: 96, lr: 1.0e-02, train_loss: 0.5650, train_acc: 0.7956 test_loss: 0.9752, test_acc: 0.7215, best: 0.7501, time: 0:01:05
 Epoch: 97, lr: 1.0e-02, train_loss: 0.5936, train_acc: 0.7876 test_loss: 1.0537, test_acc: 0.7107, best: 0.7501, time: 0:01:04
 Epoch: 98, lr: 1.0e-02, train_loss: 0.5839, train_acc: 0.7990 test_loss: 0.8873, test_acc: 0.7330, best: 0.7501, time: 0:01:04
 Epoch: 99, lr: 1.0e-02, train_loss: 0.5946, train_acc: 0.7944 test_loss: 0.8979, test_acc: 0.7369, best: 0.7501, time: 0:01:09
 Epoch: 100, lr: 1.0e-02, train_loss: 0.5758, train_acc: 0.7952 test_loss: 0.9283, test_acc: 0.7264, best: 0.7501, time: 0:01:02
 Epoch: 101, lr: 1.0e-02, train_loss: 0.5714, train_acc: 0.8024 test_loss: 0.8891, test_acc: 0.7375, best: 0.7501, time: 0:01:00
 Epoch: 102, lr: 1.0e-02, train_loss: 0.5739, train_acc: 0.7966 test_loss: 0.9874, test_acc: 0.7154, best: 0.7501, time: 0:01:04
 Epoch: 103, lr: 1.0e-02, train_loss: 0.5519, train_acc: 0.8012 test_loss: 0.9749, test_acc: 0.7345, best: 0.7501, time: 0:01:01
 Epoch: 104, lr: 1.0e-02, train_loss: 0.5478, train_acc: 0.8082 test_loss: 1.0508, test_acc: 0.7107, best: 0.7501, time: 0:01:01
 Epoch: 105, lr: 1.0e-02, train_loss: 0.5457, train_acc: 0.8088 test_loss: 0.8810, test_acc: 0.7485, best: 0.7501, time: 0:01:01
 Epoch: 106, lr: 1.0e-02, train_loss: 0.5365, train_acc: 0.8084 test_loss: 0.9432, test_acc: 0.7355, best: 0.7501, time: 0:01:01
 Epoch: 107, lr: 1.0e-02, train_loss: 0.5566, train_acc: 0.8092 test_loss: 0.9560, test_acc: 0.7359, best: 0.7501, time: 0:01:02
 Epoch: 108, lr: 1.0e-02, train_loss: 0.5317, train_acc: 0.8108 test_loss: 0.9036, test_acc: 0.7478, best: 0.7501, time: 0:01:01
 Epoch: 109, lr: 1.0e-02, train_loss: 0.5399, train_acc: 0.8070 test_loss: 0.8767, test_acc: 0.7479, best: 0.7501, time: 0:00:59
 Epoch: 110, lr: 1.0e-02, train_loss: 0.5564, train_acc: 0.8064 test_loss: 0.9271, test_acc: 0.7299, best: 0.7501, time: 0:00:59
 Epoch: 111, lr: 1.0e-02, train_loss: 0.5332, train_acc: 0.8120 test_loss: 0.9837, test_acc: 0.7264, best: 0.7501, time: 0:00:59
 Epoch: 112, lr: 1.0e-02, train_loss: 0.5513, train_acc: 0.8082 test_loss: 0.8775, test_acc: 0.7505, best: 0.7505, time: 0:01:02
 Epoch: 113, lr: 1.0e-02, train_loss: 0.5245, train_acc: 0.8162 test_loss: 0.8813, test_acc: 0.7554, best: 0.7554, time: 0:01:02
 Epoch: 114, lr: 1.0e-02, train_loss: 0.5189, train_acc: 0.8226 test_loss: 0.8805, test_acc: 0.7519, best: 0.7554, time: 0:01:02
 Epoch: 115, lr: 1.0e-02, train_loss: 0.5444, train_acc: 0.8088 test_loss: 0.9437, test_acc: 0.7449, best: 0.7554, time: 0:01:03
 Epoch: 116, lr: 1.0e-02, train_loss: 0.5330, train_acc: 0.8188 test_loss: 0.9563, test_acc: 0.7371, best: 0.7554, time: 0:01:01
 Epoch: 117, lr: 1.0e-02, train_loss: 0.5268, train_acc: 0.8134 test_loss: 0.8813, test_acc: 0.7406, best: 0.7554, time: 0:01:01
 Epoch: 118, lr: 1.0e-02, train_loss: 0.5115, train_acc: 0.8198 test_loss: 0.9938, test_acc: 0.7355, best: 0.7554, time: 0:01:01
 Epoch: 119, lr: 1.0e-02, train_loss: 0.4970, train_acc: 0.8234 test_loss: 0.9185, test_acc: 0.7511, best: 0.7554, time: 0:01:02
 Epoch: 120, lr: 1.0e-02, train_loss: 0.5017, train_acc: 0.8232 test_loss: 1.0071, test_acc: 0.7506, best: 0.7554, time: 0:01:01
 Epoch: 121, lr: 1.0e-02, train_loss: 0.5236, train_acc: 0.8186 test_loss: 0.9716, test_acc: 0.7440, best: 0.7554, time: 0:01:01
 Epoch: 122, lr: 1.0e-02, train_loss: 0.4997, train_acc: 0.8238 test_loss: 1.0353, test_acc: 0.7240, best: 0.7554, time: 0:01:01
 Epoch: 123, lr: 1.0e-02, train_loss: 0.5139, train_acc: 0.8154 test_loss: 0.9756, test_acc: 0.7382, best: 0.7554, time: 0:01:01
 Epoch: 124, lr: 1.0e-02, train_loss: 0.4809, train_acc: 0.8282 test_loss: 1.0274, test_acc: 0.7396, best: 0.7554, time: 0:01:01
 Epoch: 125, lr: 1.0e-02, train_loss: 0.5080, train_acc: 0.8204 test_loss: 0.9468, test_acc: 0.7429, best: 0.7554, time: 0:01:01
 Epoch: 126, lr: 1.0e-02, train_loss: 0.4720, train_acc: 0.8358 test_loss: 0.9796, test_acc: 0.7380, best: 0.7554, time: 0:01:01
 Epoch: 127, lr: 1.0e-02, train_loss: 0.4804, train_acc: 0.8294 test_loss: 0.9272, test_acc: 0.7512, best: 0.7554, time: 0:01:01
 Epoch: 128, lr: 1.0e-02, train_loss: 0.4915, train_acc: 0.8288 test_loss: 1.0459, test_acc: 0.7326, best: 0.7554, time: 0:01:01
 Epoch: 129, lr: 1.0e-02, train_loss: 0.4584, train_acc: 0.8350 test_loss: 1.0455, test_acc: 0.7362, best: 0.7554, time: 0:01:01
 Epoch: 130, lr: 1.0e-02, train_loss: 0.4846, train_acc: 0.8306 test_loss: 0.9400, test_acc: 0.7458, best: 0.7554, time: 0:01:02
 Epoch: 131, lr: 1.0e-02, train_loss: 0.4715, train_acc: 0.8372 test_loss: 0.9737, test_acc: 0.7470, best: 0.7554, time: 0:01:03
 Epoch: 132, lr: 1.0e-02, train_loss: 0.4664, train_acc: 0.8374 test_loss: 1.0024, test_acc: 0.7419, best: 0.7554, time: 0:01:03
 Epoch: 133, lr: 1.0e-02, train_loss: 0.4722, train_acc: 0.8298 test_loss: 0.9397, test_acc: 0.7539, best: 0.7554, time: 0:01:01
 Epoch: 134, lr: 1.0e-02, train_loss: 0.4898, train_acc: 0.8274 test_loss: 0.9782, test_acc: 0.7459, best: 0.7554, time: 0:01:02
 Epoch: 135, lr: 1.0e-02, train_loss: 0.4780, train_acc: 0.8308 test_loss: 1.0845, test_acc: 0.7409, best: 0.7554, time: 0:01:02
 Epoch: 136, lr: 1.0e-02, train_loss: 0.4745, train_acc: 0.8328 test_loss: 0.9592, test_acc: 0.7526, best: 0.7554, time: 0:01:02
 Epoch: 137, lr: 1.0e-02, train_loss: 0.4496, train_acc: 0.8438 test_loss: 1.0418, test_acc: 0.7440, best: 0.7554, time: 0:01:02
 Epoch: 138, lr: 1.0e-02, train_loss: 0.4539, train_acc: 0.8438 test_loss: 1.0730, test_acc: 0.7302, best: 0.7554, time: 0:01:02
 Epoch: 139, lr: 1.0e-02, train_loss: 0.4384, train_acc: 0.8550 test_loss: 1.1390, test_acc: 0.7311, best: 0.7554, time: 0:01:02
 Epoch: 140, lr: 1.0e-02, train_loss: 0.4656, train_acc: 0.8294 test_loss: 0.9747, test_acc: 0.7474, best: 0.7554, time: 0:01:01
 Epoch: 141, lr: 1.0e-02, train_loss: 0.4506, train_acc: 0.8416 test_loss: 1.0001, test_acc: 0.7438, best: 0.7554, time: 0:01:01
 Epoch: 142, lr: 1.0e-02, train_loss: 0.4418, train_acc: 0.8498 test_loss: 1.0246, test_acc: 0.7461, best: 0.7554, time: 0:01:01
 Epoch: 143, lr: 1.0e-02, train_loss: 0.4475, train_acc: 0.8452 test_loss: 1.0393, test_acc: 0.7435, best: 0.7554, time: 0:01:00
 Epoch: 144, lr: 1.0e-02, train_loss: 0.4391, train_acc: 0.8476 test_loss: 0.9331, test_acc: 0.7586, best: 0.7586, time: 0:01:01
 Epoch: 145, lr: 1.0e-02, train_loss: 0.4389, train_acc: 0.8428 test_loss: 1.0324, test_acc: 0.7514, best: 0.7586, time: 0:01:01
 Epoch: 146, lr: 1.0e-02, train_loss: 0.4340, train_acc: 0.8428 test_loss: 1.1229, test_acc: 0.7361, best: 0.7586, time: 0:01:01
 Epoch: 147, lr: 1.0e-02, train_loss: 0.4355, train_acc: 0.8488 test_loss: 1.0409, test_acc: 0.7516, best: 0.7586, time: 0:01:01
 Epoch: 148, lr: 1.0e-02, train_loss: 0.4467, train_acc: 0.8404 test_loss: 1.0206, test_acc: 0.7391, best: 0.7586, time: 0:01:00
 Epoch: 149, lr: 1.0e-02, train_loss: 0.4472, train_acc: 0.8416 test_loss: 0.9644, test_acc: 0.7590, best: 0.7590, time: 0:01:01
 Epoch: 150, lr: 1.0e-02, train_loss: 0.4308, train_acc: 0.8564 test_loss: 1.0664, test_acc: 0.7386, best: 0.7590, time: 0:01:01
 Epoch: 151, lr: 1.0e-02, train_loss: 0.4215, train_acc: 0.8506 test_loss: 0.9891, test_acc: 0.7510, best: 0.7590, time: 0:01:01
 Epoch: 152, lr: 1.0e-02, train_loss: 0.4175, train_acc: 0.8582 test_loss: 1.0038, test_acc: 0.7576, best: 0.7590, time: 0:01:01
 Epoch: 153, lr: 1.0e-02, train_loss: 0.4088, train_acc: 0.8538 test_loss: 1.0708, test_acc: 0.7449, best: 0.7590, time: 0:01:01
 Epoch: 154, lr: 1.0e-02, train_loss: 0.4132, train_acc: 0.8564 test_loss: 0.9368, test_acc: 0.7641, best: 0.7641, time: 0:01:01
 Epoch: 155, lr: 1.0e-02, train_loss: 0.4198, train_acc: 0.8556 test_loss: 0.9407, test_acc: 0.7535, best: 0.7641, time: 0:01:01
 Epoch: 156, lr: 1.0e-02, train_loss: 0.4139, train_acc: 0.8584 test_loss: 0.9893, test_acc: 0.7589, best: 0.7641, time: 0:01:01
 Epoch: 157, lr: 1.0e-02, train_loss: 0.4424, train_acc: 0.8414 test_loss: 1.0599, test_acc: 0.7438, best: 0.7641, time: 0:01:00
 Epoch: 158, lr: 1.0e-02, train_loss: 0.4425, train_acc: 0.8498 test_loss: 0.9443, test_acc: 0.7562, best: 0.7641, time: 0:01:01
 Epoch: 159, lr: 1.0e-02, train_loss: 0.4253, train_acc: 0.8560 test_loss: 0.9637, test_acc: 0.7589, best: 0.7641, time: 0:01:00
 Epoch: 160, lr: 1.0e-02, train_loss: 0.4316, train_acc: 0.8488 test_loss: 0.9629, test_acc: 0.7595, best: 0.7641, time: 0:01:00
 Epoch: 161, lr: 1.0e-02, train_loss: 0.3977, train_acc: 0.8592 test_loss: 0.9755, test_acc: 0.7618, best: 0.7641, time: 0:01:00
 Epoch: 162, lr: 1.0e-02, train_loss: 0.4127, train_acc: 0.8578 test_loss: 1.0572, test_acc: 0.7468, best: 0.7641, time: 0:01:00
 Epoch: 163, lr: 1.0e-02, train_loss: 0.3868, train_acc: 0.8644 test_loss: 1.0551, test_acc: 0.7478, best: 0.7641, time: 0:01:01
 Epoch: 164, lr: 1.0e-02, train_loss: 0.4018, train_acc: 0.8618 test_loss: 1.0054, test_acc: 0.7595, best: 0.7641, time: 0:01:01
 Epoch: 165, lr: 1.0e-02, train_loss: 0.4163, train_acc: 0.8584 test_loss: 1.0372, test_acc: 0.7505, best: 0.7641, time: 0:01:01
 Epoch: 166, lr: 1.0e-02, train_loss: 0.3866, train_acc: 0.8686 test_loss: 1.0622, test_acc: 0.7470, best: 0.7641, time: 0:01:01
 Epoch: 167, lr: 1.0e-02, train_loss: 0.3947, train_acc: 0.8630 test_loss: 0.9712, test_acc: 0.7630, best: 0.7641, time: 0:01:00
 Epoch: 168, lr: 1.0e-02, train_loss: 0.3940, train_acc: 0.8642 test_loss: 0.9689, test_acc: 0.7605, best: 0.7641, time: 0:01:01
 Epoch: 169, lr: 1.0e-02, train_loss: 0.4069, train_acc: 0.8586 test_loss: 1.0442, test_acc: 0.7484, best: 0.7641, time: 0:01:01
 Epoch: 170, lr: 1.0e-02, train_loss: 0.3727, train_acc: 0.8700 test_loss: 1.0758, test_acc: 0.7499, best: 0.7641, time: 0:01:01
 Epoch: 171, lr: 1.0e-02, train_loss: 0.3834, train_acc: 0.8626 test_loss: 0.9810, test_acc: 0.7642, best: 0.7642, time: 0:01:01
 Epoch: 172, lr: 1.0e-02, train_loss: 0.3941, train_acc: 0.8622 test_loss: 0.9901, test_acc: 0.7499, best: 0.7642, time: 0:01:00
 Epoch: 173, lr: 1.0e-02, train_loss: 0.4079, train_acc: 0.8574 test_loss: 0.9428, test_acc: 0.7616, best: 0.7642, time: 0:01:01
 Epoch: 174, lr: 1.0e-02, train_loss: 0.3819, train_acc: 0.8670 test_loss: 0.9918, test_acc: 0.7614, best: 0.7642, time: 0:01:00
 Epoch: 175, lr: 1.0e-02, train_loss: 0.3843, train_acc: 0.8688 test_loss: 1.0030, test_acc: 0.7589, best: 0.7642, time: 0:01:01
 Epoch: 176, lr: 1.0e-02, train_loss: 0.4112, train_acc: 0.8550 test_loss: 1.0983, test_acc: 0.7440, best: 0.7642, time: 0:01:01
 Epoch: 177, lr: 1.0e-02, train_loss: 0.4046, train_acc: 0.8614 test_loss: 0.9408, test_acc: 0.7710, best: 0.7710, time: 0:01:01
 Epoch: 178, lr: 1.0e-02, train_loss: 0.3805, train_acc: 0.8690 test_loss: 0.9382, test_acc: 0.7669, best: 0.7710, time: 0:01:01
 Epoch: 179, lr: 1.0e-02, train_loss: 0.3669, train_acc: 0.8696 test_loss: 1.0520, test_acc: 0.7539, best: 0.7710, time: 0:01:01
 Epoch: 180, lr: 2.0e-03, train_loss: 0.3438, train_acc: 0.8778 test_loss: 0.9071, test_acc: 0.7694, best: 0.7710, time: 0:01:01
 Epoch: 181, lr: 2.0e-03, train_loss: 0.3190, train_acc: 0.8860 test_loss: 0.9340, test_acc: 0.7770, best: 0.7770, time: 0:01:01
 Epoch: 182, lr: 2.0e-03, train_loss: 0.2978, train_acc: 0.8978 test_loss: 0.9045, test_acc: 0.7792, best: 0.7792, time: 0:01:01
 Epoch: 183, lr: 2.0e-03, train_loss: 0.2996, train_acc: 0.8974 test_loss: 0.9207, test_acc: 0.7716, best: 0.7792, time: 0:01:01
 Epoch: 184, lr: 2.0e-03, train_loss: 0.3011, train_acc: 0.8938 test_loss: 0.8916, test_acc: 0.7800, best: 0.7800, time: 0:01:01
 Epoch: 185, lr: 2.0e-03, train_loss: 0.2935, train_acc: 0.8974 test_loss: 0.8941, test_acc: 0.7790, best: 0.7800, time: 0:01:00
 Epoch: 186, lr: 2.0e-03, train_loss: 0.2944, train_acc: 0.9022 test_loss: 0.9103, test_acc: 0.7794, best: 0.7800, time: 0:01:01
 Epoch: 187, lr: 2.0e-03, train_loss: 0.2763, train_acc: 0.9052 test_loss: 0.9425, test_acc: 0.7798, best: 0.7800, time: 0:01:01
 Epoch: 188, lr: 2.0e-03, train_loss: 0.2721, train_acc: 0.9054 test_loss: 0.9114, test_acc: 0.7785, best: 0.7800, time: 0:01:00
 Epoch: 189, lr: 2.0e-03, train_loss: 0.2616, train_acc: 0.9098 test_loss: 0.9495, test_acc: 0.7824, best: 0.7824, time: 0:01:01
 Epoch: 190, lr: 2.0e-03, train_loss: 0.2799, train_acc: 0.9010 test_loss: 0.9630, test_acc: 0.7806, best: 0.7824, time: 0:01:01
 Epoch: 191, lr: 2.0e-03, train_loss: 0.2600, train_acc: 0.9092 test_loss: 0.9487, test_acc: 0.7766, best: 0.7824, time: 0:01:01
 Epoch: 192, lr: 2.0e-03, train_loss: 0.2992, train_acc: 0.8940 test_loss: 0.9576, test_acc: 0.7751, best: 0.7824, time: 0:01:00
 Epoch: 193, lr: 2.0e-03, train_loss: 0.2668, train_acc: 0.9080 test_loss: 0.9459, test_acc: 0.7825, best: 0.7825, time: 0:01:01
 Epoch: 194, lr: 2.0e-03, train_loss: 0.2659, train_acc: 0.9108 test_loss: 0.9445, test_acc: 0.7821, best: 0.7825, time: 0:01:01
 Epoch: 195, lr: 2.0e-03, train_loss: 0.2777, train_acc: 0.9068 test_loss: 0.9575, test_acc: 0.7801, best: 0.7825, time: 0:01:01
 Epoch: 196, lr: 2.0e-03, train_loss: 0.2871, train_acc: 0.8968 test_loss: 0.9589, test_acc: 0.7764, best: 0.7825, time: 0:01:01
 Epoch: 197, lr: 2.0e-03, train_loss: 0.2649, train_acc: 0.9102 test_loss: 0.9234, test_acc: 0.7847, best: 0.7847, time: 0:01:01
 Epoch: 198, lr: 2.0e-03, train_loss: 0.2692, train_acc: 0.9098 test_loss: 0.9764, test_acc: 0.7794, best: 0.7847, time: 0:01:01
 Epoch: 199, lr: 2.0e-03, train_loss: 0.2577, train_acc: 0.9130 test_loss: 0.9562, test_acc: 0.7794, best: 0.7847, time: 0:01:01
 Epoch: 200, lr: 2.0e-03, train_loss: 0.2560, train_acc: 0.9110 test_loss: 0.9680, test_acc: 0.7746, best: 0.7847, time: 0:01:01
 Epoch: 201, lr: 2.0e-03, train_loss: 0.2695, train_acc: 0.9056 test_loss: 0.9403, test_acc: 0.7802, best: 0.7847, time: 0:01:01
 Epoch: 202, lr: 2.0e-03, train_loss: 0.2604, train_acc: 0.9102 test_loss: 0.9498, test_acc: 0.7752, best: 0.7847, time: 0:01:01
 Epoch: 203, lr: 2.0e-03, train_loss: 0.2537, train_acc: 0.9130 test_loss: 0.9695, test_acc: 0.7766, best: 0.7847, time: 0:01:00
 Epoch: 204, lr: 2.0e-03, train_loss: 0.2659, train_acc: 0.9086 test_loss: 0.9644, test_acc: 0.7814, best: 0.7847, time: 0:01:01
 Epoch: 205, lr: 2.0e-03, train_loss: 0.2666, train_acc: 0.9070 test_loss: 0.9719, test_acc: 0.7833, best: 0.7847, time: 0:01:01
 Epoch: 206, lr: 2.0e-03, train_loss: 0.2690, train_acc: 0.9060 test_loss: 0.9778, test_acc: 0.7800, best: 0.7847, time: 0:01:01
 Epoch: 207, lr: 2.0e-03, train_loss: 0.2448, train_acc: 0.9160 test_loss: 0.9605, test_acc: 0.7782, best: 0.7847, time: 0:01:01
 Epoch: 208, lr: 2.0e-03, train_loss: 0.2365, train_acc: 0.9178 test_loss: 0.9883, test_acc: 0.7768, best: 0.7847, time: 0:01:00
 Epoch: 209, lr: 2.0e-03, train_loss: 0.2465, train_acc: 0.9140 test_loss: 1.0035, test_acc: 0.7759, best: 0.7847, time: 0:01:01
 Epoch: 210, lr: 2.0e-03, train_loss: 0.2273, train_acc: 0.9234 test_loss: 0.9529, test_acc: 0.7819, best: 0.7847, time: 0:01:00
 Epoch: 211, lr: 2.0e-03, train_loss: 0.2535, train_acc: 0.9116 test_loss: 0.9768, test_acc: 0.7781, best: 0.7847, time: 0:01:00
 Epoch: 212, lr: 2.0e-03, train_loss: 0.2527, train_acc: 0.9140 test_loss: 0.9734, test_acc: 0.7732, best: 0.7847, time: 0:01:01
 Epoch: 213, lr: 2.0e-03, train_loss: 0.2315, train_acc: 0.9196 test_loss: 0.9891, test_acc: 0.7788, best: 0.7847, time: 0:01:00
 Epoch: 214, lr: 2.0e-03, train_loss: 0.2474, train_acc: 0.9134 test_loss: 0.9894, test_acc: 0.7764, best: 0.7847, time: 0:01:01
 Epoch: 215, lr: 2.0e-03, train_loss: 0.2360, train_acc: 0.9236 test_loss: 0.9739, test_acc: 0.7811, best: 0.7847, time: 0:01:00
 Epoch: 216, lr: 2.0e-03, train_loss: 0.2480, train_acc: 0.9184 test_loss: 1.0239, test_acc: 0.7739, best: 0.7847, time: 0:01:00
 Epoch: 217, lr: 2.0e-03, train_loss: 0.2247, train_acc: 0.9220 test_loss: 0.9632, test_acc: 0.7877, best: 0.7877, time: 0:01:02
 Epoch: 218, lr: 2.0e-03, train_loss: 0.2650, train_acc: 0.9104 test_loss: 1.0410, test_acc: 0.7750, best: 0.7877, time: 0:01:00
 Epoch: 219, lr: 2.0e-03, train_loss: 0.2389, train_acc: 0.9154 test_loss: 0.9995, test_acc: 0.7792, best: 0.7877, time: 0:01:00
 Epoch: 220, lr: 2.0e-03, train_loss: 0.2506, train_acc: 0.9130 test_loss: 0.9777, test_acc: 0.7815, best: 0.7877, time: 0:01:01
 Epoch: 221, lr: 2.0e-03, train_loss: 0.2375, train_acc: 0.9216 test_loss: 0.9751, test_acc: 0.7839, best: 0.7877, time: 0:01:01
 Epoch: 222, lr: 2.0e-03, train_loss: 0.2212, train_acc: 0.9208 test_loss: 0.9886, test_acc: 0.7782, best: 0.7877, time: 0:01:01
 Epoch: 223, lr: 2.0e-03, train_loss: 0.2545, train_acc: 0.9080 test_loss: 0.9892, test_acc: 0.7802, best: 0.7877, time: 0:01:01
 Epoch: 224, lr: 2.0e-03, train_loss: 0.2357, train_acc: 0.9158 test_loss: 0.9761, test_acc: 0.7798, best: 0.7877, time: 0:01:01
 Epoch: 225, lr: 2.0e-03, train_loss: 0.2261, train_acc: 0.9230 test_loss: 0.9915, test_acc: 0.7780, best: 0.7877, time: 0:01:00
 Epoch: 226, lr: 2.0e-03, train_loss: 0.2392, train_acc: 0.9182 test_loss: 0.9965, test_acc: 0.7819, best: 0.7877, time: 0:01:01
 Epoch: 227, lr: 2.0e-03, train_loss: 0.2455, train_acc: 0.9148 test_loss: 1.0090, test_acc: 0.7781, best: 0.7877, time: 0:01:01
 Epoch: 228, lr: 2.0e-03, train_loss: 0.2482, train_acc: 0.9134 test_loss: 1.0131, test_acc: 0.7840, best: 0.7877, time: 0:01:01
 Epoch: 229, lr: 2.0e-03, train_loss: 0.2431, train_acc: 0.9210 test_loss: 1.0096, test_acc: 0.7759, best: 0.7877, time: 0:01:01
 Epoch: 230, lr: 2.0e-03, train_loss: 0.2197, train_acc: 0.9234 test_loss: 0.9816, test_acc: 0.7845, best: 0.7877, time: 0:01:00
 Epoch: 231, lr: 2.0e-03, train_loss: 0.2545, train_acc: 0.9140 test_loss: 1.0067, test_acc: 0.7854, best: 0.7877, time: 0:01:01
 Epoch: 232, lr: 2.0e-03, train_loss: 0.2349, train_acc: 0.9158 test_loss: 1.0192, test_acc: 0.7811, best: 0.7877, time: 0:01:00
 Epoch: 233, lr: 2.0e-03, train_loss: 0.2226, train_acc: 0.9234 test_loss: 0.9523, test_acc: 0.7844, best: 0.7877, time: 0:01:00
 Epoch: 234, lr: 2.0e-03, train_loss: 0.2146, train_acc: 0.9264 test_loss: 0.9917, test_acc: 0.7829, best: 0.7877, time: 0:01:00
 Epoch: 235, lr: 2.0e-03, train_loss: 0.2351, train_acc: 0.9226 test_loss: 0.9696, test_acc: 0.7849, best: 0.7877, time: 0:01:01
 Epoch: 236, lr: 2.0e-03, train_loss: 0.2185, train_acc: 0.9232 test_loss: 0.9911, test_acc: 0.7809, best: 0.7877, time: 0:01:01
 Epoch: 237, lr: 2.0e-03, train_loss: 0.2338, train_acc: 0.9212 test_loss: 1.0074, test_acc: 0.7799, best: 0.7877, time: 0:01:01
 Epoch: 238, lr: 2.0e-03, train_loss: 0.2398, train_acc: 0.9196 test_loss: 0.9947, test_acc: 0.7821, best: 0.7877, time: 0:01:01
 Epoch: 239, lr: 2.0e-03, train_loss: 0.2248, train_acc: 0.9212 test_loss: 0.9972, test_acc: 0.7801, best: 0.7877, time: 0:01:00
 Epoch: 240, lr: 4.0e-04, train_loss: 0.2507, train_acc: 0.9184 test_loss: 1.0040, test_acc: 0.7784, best: 0.7877, time: 0:01:01
 Epoch: 241, lr: 4.0e-04, train_loss: 0.2291, train_acc: 0.9222 test_loss: 1.0054, test_acc: 0.7808, best: 0.7877, time: 0:01:01
 Epoch: 242, lr: 4.0e-04, train_loss: 0.2403, train_acc: 0.9172 test_loss: 0.9976, test_acc: 0.7819, best: 0.7877, time: 0:01:01
 Epoch: 243, lr: 4.0e-04, train_loss: 0.2070, train_acc: 0.9282 test_loss: 0.9790, test_acc: 0.7792, best: 0.7877, time: 0:01:01
 Epoch: 244, lr: 4.0e-04, train_loss: 0.2232, train_acc: 0.9220 test_loss: 0.9963, test_acc: 0.7821, best: 0.7877, time: 0:01:00
 Epoch: 245, lr: 4.0e-04, train_loss: 0.2016, train_acc: 0.9258 test_loss: 1.0139, test_acc: 0.7795, best: 0.7877, time: 0:01:01
 Epoch: 246, lr: 4.0e-04, train_loss: 0.2366, train_acc: 0.9160 test_loss: 0.9953, test_acc: 0.7804, best: 0.7877, time: 0:01:01
 Epoch: 247, lr: 4.0e-04, train_loss: 0.2139, train_acc: 0.9250 test_loss: 0.9930, test_acc: 0.7776, best: 0.7877, time: 0:01:00
 Epoch: 248, lr: 4.0e-04, train_loss: 0.2296, train_acc: 0.9220 test_loss: 0.9769, test_acc: 0.7784, best: 0.7877, time: 0:01:00
 Epoch: 249, lr: 4.0e-04, train_loss: 0.2216, train_acc: 0.9218 test_loss: 1.0002, test_acc: 0.7760, best: 0.7877, time: 0:01:01
 Epoch: 250, lr: 4.0e-04, train_loss: 0.2279, train_acc: 0.9192 test_loss: 0.9989, test_acc: 0.7780, best: 0.7877, time: 0:01:01
 Epoch: 251, lr: 4.0e-04, train_loss: 0.2153, train_acc: 0.9256 test_loss: 1.0085, test_acc: 0.7810, best: 0.7877, time: 0:01:01
 Epoch: 252, lr: 4.0e-04, train_loss: 0.2184, train_acc: 0.9228 test_loss: 1.0044, test_acc: 0.7805, best: 0.7877, time: 0:01:01
 Epoch: 253, lr: 4.0e-04, train_loss: 0.2115, train_acc: 0.9264 test_loss: 0.9946, test_acc: 0.7809, best: 0.7877, time: 0:01:01
 Epoch: 254, lr: 4.0e-04, train_loss: 0.2254, train_acc: 0.9210 test_loss: 1.0118, test_acc: 0.7794, best: 0.7877, time: 0:01:00
 Epoch: 255, lr: 4.0e-04, train_loss: 0.2101, train_acc: 0.9274 test_loss: 0.9916, test_acc: 0.7800, best: 0.7877, time: 0:01:00
 Epoch: 256, lr: 4.0e-04, train_loss: 0.2333, train_acc: 0.9244 test_loss: 1.0114, test_acc: 0.7804, best: 0.7877, time: 0:01:00
 Epoch: 257, lr: 4.0e-04, train_loss: 0.2296, train_acc: 0.9226 test_loss: 1.0178, test_acc: 0.7794, best: 0.7877, time: 0:01:01
 Epoch: 258, lr: 4.0e-04, train_loss: 0.2005, train_acc: 0.9284 test_loss: 0.9656, test_acc: 0.7851, best: 0.7877, time: 0:01:01
 Epoch: 259, lr: 4.0e-04, train_loss: 0.2260, train_acc: 0.9244 test_loss: 0.9963, test_acc: 0.7821, best: 0.7877, time: 0:01:01
 Epoch: 260, lr: 4.0e-04, train_loss: 0.2175, train_acc: 0.9258 test_loss: 0.9841, test_acc: 0.7837, best: 0.7877, time: 0:00:59
 Epoch: 261, lr: 4.0e-04, train_loss: 0.2241, train_acc: 0.9214 test_loss: 0.9721, test_acc: 0.7845, best: 0.7877, time: 0:00:59
 Epoch: 262, lr: 4.0e-04, train_loss: 0.2283, train_acc: 0.9224 test_loss: 0.9742, test_acc: 0.7833, best: 0.7877, time: 0:00:58
 Epoch: 263, lr: 4.0e-04, train_loss: 0.2236, train_acc: 0.9256 test_loss: 0.9701, test_acc: 0.7801, best: 0.7877, time: 0:00:58
 Epoch: 264, lr: 4.0e-04, train_loss: 0.2129, train_acc: 0.9296 test_loss: 0.9862, test_acc: 0.7821, best: 0.7877, time: 0:00:59
 Epoch: 265, lr: 4.0e-04, train_loss: 0.2193, train_acc: 0.9268 test_loss: 0.9889, test_acc: 0.7823, best: 0.7877, time: 0:00:58
 Epoch: 266, lr: 4.0e-04, train_loss: 0.2277, train_acc: 0.9210 test_loss: 0.9869, test_acc: 0.7784, best: 0.7877, time: 0:00:59
 Epoch: 267, lr: 4.0e-04, train_loss: 0.2212, train_acc: 0.9224 test_loss: 0.9584, test_acc: 0.7823, best: 0.7877, time: 0:00:58
 Epoch: 268, lr: 4.0e-04, train_loss: 0.2130, train_acc: 0.9282 test_loss: 0.9844, test_acc: 0.7839, best: 0.7877, time: 0:00:59
 Epoch: 269, lr: 4.0e-04, train_loss: 0.2085, train_acc: 0.9288 test_loss: 0.9949, test_acc: 0.7785, best: 0.7877, time: 0:00:58
 Epoch: 270, lr: 8.0e-05, train_loss: 0.2196, train_acc: 0.9262 test_loss: 0.9753, test_acc: 0.7819, best: 0.7877, time: 0:00:59
 Epoch: 271, lr: 8.0e-05, train_loss: 0.2102, train_acc: 0.9308 test_loss: 0.9996, test_acc: 0.7847, best: 0.7877, time: 0:00:58
 Epoch: 272, lr: 8.0e-05, train_loss: 0.2144, train_acc: 0.9260 test_loss: 0.9888, test_acc: 0.7833, best: 0.7877, time: 0:00:56
 Epoch: 273, lr: 8.0e-05, train_loss: 0.2070, train_acc: 0.9312 test_loss: 0.9927, test_acc: 0.7802, best: 0.7877, time: 0:00:54
 Epoch: 274, lr: 8.0e-05, train_loss: 0.2225, train_acc: 0.9234 test_loss: 0.9856, test_acc: 0.7799, best: 0.7877, time: 0:00:53
 Epoch: 275, lr: 8.0e-05, train_loss: 0.2029, train_acc: 0.9298 test_loss: 0.9882, test_acc: 0.7817, best: 0.7877, time: 0:00:53
 Epoch: 276, lr: 8.0e-05, train_loss: 0.2082, train_acc: 0.9304 test_loss: 1.0105, test_acc: 0.7823, best: 0.7877, time: 0:00:53
 Epoch: 277, lr: 8.0e-05, train_loss: 0.2330, train_acc: 0.9206 test_loss: 1.0262, test_acc: 0.7800, best: 0.7877, time: 0:00:53
 Epoch: 278, lr: 8.0e-05, train_loss: 0.1960, train_acc: 0.9310 test_loss: 0.9767, test_acc: 0.7846, best: 0.7877, time: 0:00:53
 Epoch: 279, lr: 8.0e-05, train_loss: 0.2310, train_acc: 0.9194 test_loss: 0.9614, test_acc: 0.7860, best: 0.7877, time: 0:00:53
 Epoch: 280, lr: 8.0e-05, train_loss: 0.1977, train_acc: 0.9280 test_loss: 1.0076, test_acc: 0.7833, best: 0.7877, time: 0:00:53
 Epoch: 281, lr: 8.0e-05, train_loss: 0.2151, train_acc: 0.9256 test_loss: 0.9798, test_acc: 0.7831, best: 0.7877, time: 0:00:53
 Epoch: 282, lr: 8.0e-05, train_loss: 0.2141, train_acc: 0.9250 test_loss: 0.9821, test_acc: 0.7791, best: 0.7877, time: 0:00:54
 Epoch: 283, lr: 8.0e-05, train_loss: 0.1943, train_acc: 0.9314 test_loss: 0.9889, test_acc: 0.7827, best: 0.7877, time: 0:00:54
 Epoch: 284, lr: 8.0e-05, train_loss: 0.2327, train_acc: 0.9198 test_loss: 0.9711, test_acc: 0.7844, best: 0.7877, time: 0:00:55
 Epoch: 285, lr: 8.0e-05, train_loss: 0.2097, train_acc: 0.9286 test_loss: 1.0249, test_acc: 0.7804, best: 0.7877, time: 0:00:55
 Epoch: 286, lr: 8.0e-05, train_loss: 0.2164, train_acc: 0.9238 test_loss: 1.0063, test_acc: 0.7812, best: 0.7877, time: 0:00:55
 Epoch: 287, lr: 8.0e-05, train_loss: 0.2126, train_acc: 0.9242 test_loss: 0.9845, test_acc: 0.7831, best: 0.7877, time: 0:00:55
 Epoch: 288, lr: 8.0e-05, train_loss: 0.2235, train_acc: 0.9172 test_loss: 0.9773, test_acc: 0.7857, best: 0.7877, time: 0:00:56
 Epoch: 289, lr: 8.0e-05, train_loss: 0.2101, train_acc: 0.9288 test_loss: 1.0112, test_acc: 0.7837, best: 0.7877, time: 0:00:56
 Epoch: 290, lr: 8.0e-05, train_loss: 0.2039, train_acc: 0.9276 test_loss: 1.0153, test_acc: 0.7830, best: 0.7877, time: 0:00:56
 Epoch: 291, lr: 8.0e-05, train_loss: 0.2100, train_acc: 0.9290 test_loss: 0.9682, test_acc: 0.7834, best: 0.7877, time: 0:00:55
 Epoch: 292, lr: 8.0e-05, train_loss: 0.2027, train_acc: 0.9310 test_loss: 1.0102, test_acc: 0.7819, best: 0.7877, time: 0:00:56
 Epoch: 293, lr: 8.0e-05, train_loss: 0.2029, train_acc: 0.9308 test_loss: 0.9970, test_acc: 0.7826, best: 0.7877, time: 0:00:55
 Epoch: 294, lr: 8.0e-05, train_loss: 0.2227, train_acc: 0.9258 test_loss: 1.0182, test_acc: 0.7784, best: 0.7877, time: 0:00:59
 Epoch: 295, lr: 8.0e-05, train_loss: 0.2170, train_acc: 0.9230 test_loss: 0.9820, test_acc: 0.7854, best: 0.7877, time: 0:01:03
 Epoch: 296, lr: 8.0e-05, train_loss: 0.1918, train_acc: 0.9358 test_loss: 0.9957, test_acc: 0.7804, best: 0.7877, time: 0:01:03
 Epoch: 297, lr: 8.0e-05, train_loss: 0.2032, train_acc: 0.9282 test_loss: 0.9826, test_acc: 0.7815, best: 0.7877, time: 0:01:03
 Epoch: 298, lr: 8.0e-05, train_loss: 0.2064, train_acc: 0.9288 test_loss: 1.0008, test_acc: 0.7851, best: 0.7877, time: 0:01:03
 Epoch: 299, lr: 8.0e-05, train_loss: 0.2174, train_acc: 0.9266 test_loss: 1.0146, test_acc: 0.7829, best: 0.7877, time: 0:01:02
 Highest accuracy: 0.7877