
 Run on time: 2022-07-13 00:16:50.818907

 Architecture: resnet18-nlpnoexp_headfix2_nowin-2222

 Pool Config: {
    "arch": "resnet18",
    "conv1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "pool": {
        "_conv2d": null,
        "pool_cfg": {
            "_ptype": "maxp",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer2": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer3": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer4": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnoexp",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    }
}

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : resnet18-nlpnoexp_headfix2_nowin-2222
	 im_size              : 128
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): Network(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 32)
                (col_embed): Embedding(256, 32)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 64)
                (col_embed): Embedding(256, 64)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 128)
                (col_embed): Embedding(256, 128)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
              (pos_embed): PositionEmbeddingLearned(
                (row_embed): Embedding(256, 256)
                (col_embed): Embedding(256, 256)
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.1740, train_acc: 0.2016 test_loss: 1.8090, test_acc: 0.3186, best: 0.3186, time: 0:00:58
 Epoch: 2, lr: 1.0e-02, train_loss: 1.9635, train_acc: 0.2400 test_loss: 1.8869, test_acc: 0.2955, best: 0.3186, time: 0:00:59
 Epoch: 3, lr: 1.0e-02, train_loss: 1.8659, train_acc: 0.2894 test_loss: 1.6182, test_acc: 0.3724, best: 0.3724, time: 0:01:01
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8265, train_acc: 0.3118 test_loss: 1.6387, test_acc: 0.3644, best: 0.3724, time: 0:01:00
 Epoch: 5, lr: 1.0e-02, train_loss: 1.7863, train_acc: 0.3200 test_loss: 1.6406, test_acc: 0.3830, best: 0.3830, time: 0:01:01
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7475, train_acc: 0.3482 test_loss: 1.5745, test_acc: 0.4101, best: 0.4101, time: 0:01:00
 Epoch: 7, lr: 1.0e-02, train_loss: 1.7360, train_acc: 0.3506 test_loss: 1.5338, test_acc: 0.4074, best: 0.4101, time: 0:01:00
 Epoch: 8, lr: 1.0e-02, train_loss: 1.6646, train_acc: 0.3798 test_loss: 1.4127, test_acc: 0.4639, best: 0.4639, time: 0:01:00
 Epoch: 9, lr: 1.0e-02, train_loss: 1.6154, train_acc: 0.4038 test_loss: 1.4346, test_acc: 0.4606, best: 0.4639, time: 0:01:00
 Epoch: 10, lr: 1.0e-02, train_loss: 1.5698, train_acc: 0.4210 test_loss: 1.3268, test_acc: 0.5008, best: 0.5008, time: 0:01:00
 Epoch: 11, lr: 1.0e-02, train_loss: 1.5406, train_acc: 0.4308 test_loss: 1.3288, test_acc: 0.5092, best: 0.5092, time: 0:01:00
 Epoch: 12, lr: 1.0e-02, train_loss: 1.4768, train_acc: 0.4544 test_loss: 1.3137, test_acc: 0.5139, best: 0.5139, time: 0:01:00
 Epoch: 13, lr: 1.0e-02, train_loss: 1.4470, train_acc: 0.4732 test_loss: 1.3603, test_acc: 0.5066, best: 0.5139, time: 0:01:00
 Epoch: 14, lr: 1.0e-02, train_loss: 1.4137, train_acc: 0.4806 test_loss: 1.2316, test_acc: 0.5497, best: 0.5497, time: 0:01:00
 Epoch: 15, lr: 1.0e-02, train_loss: 1.3688, train_acc: 0.5032 test_loss: 1.2457, test_acc: 0.5524, best: 0.5524, time: 0:01:00
 Epoch: 16, lr: 1.0e-02, train_loss: 1.3604, train_acc: 0.5046 test_loss: 1.2711, test_acc: 0.5346, best: 0.5524, time: 0:01:00
 Epoch: 17, lr: 1.0e-02, train_loss: 1.3236, train_acc: 0.5168 test_loss: 1.2428, test_acc: 0.5576, best: 0.5576, time: 0:01:00
 Epoch: 18, lr: 1.0e-02, train_loss: 1.2961, train_acc: 0.5258 test_loss: 1.1709, test_acc: 0.5685, best: 0.5685, time: 0:01:00
 Epoch: 19, lr: 1.0e-02, train_loss: 1.2946, train_acc: 0.5230 test_loss: 1.1997, test_acc: 0.5640, best: 0.5685, time: 0:01:00
 Epoch: 20, lr: 1.0e-02, train_loss: 1.2565, train_acc: 0.5418 test_loss: 1.1120, test_acc: 0.5941, best: 0.5941, time: 0:01:00
 Epoch: 21, lr: 1.0e-02, train_loss: 1.2340, train_acc: 0.5508 test_loss: 1.1257, test_acc: 0.5883, best: 0.5941, time: 0:01:00
 Epoch: 22, lr: 1.0e-02, train_loss: 1.1957, train_acc: 0.5622 test_loss: 1.1648, test_acc: 0.5921, best: 0.5941, time: 0:01:00
 Epoch: 23, lr: 1.0e-02, train_loss: 1.1799, train_acc: 0.5730 test_loss: 1.1163, test_acc: 0.5979, best: 0.5979, time: 0:01:00
 Epoch: 24, lr: 1.0e-02, train_loss: 1.1640, train_acc: 0.5794 test_loss: 1.0136, test_acc: 0.6326, best: 0.6326, time: 0:01:00
 Epoch: 25, lr: 1.0e-02, train_loss: 1.1422, train_acc: 0.5828