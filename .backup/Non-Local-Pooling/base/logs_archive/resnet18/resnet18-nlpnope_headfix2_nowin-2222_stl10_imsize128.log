
 Run on time: 2022-07-13 00:18:09.180655

 Architecture: resnet18-nlpnope_headfix2_nowin-2222

 Pool Config: {
    "arch": "resnet18",
    "conv1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "skip",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "pool": {
        "_conv2d": null,
        "pool_cfg": {
            "_ptype": "maxp",
            "_stride": 2,
            "_psize": null,
            "_dim_reduced_ratio": null,
            "_num_heads": null,
            "_conv2d": null,
            "_win_norm": null
        }
    },
    "layer1": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnope",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer2": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnope",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer3": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnope",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    },
    "layer4": {
        "_conv2d": "norm",
        "pool_cfg": {
            "_ptype": "nlpnope",
            "_stride": 2,
            "_psize": 1,
            "_dim_reduced_ratio": 1,
            "_num_heads": 2,
            "_conv2d": "norm",
            "_win_norm": false
        }
    }
}

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : resnet18-nlpnope_headfix2_nowin-2222
	 im_size              : 128
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): Network(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (pool): Pool2d(
          (logit): Sequential(
            (pool_weight): NLP_BASE(
              (downsample): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (restore): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Sigmoid()
              )
            )
          )
          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 2.5148, train_acc: 0.1808 test_loss: 1.8782, test_acc: 0.2684, best: 0.2684, time: 0:00:58
 Epoch: 2, lr: 1.0e-02, train_loss: 1.9876, train_acc: 0.2508 test_loss: 1.7604, test_acc: 0.2963, best: 0.2963, time: 0:00:58
 Epoch: 3, lr: 1.0e-02, train_loss: 1.9147, train_acc: 0.2734 test_loss: 1.7749, test_acc: 0.3199, best: 0.3199, time: 0:00:58
 Epoch: 4, lr: 1.0e-02, train_loss: 1.8372, train_acc: 0.3014 test_loss: 1.6054, test_acc: 0.3795, best: 0.3795, time: 0:00:58
 Epoch: 5, lr: 1.0e-02, train_loss: 1.7861, train_acc: 0.3270 test_loss: 1.6522, test_acc: 0.3802, best: 0.3802, time: 0:00:58
 Epoch: 6, lr: 1.0e-02, train_loss: 1.7492, train_acc: 0.3460 test_loss: 1.6373, test_acc: 0.3821, best: 0.3821, time: 0:00:58
 Epoch: 7, lr: 1.0e-02, train_loss: 1.6885, train_acc: 0.3762 test_loss: 1.5106, test_acc: 0.4386, best: 0.4386, time: 0:00:58
 Epoch: 8, lr: 1.0e-02, train_loss: 1.6362, train_acc: 0.3870 test_loss: 1.4613, test_acc: 0.4641, best: 0.4641, time: 0:00:58
 Epoch: 9, lr: 1.0e-02, train_loss: 1.5985, train_acc: 0.4130 test_loss: 1.4670, test_acc: 0.4657, best: 0.4657, time: 0:00:58
 Epoch: 10, lr: 1.0e-02, train_loss: 1.5645, train_acc: 0.4178 test_loss: 1.4842, test_acc: 0.4617, best: 0.4657, time: 0:00:58
 Epoch: 11, lr: 1.0e-02, train_loss: 1.5291, train_acc: 0.4366 test_loss: 1.4080, test_acc: 0.5078, best: 0.5078, time: 0:00:58
 Epoch: 12, lr: 1.0e-02, train_loss: 1.4799, train_acc: 0.4610 test_loss: 1.3827, test_acc: 0.4954, best: 0.5078, time: 0:00:58
 Epoch: 13, lr: 1.0e-02, train_loss: 1.4227, train_acc: 0.4814 test_loss: 1.2710, test_acc: 0.5429, best: 0.5429, time: 0:00:58
 Epoch: 14, lr: 1.0e-02, train_loss: 1.3810, train_acc: 0.4954 test_loss: 1.2790, test_acc: 0.5387, best: 0.5429, time: 0:00:58
 Epoch: 15, lr: 1.0e-02, train_loss: 1.4106, train_acc: 0.4852 test_loss: 1.3170, test_acc: 0.5349, best: 0.5429, time: 0:00:58
 Epoch: 16, lr: 1.0e-02, train_loss: 1.3469, train_acc: 0.5120 test_loss: 1.2965, test_acc: 0.5727, best: 0.5727, time: 0:00:58
 Epoch: 17, lr: 1.0e-02, train_loss: 1.3080, train_acc: 0.5210 test_loss: 1.2398, test_acc: 0.5566, best: 0.5727, time: 0:00:58
 Epoch: 18, lr: 1.0e-02, train_loss: 1.2679, train_acc: 0.5360 test_loss: 1.3615, test_acc: 0.5295, best: 0.5727, time: 0:00:58
 Epoch: 19, lr: 1.0e-02, train_loss: 1.2667, train_acc: 0.5314 test_loss: 1.1952, test_acc: 0.5786, best: 0.5786, time: 0:00:58
 Epoch: 20, lr: 1.0e-02, train_loss: 1.2351, train_acc: 0.5488 test_loss: 1.1224, test_acc: 0.6000, best: 0.6000, time: 0:00:58
 Epoch: 21, lr: 1.0e-02, train_loss: 1.1942, train_acc: 0.5724 test_loss: 1.2231, test_acc: 0.5743, best: 0.6000, time: 0:00:58
 Epoch: 22, lr: 1.0e-02, train_loss: 1.1969, train_acc: 0.5698 test_loss: 1.2960, test_acc: 0.5740, best: 0.6000, time: 0:00:58
 Epoch: 23, lr: 1.0e-02, train_loss: 1.1816, train_acc: 0.5690 test_loss: 1.1839, test_acc: 0.5876, best: 0.6000, time: 0:00:58
 Epoch: 24, lr: 1.0e-02, train_loss: 1.1387, train_acc: 0.5906 test_loss: 1.0673, test_acc: 0.6194, best: 0.6194, time: 0:00:58
 Epoch: 25, lr: 1.0e-02, train_loss: 1.1367, train_acc: 0.5896