
 Run on time: 2022-06-29 16:00:49.146355

 Arguments:
	 gpu                  : True
	 log                  : True
	 seed                 : 0
	 momentum             : 0.9
	 amsgrad              : True
	 dataset              : STL10
	 batch_size           : 8
	 architecture         : RESNET18_4222
	 im_size              : 128
	 relu_threshold       : 4.0
	 learning_rate        : 0.01
	 pretrained_backbone  : 
	 pretrained_ann       : 
	 weight_decay         : 0.0
	 test_only            : False
	 epochs               : 300
	 lr_interval          : [180, 240, 270]
	 lr_reduce            : 5
	 optimizer            : SGD
	 dropout              : 0.2
	 kernel_size          : 3
	 dont_save            : False
	 visualize            : False
	 devices              : 0
 DataParallel(
  (module): NetworkByName(
    (net): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(4, 4), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer2): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer3): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (layer4): Sequential(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=512, out_features=10, bias=True)
    )
  )
)
 SGD (
Parameter Group 0
    dampening: 0
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0
)
 Epoch: 1, lr: 1.0e-02, train_loss: 3.1888, train_acc: 0.1604 test_loss: 2.4139, test_acc: 0.2467, best: 0.2467, time: 0:00:58
 Epoch: 2, lr: 1.0e-02, train_loss: 2.3154, train_acc: 0.1980 test_loss: 2.0516, test_acc: 0.2515, best: 0.2515, time: 0:00:58
 Epoch: 3, lr: 1.0e-02, train_loss: 2.0895, train_acc: 0.2216 test_loss: 1.8389, test_acc: 0.2939, best: 0.2939, time: 0:00:59
 Epoch: 4, lr: 1.0e-02, train_loss: 2.0217, train_acc: 0.2414 test_loss: 1.7882, test_acc: 0.2894, best: 0.2939, time: 0:00:59
 Epoch: 5, lr: 1.0e-02, train_loss: 1.9561, train_acc: 0.2646 test_loss: 1.8250, test_acc: 0.3227, best: 0.3227, time: 0:00:57
 Epoch: 6, lr: 1.0e-02, train_loss: 1.9398, train_acc: 0.2620 test_loss: 1.8256, test_acc: 0.3635, best: 0.3635, time: 0:00:58
 Epoch: 7, lr: 1.0e-02, train_loss: 1.9060, train_acc: 0.2826 test_loss: 1.7505, test_acc: 0.3590, best: 0.3635, time: 0:00:58
 Epoch: 8, lr: 1.0e-02, train_loss: 1.9055, train_acc: 0.2706 test_loss: 1.8142, test_acc: 0.3385, best: 0.3635, time: 0:00:57
 Epoch: 9, lr: 1.0e-02, train_loss: 1.8666, train_acc: 0.3028 test_loss: 1.6619, test_acc: 0.3795, best: 0.3795, time: 0:00:57
 Epoch: 10, lr: 1.0e-02, train_loss: 1.9172, train_acc: 0.2846 test_loss: 1.7035, test_acc: 0.3723, best: 0.3795, time: 0:00:57
 Epoch: 11, lr: 1.0e-02, train_loss: 1.9072, train_acc: 0.2900 test_loss: 1.7499, test_acc: 0.3225, best: 0.3795, time: 0:00:59
 Epoch: 12, lr: 1.0e-02, train_loss: 1.8983, train_acc: 0.2862 test_loss: 1.6390, test_acc: 0.3761, best: 0.3795, time: 0:00:58
 Epoch: 13, lr: 1.0e-02, train_loss: 1.8484, train_acc: 0.2958 test_loss: 1.7785, test_acc: 0.3194, best: 0.3795, time: 0:00:57
 Epoch: 14, lr: 1.0e-02, train_loss: 1.9124, train_acc: 0.2734 test_loss: 1.7315, test_acc: 0.3376, best: 0.3795, time: 0:00:57
 Epoch: 15, lr: 1.0e-02, train_loss: 1.8627, train_acc: 0.3032 test_loss: 1.5885, test_acc: 0.3961, best: 0.3961, time: 0:00:58
 Epoch: 16, lr: 1.0e-02, train_loss: 1.8388, train_acc: 0.3074 test_loss: 1.6588, test_acc: 0.3767, best: 0.3961, time: 0:00:58
 Epoch: 17, lr: 1.0e-02, train_loss: 1.8174, train_acc: 0.3118 test_loss: 1.5996, test_acc: 0.3809, best: 0.3961, time: 0:00:58
 Epoch: 18, lr: 1.0e-02, train_loss: 1.8244, train_acc: 0.3144 test_loss: 1.7446, test_acc: 0.3402, best: 0.3961, time: 0:00:59
 Epoch: 19, lr: 1.0e-02, train_loss: 1.8443, train_acc: 0.3144 test_loss: 1.6642, test_acc: 0.3676, best: 0.3961, time: 0:00:58
 Epoch: 20, lr: 1.0e-02, train_loss: 1.8327, train_acc: 0.3060 test_loss: 1.6314, test_acc: 0.3765, best: 0.3961, time: 0:00:58
 Epoch: 21, lr: 1.0e-02, train_loss: 1.7982, train_acc: 0.3236 test_loss: 1.6289, test_acc: 0.3996, best: 0.3996, time: 0:00:59
 Epoch: 22, lr: 1.0e-02, train_loss: 1.8809, train_acc: 0.2906 test_loss: 1.8679, test_acc: 0.3310, best: 0.3996, time: 0:00:58
 Epoch: 23, lr: 1.0e-02, train_loss: 1.8479, train_acc: 0.3158 test_loss: 1.6945, test_acc: 0.3490, best: 0.3996, time: 0:00:57
 Epoch: 24, lr: 1.0e-02, train_loss: 1.8488, train_acc: 0.3024 test_loss: 1.6136, test_acc: 0.3857, best: 0.3996, time: 0:00:56
 Epoch: 25, lr: 1.0e-02, train_loss: 1.8308, train_acc: 0.3126 test_loss: 1.6501, test_acc: 0.3849, best: 0.3996, time: 0:00:57
 Epoch: 26, lr: 1.0e-02, train_loss: 1.8057, train_acc: 0.3268 test_loss: 1.5874, test_acc: 0.3911, best: 0.3996, time: 0:00:58
 Epoch: 27, lr: 1.0e-02, train_loss: 1.7742, train_acc: 0.3394 test_loss: 1.5871, test_acc: 0.4091, best: 0.4091, time: 0:00:59
 Epoch: 28, lr: 1.0e-02, train_loss: 1.7650, train_acc: 0.3368 test_loss: 1.5839, test_acc: 0.4030, best: 0.4091, time: 0:00:58
 Epoch: 29, lr: 1.0e-02, train_loss: 1.7547, train_acc: 0.3416 test_loss: 2.7120, test_acc: 0.3427, best: 0.4091, time: 0:01:03
 Epoch: 30, lr: 1.0e-02, train_loss: 1.7374, train_acc: 0.3460 test_loss: 1.7497, test_acc: 0.4029, best: 0.4091, time: 0:00:57
 Epoch: 31, lr: 1.0e-02, train_loss: 1.6887, train_acc: 0.3538 test_loss: 1.7944, test_acc: 0.3992, best: 0.4091, time: 0:00:58
 Epoch: 32, lr: 1.0e-02, train_loss: 1.6931, train_acc: 0.3706 test_loss: 1.7473, test_acc: 0.4075, best: 0.4091, time: 0:01:00
 Epoch: 33, lr: 1.0e-02, train_loss: 1.7037, train_acc: 0.3474 test_loss: 2.0878, test_acc: 0.4049, best: 0.4091, time: 0:00:57
 Epoch: 34, lr: 1.0e-02, train_loss: 1.7314, train_acc: 0.3584 test_loss: 2.4598, test_acc: 0.3802, best: 0.4091, time: 0:00:58
 Epoch: 35, lr: 1.0e-02, train_loss: 1.7105, train_acc: 0.3602 test_loss: 3.5130, test_acc: 0.3831, best: 0.4091, time: 0:00:57
 Epoch: 36, lr: 1.0e-02, train_loss: 1.6859, train_acc: 0.3638 test_loss: 1.7387, test_acc: 0.4246, best: 0.4246, time: 0:00:58
 Epoch: 37, lr: 1.0e-02, train_loss: 1.7001, train_acc: 0.3558 test_loss: 1.8571, test_acc: 0.3995, best: 0.4246, time: 0:00:59
 Epoch: 38, lr: 1.0e-02, train_loss: 1.6705, train_acc: 0.3662 test_loss: 1.5978, test_acc: 0.4366, best: 0.4366, time: 0:00:57
 Epoch: 39, lr: 1.0e-02, train_loss: 1.6532, train_acc: 0.3806 test_loss: 1.6078, test_acc: 0.4231, best: 0.4366, time: 0:01:02
 Epoch: 40, lr: 1.0e-02, train_loss: 1.7467, train_acc: 0.3432 test_loss: 1.5322, test_acc: 0.4314, best: 0.4366, time: 0:01:00
 Epoch: 41, lr: 1.0e-02, train_loss: 1.6731, train_acc: 0.3776 test_loss: 1.6980, test_acc: 0.3641, best: 0.4366, time: 0:00:59
 Epoch: 42, lr: 1.0e-02, train_loss: 1.7141, train_acc: 0.3586 test_loss: 1.5962, test_acc: 0.4208, best: 0.4366, time: 0:00:57
 Epoch: 43, lr: 1.0e-02, train_loss: 1.6949, train_acc: 0.3578 test_loss: 1.5881, test_acc: 0.4420, best: 0.4420, time: 0:00:57
 Epoch: 44, lr: 1.0e-02, train_loss: 1.6448, train_acc: 0.3912 test_loss: 1.5130, test_acc: 0.4587, best: 0.4587, time: 0:00:57
 Epoch: 45, lr: 1.0e-02, train_loss: 1.6237, train_acc: 0.3902 test_loss: 1.5114, test_acc: 0.4617, best: 0.4617, time: 0:00:58
 Epoch: 46, lr: 1.0e-02, train_loss: 1.6279, train_acc: 0.3884 test_loss: 1.5473, test_acc: 0.4531, best: 0.4617, time: 0:00:56
 Epoch: 47, lr: 1.0e-02, train_loss: 1.6050, train_acc: 0.4080 test_loss: 1.4468, test_acc: 0.4645, best: 0.4645, time: 0:00:59
 Epoch: 48, lr: 1.0e-02, train_loss: 1.5904, train_acc: 0.4152 test_loss: 1.4282, test_acc: 0.4672, best: 0.4672, time: 0:00:59
 Epoch: 49, lr: 1.0e-02, train_loss: 1.5753, train_acc: 0.4178 test_loss: 1.4450, test_acc: 0.4843, best: 0.4843, time: 0:00:57
 Epoch: 50, lr: 1.0e-02, train_loss: 1.5814, train_acc: 0.4042 test_loss: 1.5165, test_acc: 0.4375, best: 0.4843, time: 0:00:56
 Epoch: 51, lr: 1.0e-02, train_loss: 1.6673, train_acc: 0.3784 test_loss: 1.4739, test_acc: 0.4575, best: 0.4843, time: 0:00:57
 Epoch: 52, lr: 1.0e-02, train_loss: 1.6463, train_acc: 0.3896 test_loss: 2.1430, test_acc: 0.4179, best: 0.4843, time: 0:00:59
 Epoch: 53, lr: 1.0e-02, train_loss: 1.6332, train_acc: 0.3928 test_loss: 1.7339, test_acc: 0.4355, best: 0.4843, time: 0:00:59
 Epoch: 54, lr: 1.0e-02, train_loss: 1.6242, train_acc: 0.3966 test_loss: 1.7628, test_acc: 0.4481, best: 0.4843, time: 0:00:59
 Epoch: 55, lr: 1.0e-02, train_loss: 1.6015, train_acc: 0.4010 test_loss: 1.4924, test_acc: 0.4698, best: 0.4843, time: 0:01:00
 Epoch: 56, lr: 1.0e-02, train_loss: 1.5732, train_acc: 0.4164 test_loss: 1.6675, test_acc: 0.4719, best: 0.4843, time: 0:00:57
 Epoch: 57, lr: 1.0e-02, train_loss: 1.5610, train_acc: 0.4276 test_loss: 1.3673, test_acc: 0.5068, best: 0.5068, time: 0:01:01
 Epoch: 58, lr: 1.0e-02, train_loss: 1.5472, train_acc: 0.4134 test_loss: 1.3344, test_acc: 0.5072, best: 0.5072, time: 0:00:58
 Epoch: 59, lr: 1.0e-02, train_loss: 1.5240, train_acc: 0.4362 test_loss: 1.8902, test_acc: 0.4519, best: 0.5072, time: 0:00:57
 Epoch: 60, lr: 1.0e-02, train_loss: 1.5382, train_acc: 0.4172 test_loss: 1.6022, test_acc: 0.4821, best: 0.5072, time: 0:01:00
 Epoch: 61, lr: 1.0e-02, train_loss: 1.5346, train_acc: 0.4418 test_loss: 3.6605, test_acc: 0.4148, best: 0.5072, time: 0:00:57
 Epoch: 62, lr: 1.0e-02, train_loss: 1.5163, train_acc: 0.4424 test_loss: 1.3475, test_acc: 0.5075, best: 0.5075, time: 0:00:59
 Epoch: 63, lr: 1.0e-02, train_loss: 1.4838, train_acc: 0.4564 test_loss: 1.3918, test_acc: 0.5064, best: 0.5075, time: 0:00:57
 Epoch: 64, lr: 1.0e-02, train_loss: 1.5112, train_acc: 0.4406 test_loss: 1.4968, test_acc: 0.5078, best: 0.5078, time: 0:01:06
 Epoch: 65, lr: 1.0e-02, train_loss: 1.4986, train_acc: 0.4434 test_loss: 1.3498, test_acc: 0.5200, best: 0.5200, time: 0:01:06
 Epoch: 66, lr: 1.0e-02, train_loss: 1.5408, train_acc: 0.4398 test_loss: 1.3589, test_acc: 0.4925, best: 0.5200, time: 0:00:58
 Epoch: 67, lr: 1.0e-02, train_loss: 1.4997, train_acc: 0.4478 test_loss: 1.5001, test_acc: 0.4899, best: 0.5200, time: 0:00:58
 Epoch: 68, lr: 1.0e-02, train_loss: 1.4887, train_acc: 0.4488 test_loss: 1.3683, test_acc: 0.5048, best: 0.5200, time: 0:00:57
 Epoch: 69, lr: 1.0e-02, train_loss: 1.4638, train_acc: 0.4542 test_loss: 1.2888, test_acc: 0.5301, best: 0.5301, time: 0:01:00
 Epoch: 70, lr: 1.0e-02, train_loss: 1.4557, train_acc: 0.4716 test_loss: 1.3157, test_acc: 0.5238, best: 0.5301, time: 0:00:59
 Epoch: 71, lr: 1.0e-02, train_loss: 1.4772, train_acc: 0.4602 test_loss: 1.3377, test_acc: 0.5159, best: 0.5301, time: 0:00:57
 Epoch: 72, lr: 1.0e-02, train_loss: 1.5103, train_acc: 0.4414 test_loss: 1.3969, test_acc: 0.5009, best: 0.5301, time: 0:00:59
 Epoch: 73, lr: 1.0e-02, train_loss: 1.5256, train_acc: 0.4384 test_loss: 1.4138, test_acc: 0.4831, best: 0.5301, time: 0:00:58
 Epoch: 74, lr: 1.0e-02, train_loss: 1.4885, train_acc: 0.4524 test_loss: 1.3311, test_acc: 0.5165, best: 0.5301, time: 0:00:57
 Epoch: 75, lr: 1.0e-02, train_loss: 1.4644, train_acc: 0.4684 test_loss: 1.2038, test_acc: 0.5620, best: 0.5620, time: 0:00:56
 Epoch: 76, lr: 1.0e-02, train_loss: 1.4738, train_acc: 0.4588 test_loss: 1.3010, test_acc: 0.5261, best: 0.5620, time: 0:00:58
 Epoch: 77, lr: 1.0e-02, train_loss: 1.4813, train_acc: 0.4532 test_loss: 1.2390, test_acc: 0.5541, best: 0.5620, time: 0:00:57
 Epoch: 78, lr: 1.0e-02, train_loss: 1.4861, train_acc: 0.4568 test_loss: 1.2866, test_acc: 0.5345, best: 0.5620, time: 0:00:56
 Epoch: 79, lr: 1.0e-02, train_loss: 1.4165, train_acc: 0.4808 test_loss: 1.2758, test_acc: 0.5456, best: 0.5620, time: 0:00:57
 Epoch: 80, lr: 1.0e-02, train_loss: 1.4274, train_acc: 0.4846 test_loss: 1.2570, test_acc: 0.5433, best: 0.5620, time: 0:00:59
 Epoch: 81, lr: 1.0e-02, train_loss: 1.4171, train_acc: 0.4890 test_loss: 1.3760, test_acc: 0.5433, best: 0.5620, time: 0:00:57
 Epoch: 82, lr: 1.0e-02, train_loss: 1.3968, train_acc: 0.4918 test_loss: 1.1797, test_acc: 0.5706, best: 0.5706, time: 0:00:58
 Epoch: 83, lr: 1.0e-02, train_loss: 1.4041, train_acc: 0.4794 test_loss: 1.2034, test_acc: 0.5616, best: 0.5706, time: 0:01:00
 Epoch: 84, lr: 1.0e-02, train_loss: 1.4186, train_acc: 0.4776 test_loss: 1.2435, test_acc: 0.5365, best: 0.5706, time: 0:00:56
 Epoch: 85, lr: 1.0e-02, train_loss: 1.3916, train_acc: 0.4934 test_loss: 1.2392, test_acc: 0.5516, best: 0.5706, time: 0:01:02
 Epoch: 86, lr: 1.0e-02, train_loss: 1.4085, train_acc: 0.4954 test_loss: 1.2051, test_acc: 0.5599, best: 0.5706, time: 0:00:58
 Epoch: 87, lr: 1.0e-02, train_loss: 1.3834, train_acc: 0.4960 test_loss: 1.4185, test_acc: 0.5092, best: 0.5706, time: 0:00:58
 Epoch: 88, lr: 1.0e-02, train_loss: 1.4003, train_acc: 0.4896 test_loss: 1.2334, test_acc: 0.5544, best: 0.5706, time: 0:01:00
 Epoch: 89, lr: 1.0e-02, train_loss: 1.3899, train_acc: 0.4984 test_loss: 1.1858, test_acc: 0.5640, best: 0.5706, time: 0:00:59
 Epoch: 90, lr: 1.0e-02, train_loss: 1.3892, train_acc: 0.4884 test_loss: 1.1499, test_acc: 0.5881, best: 0.5881, time: 0:00:59
 Epoch: 91, lr: 1.0e-02, train_loss: 1.3685, train_acc: 0.4960 test_loss: 1.2042, test_acc: 0.5633, best: 0.5881, time: 0:00:59
 Epoch: 92, lr: 1.0e-02, train_loss: 1.3731, train_acc: 0.4972 test_loss: 1.3741, test_acc: 0.5185, best: 0.5881, time: 0:01:01
 Epoch: 93, lr: 1.0e-02, train_loss: 1.3712, train_acc: 0.4966 test_loss: 1.1784, test_acc: 0.5651, best: 0.5881, time: 0:00:58
 Epoch: 94, lr: 1.0e-02, train_loss: 1.4024, train_acc: 0.4762 test_loss: 1.3421, test_acc: 0.5429, best: 0.5881, time: 0:00:59
 Epoch: 95, lr: 1.0e-02, train_loss: 1.3852, train_acc: 0.4964 test_loss: 1.1573, test_acc: 0.5789, best: 0.5881, time: 0:00:57
 Epoch: 96, lr: 1.0e-02, train_loss: 1.3522, train_acc: 0.5056 test_loss: 1.1430, test_acc: 0.5859, best: 0.5881, time: 0:01:01
 Epoch: 97, lr: 1.0e-02, train_loss: 1.3742, train_acc: 0.4996 test_loss: 1.2779, test_acc: 0.5470, best: 0.5881, time: 0:00:58
 Epoch: 98, lr: 1.0e-02, train_loss: 1.3720, train_acc: 0.5068 test_loss: 1.2616, test_acc: 0.5606, best: 0.5881, time: 0:01:00
 Epoch: 99, lr: 1.0e-02, train_loss: 1.3570, train_acc: 0.5056 test_loss: 1.2154, test_acc: 0.5631, best: 0.5881, time: 0:00:59
 Epoch: 100, lr: 1.0e-02, train_loss: 1.3584, train_acc: 0.5014 test_loss: 2.0282, test_acc: 0.4991, best: 0.5881, time: 0:00:58
 Epoch: 101, lr: 1.0e-02, train_loss: 1.3541, train_acc: 0.5088 test_loss: 1.3085, test_acc: 0.5497, best: 0.5881, time: 0:00:57
 Epoch: 102, lr: 1.0e-02, train_loss: 1.3405, train_acc: 0.5202 test_loss: 1.2386, test_acc: 0.5604, best: 0.5881, time: 0:00:56
 Epoch: 103, lr: 1.0e-02, train_loss: 1.3475, train_acc: 0.5028 test_loss: 1.2991, test_acc: 0.5416, best: 0.5881, time: 0:00:58
 Epoch: 104, lr: 1.0e-02, train_loss: 1.3332, train_acc: 0.5098 test_loss: 1.2393, test_acc: 0.5741, best: 0.5881, time: 0:00:58
 Epoch: 105, lr: 1.0e-02, train_loss: 1.3407, train_acc: 0.5164 test_loss: 1.6248, test_acc: 0.5236, best: 0.5881, time: 0:00:56
 Epoch: 106, lr: 1.0e-02, train_loss: 1.3259, train_acc: 0.5202 test_loss: 1.2870, test_acc: 0.5644, best: 0.5881, time: 0:00:57
 Epoch: 107, lr: 1.0e-02, train_loss: 1.3064, train_acc: 0.5336 test_loss: 1.2276, test_acc: 0.5720, best: 0.5881, time: 0:00:57
 Epoch: 108, lr: 1.0e-02, train_loss: 1.2952, train_acc: 0.5262 test_loss: 1.1600, test_acc: 0.5931, best: 0.5931, time: 0:00:57
 Epoch: 109, lr: 1.0e-02, train_loss: 1.3428, train_acc: 0.5150 test_loss: 1.1721, test_acc: 0.5824, best: 0.5931, time: 0:00:56
 Epoch: 110, lr: 1.0e-02, train_loss: 1.3152, train_acc: 0.5258 test_loss: 1.2044, test_acc: 0.5846, best: 0.5931, time: 0:01:02
 Epoch: 111, lr: 1.0e-02, train_loss: 1.3063, train_acc: 0.5282 test_loss: 1.2592, test_acc: 0.5516, best: 0.5931, time: 0:00:56
 Epoch: 112, lr: 1.0e-02, train_loss: 1.2949, train_acc: 0.5312 test_loss: 1.1649, test_acc: 0.5833, best: 0.5931, time: 0:00:57
 Epoch: 113, lr: 1.0e-02, train_loss: 1.2991, train_acc: 0.5350 test_loss: 1.1594, test_acc: 0.5860, best: 0.5931, time: 0:00:56
 Epoch: 114, lr: 1.0e-02, train_loss: 1.3024, train_acc: 0.5330 test_loss: 1.1847, test_acc: 0.5740, best: 0.5931, time: 0:00:59
 Epoch: 115, lr: 1.0e-02, train_loss: 1.2811, train_acc: 0.5352 test_loss: 1.1379, test_acc: 0.5870, best: 0.5931, time: 0:00:55
 Epoch: 116, lr: 1.0e-02, train_loss: 1.2498, train_acc: 0.5374 test_loss: 1.1062, test_acc: 0.5969, best: 0.5969, time: 0:00:55
 Epoch: 117, lr: 1.0e-02, train_loss: 1.2703, train_acc: 0.5390 test_loss: 1.1126, test_acc: 0.5914, best: 0.5969, time: 0:01:00
 Epoch: 118, lr: 1.0e-02, train_loss: 1.2624, train_acc: 0.5410 test_loss: 1.1647, test_acc: 0.5869, best: 0.5969, time: 0:00:56
 Epoch: 119, lr: 1.0e-02, train_loss: 1.2493, train_acc: 0.5388 test_loss: 1.1090, test_acc: 0.5964, best: 0.5969, time: 0:00:56
 Epoch: 120, lr: 1.0e-02, train_loss: 1.2576, train_acc: 0.5464 test_loss: 1.1123, test_acc: 0.5968, best: 0.5969, time: 0:00:56
 Epoch: 121, lr: 1.0e-02, train_loss: 1.2590, train_acc: 0.5464 test_loss: 1.1104, test_acc: 0.6015, best: 0.6015, time: 0:01:00
 Epoch: 122, lr: 1.0e-02, train_loss: 1.2340, train_acc: 0.5496 test_loss: 1.1063, test_acc: 0.6001, best: 0.6015, time: 0:01:01
 Epoch: 123, lr: 1.0e-02, train_loss: 1.2409, train_acc: 0.5442 test_loss: 1.2251, test_acc: 0.5699, best: 0.6015, time: 0:00:58
 Epoch: 124, lr: 1.0e-02, train_loss: 1.2698, train_acc: 0.5384 test_loss: 1.1218, test_acc: 0.5903, best: 0.6015, time: 0:00:55
 Epoch: 125, lr: 1.0e-02, train_loss: 1.2476, train_acc: 0.5474 test_loss: 1.1100, test_acc: 0.6046, best: 0.6046, time: 0:01:00
 Epoch: 126, lr: 1.0e-02, train_loss: 1.2610, train_acc: 0.5380 test_loss: 1.0906, test_acc: 0.6125, best: 0.6125, time: 0:00:57
 Epoch: 127, lr: 1.0e-02, train_loss: 1.2230, train_acc: 0.5548 test_loss: 1.0760, test_acc: 0.6169, best: 0.6169, time: 0:01:01
 Epoch: 128, lr: 1.0e-02, train_loss: 1.2407, train_acc: 0.5476 test_loss: 1.1890, test_acc: 0.5933, best: 0.6169, time: 0:00:57
 Epoch: 129, lr: 1.0e-02, train_loss: 1.2445, train_acc: 0.5482 test_loss: 1.1270, test_acc: 0.6071, best: 0.6169, time: 0:00:57
 Epoch: 130, lr: 1.0e-02, train_loss: 1.2559, train_acc: 0.5464 test_loss: 1.2059, test_acc: 0.5637, best: 0.6169, time: 0:00:54
 Epoch: 131, lr: 1.0e-02, train_loss: 1.2648, train_acc: 0.5452 test_loss: 1.1494, test_acc: 0.5906, best: 0.6169, time: 0:00:56
 Epoch: 132, lr: 1.0e-02, train_loss: 1.2264, train_acc: 0.5604 test_loss: 1.1319, test_acc: 0.6130, best: 0.6169, time: 0:00:56
 Epoch: 133, lr: 1.0e-02, train_loss: 1.2249, train_acc: 0.5632 test_loss: 1.1449, test_acc: 0.5941, best: 0.6169, time: 0:00:55
 Epoch: 134, lr: 1.0e-02, train_loss: 1.2412, train_acc: 0.5458 test_loss: 1.1808, test_acc: 0.5914, best: 0.6169, time: 0:00:58
 Epoch: 135, lr: 1.0e-02, train_loss: 1.2272, train_acc: 0.5590 test_loss: 1.1478, test_acc: 0.6012, best: 0.6169, time: 0:00:57
 Epoch: 136, lr: 1.0e-02, train_loss: 1.2008, train_acc: 0.5604 test_loss: 1.2451, test_acc: 0.6005, best: 0.6169, time: 0:00:58
 Epoch: 137, lr: 1.0e-02, train_loss: 1.2412, train_acc: 0.5492 test_loss: 1.1363, test_acc: 0.6099, best: 0.6169, time: 0:00:55
 Epoch: 138, lr: 1.0e-02, train_loss: 1.2292, train_acc: 0.5566 test_loss: 1.1709, test_acc: 0.6022, best: 0.6169, time: 0:00:56
 Epoch: 139, lr: 1.0e-02, train_loss: 1.2131, train_acc: 0.5590 test_loss: 1.3277, test_acc: 0.5793, best: 0.6169, time: 0:00:54
 Epoch: 140, lr: 1.0e-02, train_loss: 1.2159, train_acc: 0.5574 test_loss: 1.5575, test_acc: 0.5460, best: 0.6169, time: 0:00:57
 Epoch: 141, lr: 1.0e-02, train_loss: 1.2062, train_acc: 0.5722 test_loss: 1.2228, test_acc: 0.5781, best: 0.6169, time: 0:00:57
 Epoch: 142, lr: 1.0e-02, train_loss: 1.1936, train_acc: 0.5716 test_loss: 1.1352, test_acc: 0.6031, best: 0.6169, time: 0:00:58
 Epoch: 143, lr: 1.0e-02, train_loss: 1.1949, train_acc: 0.5662 test_loss: 1.1270, test_acc: 0.6135, best: 0.6169, time: 0:00:56
 Epoch: 144, lr: 1.0e-02, train_loss: 1.2104, train_acc: 0.5596 test_loss: 1.1255, test_acc: 0.6022, best: 0.6169, time: 0:00:56
 Epoch: 145, lr: 1.0e-02, train_loss: 1.1892, train_acc: 0.5692 test_loss: 1.1446, test_acc: 0.6011, best: 0.6169, time: 0:00:57
 Epoch: 146, lr: 1.0e-02, train_loss: 1.1831, train_acc: 0.5784 test_loss: 1.1751, test_acc: 0.6142, best: 0.6169, time: 0:00:57
 Epoch: 147, lr: 1.0e-02, train_loss: 1.1508, train_acc: 0.5880 test_loss: 1.1174, test_acc: 0.6024, best: 0.6169, time: 0:00:58
 Epoch: 148, lr: 1.0e-02, train_loss: 1.1629, train_acc: 0.5794 test_loss: 1.1883, test_acc: 0.5966, best: 0.6169, time: 0:00:57
 Epoch: 149, lr: 1.0e-02, train_loss: 1.1854, train_acc: 0.5744 test_loss: 1.1600, test_acc: 0.6119, best: 0.6169, time: 0:00:55
 Epoch: 150, lr: 1.0e-02, train_loss: 1.1835, train_acc: 0.5706 test_loss: 1.1621, test_acc: 0.6082, best: 0.6169, time: 0:00:57
 Epoch: 151, lr: 1.0e-02, train_loss: 1.1685, train_acc: 0.5830 test_loss: 1.1421, test_acc: 0.6022, best: 0.6169, time: 0:00:54
 Epoch: 152, lr: 1.0e-02, train_loss: 1.1915, train_acc: 0.5730 test_loss: 1.0945, test_acc: 0.6130, best: 0.6169, time: 0:00:54
 Epoch: 153, lr: 1.0e-02, train_loss: 1.1591, train_acc: 0.5876 test_loss: 1.1828, test_acc: 0.5939, best: 0.6169, time: 0:00:58
 Epoch: 154, lr: 1.0e-02, train_loss: 1.1517, train_acc: 0.5778 test_loss: 1.1330, test_acc: 0.5956, best: 0.6169, time: 0:00:57
 Epoch: 155, lr: 1.0e-02, train_loss: 1.1509, train_acc: 0.5934 test_loss: 1.1343, test_acc: 0.6048, best: 0.6169, time: 0:00:55
 Epoch: 156, lr: 1.0e-02, train_loss: 1.1505, train_acc: 0.5902 test_loss: 1.0799, test_acc: 0.6132, best: 0.6169, time: 0:00:56
 Epoch: 157, lr: 1.0e-02, train_loss: 1.1305, train_acc: 0.5974 test_loss: 1.0651, test_acc: 0.6158, best: 0.6169, time: 0:00:55
 Epoch: 158, lr: 1.0e-02, train_loss: 1.1331, train_acc: 0.5876 test_loss: 1.1288, test_acc: 0.6115, best: 0.6169, time: 0:00:57
 Epoch: 159, lr: 1.0e-02, train_loss: 1.1309, train_acc: 0.5962 test_loss: 1.0958, test_acc: 0.6138, best: 0.6169, time: 0:00:57
 Epoch: 160, lr: 1.0e-02, train_loss: 1.1181, train_acc: 0.5934 test_loss: 1.1315, test_acc: 0.6085, best: 0.6169, time: 0:00:57
 Epoch: 161, lr: 1.0e-02, train_loss: 1.1438, train_acc: 0.5994 test_loss: 1.1018, test_acc: 0.6122, best: 0.6169, time: 0:00:57
 Epoch: 162, lr: 1.0e-02, train_loss: 1.1395, train_acc: 0.5914 test_loss: 1.1047, test_acc: 0.6182, best: 0.6182, time: 0:00:58
 Epoch: 163, lr: 1.0e-02, train_loss: 1.1540, train_acc: 0.5822 test_loss: 1.1522, test_acc: 0.6166, best: 0.6182, time: 0:00:58
 Epoch: 164, lr: 1.0e-02, train_loss: 1.1548, train_acc: 0.5842 test_loss: 1.2245, test_acc: 0.6110, best: 0.6182, time: 0:00:58
 Epoch: 165, lr: 1.0e-02, train_loss: 1.1419, train_acc: 0.5906 test_loss: 1.0369, test_acc: 0.6284, best: 0.6284, time: 0:00:57
 Epoch: 166, lr: 1.0e-02, train_loss: 1.1128, train_acc: 0.5978 test_loss: 1.2728, test_acc: 0.5986, best: 0.6284, time: 0:00:57
 Epoch: 167, lr: 1.0e-02, train_loss: 1.1029, train_acc: 0.5928 test_loss: 1.0695, test_acc: 0.6202, best: 0.6284, time: 0:00:55
 Epoch: 168, lr: 1.0e-02, train_loss: 1.1227, train_acc: 0.6008 test_loss: 1.0456, test_acc: 0.6341, best: 0.6341, time: 0:00:58
 Epoch: 169, lr: 1.0e-02, train_loss: 1.1313, train_acc: 0.5822 test_loss: 1.1109, test_acc: 0.6079, best: 0.6341, time: 0:00:56
 Epoch: 170, lr: 1.0e-02, train_loss: 1.1222, train_acc: 0.5894 test_loss: 1.0654, test_acc: 0.6245, best: 0.6341, time: 0:00:55
 Epoch: 171, lr: 1.0e-02, train_loss: 1.1341, train_acc: 0.5902 test_loss: 1.0449, test_acc: 0.6381, best: 0.6381, time: 0:00:57
 Epoch: 172, lr: 1.0e-02, train_loss: 1.1131, train_acc: 0.6006 test_loss: 1.1088, test_acc: 0.6180, best: 0.6381, time: 0:00:56
 Epoch: 173, lr: 1.0e-02, train_loss: 1.1166, train_acc: 0.6018 test_loss: 1.1725, test_acc: 0.6158, best: 0.6381, time: 0:00:57
 Epoch: 174, lr: 1.0e-02, train_loss: 1.1029, train_acc: 0.6024 test_loss: 1.1032, test_acc: 0.6228, best: 0.6381, time: 0:00:57
 Epoch: 175, lr: 1.0e-02, train_loss: 1.1201, train_acc: 0.5962 test_loss: 1.1350, test_acc: 0.6345, best: 0.6381, time: 0:00:55
 Epoch: 176, lr: 1.0e-02, train_loss: 1.0999, train_acc: 0.6036 test_loss: 1.1573, test_acc: 0.6182, best: 0.6381, time: 0:00:57
 Epoch: 177, lr: 1.0e-02, train_loss: 1.1010, train_acc: 0.6036 test_loss: 1.1761, test_acc: 0.6016, best: 0.6381, time: 0:00:56
 Epoch: 178, lr: 1.0e-02, train_loss: 1.1381, train_acc: 0.5886 test_loss: 1.1915, test_acc: 0.6056, best: 0.6381, time: 0:00:57
 Epoch: 179, lr: 1.0e-02, train_loss: 1.1092, train_acc: 0.5960 test_loss: 1.0903, test_acc: 0.6311, best: 0.6381, time: 0:01:00
 Epoch: 180, lr: 2.0e-03, train_loss: 1.0376, train_acc: 0.6262 test_loss: 1.0605, test_acc: 0.6432, best: 0.6432, time: 0:01:00
 Epoch: 181, lr: 2.0e-03, train_loss: 1.0265, train_acc: 0.6306 test_loss: 1.1363, test_acc: 0.6284, best: 0.6432, time: 0:01:00
 Epoch: 182, lr: 2.0e-03, train_loss: 0.9755, train_acc: 0.6400 test_loss: 1.1007, test_acc: 0.6361, best: 0.6432, time: 0:00:55
 Epoch: 183, lr: 2.0e-03, train_loss: 1.0297, train_acc: 0.6290 test_loss: 1.1605, test_acc: 0.6236, best: 0.6432, time: 0:00:55
 Epoch: 184, lr: 2.0e-03, train_loss: 0.9850, train_acc: 0.6458 test_loss: 1.0855, test_acc: 0.6360, best: 0.6432, time: 0:00:56
 Epoch: 185, lr: 2.0e-03, train_loss: 0.9881, train_acc: 0.6402 test_loss: 1.1927, test_acc: 0.6228, best: 0.6432, time: 0:00:56
 Epoch: 186, lr: 2.0e-03, train_loss: 1.0108, train_acc: 0.6336 test_loss: 1.2650, test_acc: 0.6204, best: 0.6432, time: 0:00:56
 Epoch: 187, lr: 2.0e-03, train_loss: 0.9912, train_acc: 0.6414 test_loss: 1.0908, test_acc: 0.6332, best: 0.6432, time: 0:00:59
 Epoch: 188, lr: 2.0e-03, train_loss: 0.9701, train_acc: 0.6468 test_loss: 1.2851, test_acc: 0.6196, best: 0.6432, time: 0:00:56
 Epoch: 189, lr: 2.0e-03, train_loss: 0.9607, train_acc: 0.6602 test_loss: 1.2312, test_acc: 0.6339, best: 0.6432, time: 0:01:00
 Epoch: 190, lr: 2.0e-03, train_loss: 0.9537, train_acc: 0.6568 test_loss: 1.2370, test_acc: 0.6306, best: 0.6432, time: 0:01:01
 Epoch: 191, lr: 2.0e-03, train_loss: 0.9477, train_acc: 0.6650 test_loss: 1.1869, test_acc: 0.6355, best: 0.6432, time: 0:01:02
 Epoch: 192, lr: 2.0e-03, train_loss: 0.9551, train_acc: 0.6586 test_loss: 1.0933, test_acc: 0.6464, best: 0.6464, time: 0:00:59
 Epoch: 193, lr: 2.0e-03, train_loss: 0.9509, train_acc: 0.6554 test_loss: 1.0957, test_acc: 0.6391, best: 0.6464, time: 0:00:58
 Epoch: 194, lr: 2.0e-03, train_loss: 0.9549, train_acc: 0.6558 test_loss: 1.0948, test_acc: 0.6394, best: 0.6464, time: 0:00:59
 Epoch: 195, lr: 2.0e-03, train_loss: 0.9617, train_acc: 0.6480 test_loss: 1.1935, test_acc: 0.6356, best: 0.6464, time: 0:00:59
 Epoch: 196, lr: 2.0e-03, train_loss: 0.9509, train_acc: 0.6648 test_loss: 1.0856, test_acc: 0.6474, best: 0.6474, time: 0:00:56
 Epoch: 197, lr: 2.0e-03, train_loss: 0.9454, train_acc: 0.6556 test_loss: 1.1445, test_acc: 0.6410, best: 0.6474, time: 0:00:58
 Epoch: 198, lr: 2.0e-03, train_loss: 0.9532, train_acc: 0.6518 test_loss: 1.0605, test_acc: 0.6556, best: 0.6556, time: 0:00:58
 Epoch: 199, lr: 2.0e-03, train_loss: 0.9332, train_acc: 0.6618 test_loss: 1.2410, test_acc: 0.6418, best: 0.6556, time: 0:01:00
 Epoch: 200, lr: 2.0e-03, train_loss: 0.9366, train_acc: 0.6684 test_loss: 1.3745, test_acc: 0.6381, best: 0.6556, time: 0:00:58
 Epoch: 201, lr: 2.0e-03, train_loss: 0.9408, train_acc: 0.6608 test_loss: 1.0220, test_acc: 0.6579, best: 0.6579, time: 0:01:00
 Epoch: 202, lr: 2.0e-03, train_loss: 0.9288, train_acc: 0.6628 test_loss: 1.1228, test_acc: 0.6442, best: 0.6579, time: 0:01:01
 Epoch: 203, lr: 2.0e-03, train_loss: 0.9183, train_acc: 0.6702 test_loss: 1.1265, test_acc: 0.6456, best: 0.6579, time: 0:00:59
 Epoch: 204, lr: 2.0e-03, train_loss: 0.9330, train_acc: 0.6642 test_loss: 1.0532, test_acc: 0.6508, best: 0.6579, time: 0:00:58
 Epoch: 205, lr: 2.0e-03, train_loss: 0.9357, train_acc: 0.6680 test_loss: 1.0452, test_acc: 0.6471, best: 0.6579, time: 0:00:56
 Epoch: 206, lr: 2.0e-03, train_loss: 0.9101, train_acc: 0.6758 test_loss: 1.0330, test_acc: 0.6501, best: 0.6579, time: 0:00:58
 Epoch: 207, lr: 2.0e-03, train_loss: 0.8941, train_acc: 0.6816 test_loss: 1.0957, test_acc: 0.6498, best: 0.6579, time: 0:01:00
 Epoch: 208, lr: 2.0e-03, train_loss: 0.9432, train_acc: 0.6574 test_loss: 1.0859, test_acc: 0.6476, best: 0.6579, time: 0:00:55
 Epoch: 209, lr: 2.0e-03, train_loss: 0.9185, train_acc: 0.6694 test_loss: 1.2225, test_acc: 0.6340, best: 0.6579, time: 0:00:57
 Epoch: 210, lr: 2.0e-03, train_loss: 0.9253, train_acc: 0.6668 test_loss: 1.1870, test_acc: 0.6369, best: 0.6579, time: 0:00:58
 Epoch: 211, lr: 2.0e-03, train_loss: 0.9319, train_acc: 0.6654 test_loss: 1.0502, test_acc: 0.6555, best: 0.6579, time: 0:00:59
 Epoch: 212, lr: 2.0e-03, train_loss: 0.9223, train_acc: 0.6676 test_loss: 1.1247, test_acc: 0.6510, best: 0.6579, time: 0:00:56
 Epoch: 213, lr: 2.0e-03, train_loss: 0.9253, train_acc: 0.6606 test_loss: 1.1905, test_acc: 0.6352, best: 0.6579, time: 0:00:59
 Epoch: 214, lr: 2.0e-03, train_loss: 0.9101, train_acc: 0.6760 test_loss: 1.0423, test_acc: 0.6496, best: 0.6579, time: 0:00:58
 Epoch: 215, lr: 2.0e-03, train_loss: 0.9095, train_acc: 0.6738 test_loss: 1.0380, test_acc: 0.6512, best: 0.6579, time: 0:01:00
 Epoch: 216, lr: 2.0e-03, train_loss: 0.9080, train_acc: 0.6756 test_loss: 1.0786, test_acc: 0.6505, best: 0.6579, time: 0:00:56
 Epoch: 217, lr: 2.0e-03, train_loss: 0.8868, train_acc: 0.6806 test_loss: 1.0778, test_acc: 0.6556, best: 0.6579, time: 0:01:01
 Epoch: 218, lr: 2.0e-03, train_loss: 0.8940, train_acc: 0.6788 test_loss: 1.0363, test_acc: 0.6584, best: 0.6584, time: 0:00:59
 Epoch: 219, lr: 2.0e-03, train_loss: 0.9157, train_acc: 0.6746 test_loss: 1.1008, test_acc: 0.6461, best: 0.6584, time: 0:01:00
 Epoch: 220, lr: 2.0e-03, train_loss: 0.8842, train_acc: 0.6744 test_loss: 1.0860, test_acc: 0.6520, best: 0.6584, time: 0:00:58
 Epoch: 221, lr: 2.0e-03, train_loss: 0.9161, train_acc: 0.6700 test_loss: 1.2713, test_acc: 0.6294, best: 0.6584, time: 0:00:55
 Epoch: 222, lr: 2.0e-03, train_loss: 0.9137, train_acc: 0.6700 test_loss: 1.1553, test_acc: 0.6408, best: 0.6584, time: 0:00:58
 Epoch: 223, lr: 2.0e-03, train_loss: 0.9224, train_acc: 0.6588 test_loss: 0.9992, test_acc: 0.6613, best: 0.6613, time: 0:00:57
 Epoch: 224, lr: 2.0e-03, train_loss: 0.8773, train_acc: 0.6892 test_loss: 1.2400, test_acc: 0.6325, best: 0.6613, time: 0:00:57
 Epoch: 225, lr: 2.0e-03, train_loss: 0.9027, train_acc: 0.6790 test_loss: 1.0738, test_acc: 0.6539, best: 0.6613, time: 0:00:56
 Epoch: 226, lr: 2.0e-03, train_loss: 0.9117, train_acc: 0.6706 test_loss: 1.1345, test_acc: 0.6452, best: 0.6613, time: 0:00:55
 Epoch: 227, lr: 2.0e-03, train_loss: 0.9013, train_acc: 0.6808 test_loss: 1.1076, test_acc: 0.6495, best: 0.6613, time: 0:00:56
 Epoch: 228, lr: 2.0e-03, train_loss: 0.8874, train_acc: 0.6790 test_loss: 1.0063, test_acc: 0.6564, best: 0.6613, time: 0:00:58
 Epoch: 229, lr: 2.0e-03, train_loss: 0.8823, train_acc: 0.6826 test_loss: 1.0291, test_acc: 0.6524, best: 0.6613, time: 0:01:00
 Epoch: 230, lr: 2.0e-03, train_loss: 0.8894, train_acc: 0.6816 test_loss: 1.4128, test_acc: 0.6332, best: 0.6613, time: 0:01:00
 Epoch: 231, lr: 2.0e-03, train_loss: 0.8775, train_acc: 0.6860 test_loss: 1.0927, test_acc: 0.6520, best: 0.6613, time: 0:00:59
 Epoch: 232, lr: 2.0e-03, train_loss: 0.8800, train_acc: 0.6828 test_loss: 1.1134, test_acc: 0.6431, best: 0.6613, time: 0:00:59
 Epoch: 233, lr: 2.0e-03, train_loss: 0.8810, train_acc: 0.6824 test_loss: 1.1063, test_acc: 0.6435, best: 0.6613, time: 0:00:57
 Epoch: 234, lr: 2.0e-03, train_loss: 0.8968, train_acc: 0.6834 test_loss: 1.4913, test_acc: 0.6259, best: 0.6613, time: 0:00:58
 Epoch: 235, lr: 2.0e-03, train_loss: 0.9019, train_acc: 0.6780 test_loss: 1.0497, test_acc: 0.6566, best: 0.6613, time: 0:00:57
 Epoch: 236, lr: 2.0e-03, train_loss: 0.8857, train_acc: 0.6800 test_loss: 1.0496, test_acc: 0.6579, best: 0.6613, time: 0:00:56
 Epoch: 237, lr: 2.0e-03, train_loss: 0.8751, train_acc: 0.6860 test_loss: 1.2963, test_acc: 0.6386, best: 0.6613, time: 0:00:59
 Epoch: 238, lr: 2.0e-03, train_loss: 0.8876, train_acc: 0.6864 test_loss: 1.0477, test_acc: 0.6542, best: 0.6613, time: 0:01:01
 Epoch: 239, lr: 2.0e-03, train_loss: 0.8874, train_acc: 0.6840 test_loss: 1.1202, test_acc: 0.6461, best: 0.6613, time: 0:01:00
 Epoch: 240, lr: 4.0e-04, train_loss: 0.8679, train_acc: 0.6848 test_loss: 1.4293, test_acc: 0.6284, best: 0.6613, time: 0:00:58
 Epoch: 241, lr: 4.0e-04, train_loss: 0.8739, train_acc: 0.6890 test_loss: 1.2258, test_acc: 0.6456, best: 0.6613, time: 0:01:01
 Epoch: 242, lr: 4.0e-04, train_loss: 0.8444, train_acc: 0.6980 test_loss: 1.3440, test_acc: 0.6440, best: 0.6613, time: 0:00:58
 Epoch: 243, lr: 4.0e-04, train_loss: 0.8486, train_acc: 0.6944 test_loss: 1.1953, test_acc: 0.6425, best: 0.6613, time: 0:00:58
 Epoch: 244, lr: 4.0e-04, train_loss: 0.8788, train_acc: 0.6906 test_loss: 1.0829, test_acc: 0.6514, best: 0.6613, time: 0:00:58
 Epoch: 245, lr: 4.0e-04, train_loss: 0.8584, train_acc: 0.6932 test_loss: 1.0312, test_acc: 0.6610, best: 0.6613, time: 0:00:57
 Epoch: 246, lr: 4.0e-04, train_loss: 0.8692, train_acc: 0.6868 test_loss: 1.0952, test_acc: 0.6515, best: 0.6613, time: 0:01:00
 Epoch: 247, lr: 4.0e-04, train_loss: 0.8170, train_acc: 0.7034 test_loss: 1.0513, test_acc: 0.6562, best: 0.6613, time: 0:00:59
 Epoch: 248, lr: 4.0e-04, train_loss: 0.8712, train_acc: 0.6936 test_loss: 1.0537, test_acc: 0.6539, best: 0.6613, time: 0:00:58
 Epoch: 249, lr: 4.0e-04, train_loss: 0.8461, train_acc: 0.6914 test_loss: 1.1242, test_acc: 0.6526, best: 0.6613, time: 0:00:55
 Epoch: 250, lr: 4.0e-04, train_loss: 0.8247, train_acc: 0.7024 test_loss: 1.1488, test_acc: 0.6481, best: 0.6613, time: 0:01:00
 Epoch: 251, lr: 4.0e-04, train_loss: 0.8550, train_acc: 0.6964 test_loss: 1.3867, test_acc: 0.6366, best: 0.6613, time: 0:01:01
 Epoch: 252, lr: 4.0e-04, train_loss: 0.8324, train_acc: 0.6938 test_loss: 1.0815, test_acc: 0.6558, best: 0.6613, time: 0:00:56
 Epoch: 253, lr: 4.0e-04, train_loss: 0.8310, train_acc: 0.7046 test_loss: 1.1257, test_acc: 0.6530, best: 0.6613, time: 0:00:59
 Epoch: 254, lr: 4.0e-04, train_loss: 0.8358, train_acc: 0.6968 test_loss: 1.1311, test_acc: 0.6560, best: 0.6613, time: 0:00:58
 Epoch: 255, lr: 4.0e-04, train_loss: 0.8521, train_acc: 0.6982 test_loss: 1.0559, test_acc: 0.6591, best: 0.6613, time: 0:00:57
 Epoch: 256, lr: 4.0e-04, train_loss: 0.8369, train_acc: 0.7032 test_loss: 1.3021, test_acc: 0.6405, best: 0.6613, time: 0:01:00
 Epoch: 257, lr: 4.0e-04, train_loss: 0.8455, train_acc: 0.6984 test_loss: 1.0613, test_acc: 0.6609, best: 0.6613, time: 0:00:59
 Epoch: 258, lr: 4.0e-04, train_loss: 0.8337, train_acc: 0.6978 test_loss: 1.0236, test_acc: 0.6609, best: 0.6613, time: 0:00:58
 Epoch: 259, lr: 4.0e-04, train_loss: 0.8350, train_acc: 0.6980 test_loss: 1.0282, test_acc: 0.6613, best: 0.6613, time: 0:00:59
 Epoch: 260, lr: 4.0e-04, train_loss: 0.8279, train_acc: 0.7058 test_loss: 1.1164, test_acc: 0.6551, best: 0.6613, time: 0:01:00
 Epoch: 261, lr: 4.0e-04, train_loss: 0.8216, train_acc: 0.7064 test_loss: 1.0081, test_acc: 0.6634, best: 0.6634, time: 0:01:00
 Epoch: 262, lr: 4.0e-04, train_loss: 0.8362, train_acc: 0.7018 test_loss: 1.0355, test_acc: 0.6614, best: 0.6634, time: 0:00:57
 Epoch: 263, lr: 4.0e-04, train_loss: 0.8536, train_acc: 0.6906 test_loss: 1.2147, test_acc: 0.6490, best: 0.6634, time: 0:00:57
 Epoch: 264, lr: 4.0e-04, train_loss: 0.8573, train_acc: 0.6954 test_loss: 1.1340, test_acc: 0.6504, best: 0.6634, time: 0:00:57
 Epoch: 265, lr: 4.0e-04, train_loss: 0.8138, train_acc: 0.7108 test_loss: 1.1167, test_acc: 0.6545, best: 0.6634, time: 0:01:01
 Epoch: 266, lr: 4.0e-04, train_loss: 0.8315, train_acc: 0.7060 test_loss: 1.1168, test_acc: 0.6544, best: 0.6634, time: 0:00:59
 Epoch: 267, lr: 4.0e-04, train_loss: 0.8388, train_acc: 0.6994 test_loss: 1.1378, test_acc: 0.6498, best: 0.6634, time: 0:00:55
 Epoch: 268, lr: 4.0e-04, train_loss: 0.8262, train_acc: 0.6950 test_loss: 1.0381, test_acc: 0.6634, best: 0.6634, time: 0:00:56
 Epoch: 269, lr: 4.0e-04, train_loss: 0.8262, train_acc: 0.7026 test_loss: 1.2214, test_acc: 0.6519, best: 0.6634, time: 0:00:57
 Epoch: 270, lr: 8.0e-05, train_loss: 0.8271, train_acc: 0.7114 test_loss: 1.0051, test_acc: 0.6630, best: 0.6634, time: 0:00:56
 Epoch: 271, lr: 8.0e-05, train_loss: 0.8438, train_acc: 0.6990 test_loss: 1.3867, test_acc: 0.6441, best: 0.6634, time: 0:00:59
 Epoch: 272, lr: 8.0e-05, train_loss: 0.8362, train_acc: 0.7038 test_loss: 1.0335, test_acc: 0.6597, best: 0.6634, time: 0:00:56
 Epoch: 273, lr: 8.0e-05, train_loss: 0.8224, train_acc: 0.7092 test_loss: 1.3880, test_acc: 0.6326, best: 0.6634, time: 0:00:55
 Epoch: 274, lr: 8.0e-05, train_loss: 0.8231, train_acc: 0.7006 test_loss: 1.1279, test_acc: 0.6511, best: 0.6634, time: 0:00:57
 Epoch: 275, lr: 8.0e-05, train_loss: 0.8482, train_acc: 0.6972 test_loss: 1.1757, test_acc: 0.6455, best: 0.6634, time: 0:00:56
 Epoch: 276, lr: 8.0e-05, train_loss: 0.8258, train_acc: 0.7070 test_loss: 1.0978, test_acc: 0.6560, best: 0.6634, time: 0:00:56
 Epoch: 277, lr: 8.0e-05, train_loss: 0.8285, train_acc: 0.7048 test_loss: 1.0754, test_acc: 0.6560, best: 0.6634, time: 0:00:59
 Epoch: 278, lr: 8.0e-05, train_loss: 0.8165, train_acc: 0.7134 test_loss: 1.3149, test_acc: 0.6439, best: 0.6634, time: 0:00:57
 Epoch: 279, lr: 8.0e-05, train_loss: 0.8373, train_acc: 0.6882 test_loss: 1.0710, test_acc: 0.6593, best: 0.6634, time: 0:00:58
 Epoch: 280, lr: 8.0e-05, train_loss: 0.8361, train_acc: 0.6990 test_loss: 1.0953, test_acc: 0.6548, best: 0.6634, time: 0:00:57
 Epoch: 281, lr: 8.0e-05, train_loss: 0.8337, train_acc: 0.7034 test_loss: 1.0683, test_acc: 0.6609, best: 0.6634, time: 0:00:58
 Epoch: 282, lr: 8.0e-05, train_loss: 0.8378, train_acc: 0.6980 test_loss: 1.4106, test_acc: 0.6420, best: 0.6634, time: 0:00:57
 Epoch: 283, lr: 8.0e-05, train_loss: 0.8399, train_acc: 0.6954 test_loss: 1.0665, test_acc: 0.6589, best: 0.6634, time: 0:00:57
 Epoch: 284, lr: 8.0e-05, train_loss: 0.8166, train_acc: 0.7044 test_loss: 1.1268, test_acc: 0.6545, best: 0.6634, time: 0:00:58
 Epoch: 285, lr: 8.0e-05, train_loss: 0.8268, train_acc: 0.7014 test_loss: 1.0873, test_acc: 0.6519, best: 0.6634, time: 0:00:58
 Epoch: 286, lr: 8.0e-05, train_loss: 0.8100, train_acc: 0.7092 test_loss: 1.0410, test_acc: 0.6603, best: 0.6634, time: 0:00:57
 Epoch: 287, lr: 8.0e-05, train_loss: 0.8266, train_acc: 0.7110 test_loss: 0.9879, test_acc: 0.6649, best: 0.6649, time: 0:00:58
 Epoch: 288, lr: 8.0e-05, train_loss: 0.8186, train_acc: 0.7032 test_loss: 1.1098, test_acc: 0.6569, best: 0.6649, time: 0:00:58
 Epoch: 289, lr: 8.0e-05, train_loss: 0.8372, train_acc: 0.6960 test_loss: 1.3057, test_acc: 0.6410, best: 0.6649, time: 0:00:57
 Epoch: 290, lr: 8.0e-05, train_loss: 0.8397, train_acc: 0.6940 test_loss: 1.1453, test_acc: 0.6515, best: 0.6649, time: 0:00:57
 Epoch: 291, lr: 8.0e-05, train_loss: 0.8086, train_acc: 0.7100 test_loss: 1.0909, test_acc: 0.6529, best: 0.6649, time: 0:00:57
 Epoch: 292, lr: 8.0e-05, train_loss: 0.8098, train_acc: 0.7122 test_loss: 1.3295, test_acc: 0.6406, best: 0.6649, time: 0:00:58
 Epoch: 293, lr: 8.0e-05, train_loss: 0.8087, train_acc: 0.7130 test_loss: 1.2955, test_acc: 0.6354, best: 0.6649, time: 0:00:58
 Epoch: 294, lr: 8.0e-05, train_loss: 0.8159, train_acc: 0.7062 test_loss: 1.0304, test_acc: 0.6616, best: 0.6649, time: 0:00:58
 Epoch: 295, lr: 8.0e-05, train_loss: 0.8308, train_acc: 0.7014 test_loss: 1.0340, test_acc: 0.6610, best: 0.6649, time: 0:00:57
 Epoch: 296, lr: 8.0e-05, train_loss: 0.8274, train_acc: 0.7042 test_loss: 1.1319, test_acc: 0.6504, best: 0.6649, time: 0:00:57
 Epoch: 297, lr: 8.0e-05, train_loss: 0.8375, train_acc: 0.7022 test_loss: 1.1509, test_acc: 0.6549, best: 0.6649, time: 0:00:59
 Epoch: 298, lr: 8.0e-05, train_loss: 0.8515, train_acc: 0.6936 test_loss: 1.0655, test_acc: 0.6625, best: 0.6649, time: 0:00:58
 Epoch: 299, lr: 8.0e-05, train_loss: 0.8245, train_acc: 0.7064 test_loss: 1.2349, test_acc: 0.6500, best: 0.6649, time: 0:00:59
 Highest accuracy: 0.6649